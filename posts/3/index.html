
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="ja"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>EdmondFrank's 时光足迹</title>
  <meta name="author" content="EdmondFrank">

  
  <meta name="description" content="﻿SVM(Support Vector Machines)-支持向量机 曾经很多人都认为SVM是现在的最好的分类器，即：在不加以修改的前提之下，就能够在数据上进行训练并能够对训练集之外的数据点做出很好的分类决策。 基于最大间隔分割数据 支持向量机： 优点：泛化错误率低，计算开销不大，结果容易解释 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://edmondfrank.github.io/posts/3/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="EdmondFrank's 时光足迹" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.cat.net/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
   <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_SVG"></script>
  
  

</head>

<body >
  <div id="container">
    <header role="banner"><hgroup>
  <h1><a href="/">EdmondFrank's 时光足迹</a></h1>
  
    <h2>この先は暗い夜道だけかもしれない　それでも信じて進むんだ。星がその道を少しでも照らしてくれるのを。<br>或许前路永夜，即便如此我也要前进，因为星光即使微弱也会我为照亮前途。<br>——《四月は君の嘘》</h2>
  
</hgroup>

</header>
    <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="site:edmondfrank.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
</ul>

</nav>
    <div id="main">
      <div id="content">
        <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/10/11/svmzhi-chi-xiang-liang-ji/">SVM支持向量机</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-10-11T16:38:50+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="svmsupport-vector-machines-支持向量机">SVM(Support Vector Machines)-支持向量机</h1></p>

<p>曾经很多人都认为SVM是现在的最好的分类器，即：在不加以修改的前提之下，就能够在数据上进行训练并能够对训练集之外的数据点做出很好的分类决策。</p>




<h2 id="基于最大间隔分割数据">基于最大间隔分割数据</h2>




<p><strong>支持向量机：</strong> <br>
优点：泛化错误率低，计算开销不大，结果容易解释 <br>
缺点：对参数调节和核函数的选择策略敏感，原始分类器不加修改仅适用于处理二类问题。 <br>
<img src="http://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_0011.png" alt="enter image description here" title=""></p>




<p>在上图中，我们可以看出：我们可以很容易在图中画出一条直线将两组数据点分开。在这种情况下，这组数据被称为<strong>线性可分(linearly separable)</strong>数据，而将数据集分割开来的直线我们称为<strong>分隔超平面(separating hyperplane)</strong>。在上图例子中，由于数据点都在二维平面上，所有此时分隔超平面就只是一条直线而已。但是，如果所给的数据为三维的，那么此时用来分隔数据的就是一个平面。依此类推，如果给出一个N（N&gt;3）维数据集，那么则要用一个N-1维的对象来对数据进行分隔，该对象亦被称为<strong>超平面(hyperplane)</strong>。</p>




<p>我们希望通过这样的方式来构建分类器。即如果数据点离决策边界越远，那么其最后的预测效果就越可信。那么我们继续看回上面的图片，我们可以看到有三条直线（一条实线，两条虚线）它们分别都能将数据分隔开，但是其中哪一条才是最理想的呢？通常，我们可以做过这样的方法来确定一个最佳分隔平面，即：我们先找到离分隔平面最近的点，确保它们离分隔平面的距离尽可能远。</p>




<p>这里我们又要先引入一些新的概念： <br>
首先是，点到分隔面的距离被称为<strong>间隔(margin)</strong> <br>
<strong>支持向量(support vector)：</strong>就是离分割平面最近的那些点。</p>




<p>接下来，就是最大化支持向量都分隔面的距离，并需要找到此问题的优化求解方法。</p>




<h2 id="寻找最大间隔">寻找最大间隔</h2>




<p><strong>Maximum Marginal（最大间隔）</strong>是SVM的一个理论基础之一。选择使得间隔最大的函数作为分隔平面是十分容易解释的。从概率的角度上而言，就是使得置信度最小的点置信度最大;从现实意义上而言，两个个体的类别差异越大，我们自然也能够更为准确地分类。</p>




<p><img src="https://i.loli.net/2017/10/11/59ddd657a3c93.png" alt="svm.png" title=""></p>




<p>上图就是一个对之前所提及的类别间隙的一个描述。其中中间的黑色实线为<strong>分隔边界（Classifier Boundary）</strong>是我们算法中要求解的<strong>f(x)</strong>，红色和蓝色的线(plus plane 与 minus plane)就是支持变量所在的平面，而红色，蓝色之间的间隙就是我们要最大化的分类间的间隙。</p>




<p>首先，我们可以知道其两个支持向量的所在平面可以表达成如下形式：</p>




<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a677ed33ca0c840aa9295405fc095c8aefa73e48" alt="enter image description here" title=""></p>




<p>和</p>




<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6c3dbeeb7d5af27a2551ec07ce172ddbce62fc58" alt="enter image description here" title=""></p>




<p>然后，这两个超平面的距离可以表达成：<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ac553c94aec996dffa3369adcf285319178a474f" alt="enter image description here" title=""></p>




<p>因此，为了最大化两个平面的距离，我们只要最小化<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b6f27a892f3053ef0bfe273f88f18351a1a18ac" alt="" title="">即可。</p>




<p><strong>综上所述</strong>，我们可以将整个原理表示为：</p>




<blockquote>
  <p>Minimize<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b6f27a892f3053ef0bfe273f88f18351a1a18ac" alt="" title="">  <br>
  subject to<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7181cf8e723b24ad6d85b73b9513dcaac0d31023" alt="" title=""> <br>
  for <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/520ffef648f7b26db5bae564be860346630635fc" alt="enter image description here" title=""></p>
</blockquote>




<p>当支持变量确定的时候，整个分割函数也就确定了下来。除此之外，支持向量的出现还可以让向量后方的样本点不用再参与计算，大大降低了算法的计算复杂度。</p>




<p>再者，有关距离计算的优化。<script type="math/tex" id="MathJax-Element-41">||\vec w||</script>的意思是<script type="math/tex" id="MathJax-Element-42">\vec w</script>的二范数，由之前我们得到的最大间隔<script type="math/tex" id="MathJax-Element-43">M=2/||\vec w||</script>，最大化这个式子等价于最小化<script type="math/tex" id="MathJax-Element-44">|||\vec w||</script>，另外由于<script type="math/tex" id="MathJax-Element-45">||\vec w||</script>是一个单调函数，我们可以对其进行平方，和加上系数。数学经验丰富的朋友可能一眼就看出来，这样做是为了方便求导。</p>




<p>最后我们的式子可以写成：</p>




<p><img src="https://i.loli.net/2017/10/11/59ddd726bc801.png" alt="svmalg.png" title=""></p>




<p><strong>s.t的意思是subject to</strong>，也就是在后面这个限制条件下的意思，这个词在svm的论文里面非常容易见到。这其实是一个<strong>带约束的二次规划(quadratic programming, QP)问题</strong>，是一个<strong>凸问题</strong>，凸问题就是指的不会有局部最优解，可以想象一个漏斗，不管我们开始的时候将一个小球放在漏斗的什么位置，这个小球最终一定可以掉出漏斗，也就是得到全局最优解。s.t.后面的限制条件可以看做是一个凸多面体，我们要做的就是在这个凸多面体中找到最优解。</p>




<h2 id="优化求解">优化求解</h2>




<p>这个优化问题可以用<a href="https://en.wikipedia.org/wiki/Lagrange_multiplier">拉格朗日乘子法</a>去解，使用了<a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">KKT条件</a>的理论，这里直接作出这个式子的拉格朗日目标函数： <br>
<img src="https://i.loli.net/2017/10/11/59ddd726bb94a.png" alt="Lagrange.png" title=""></p>




<p>由于求解这个式子的过程需要<a href="https://en.wikipedia.org/wiki/Quadratic_programming#Lagrangian_duality">拉格朗日对偶性</a>的相关知识，以及较深入的数学背景知识，在这篇文章中暂且不谈，以后博客再另外写一篇有关具体推导的文章。</p>




<p>在此，我先贴出在该问题在论文中的关键推导步骤：</p>




<p><img src="https://i.loli.net/2017/10/11/59ddd726dd5a4.png" alt="formulation.png" title=""></p>




<p><img src="https://i.loli.net/2017/10/11/59ddd726d9bc8.png" alt="dual.png" title=""></p>




<p>上图就是我们需要最终优化的式子了。整篇文章到这里，我们终于得到了SVM线性可分问题的优化式子。</p>




<h2 id="svm的使用">SVM的使用</h2>




<p>由于支持向量机算法的实现涉及过多的数学背景，在本中暂不使用原生程序代码实现，而是选择调用Python sklearn 库现有的SVM算法进行使用的举例。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
</span><span class='line'><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
</span><span class='line'><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
</span><span class='line'><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
</span><span class='line'><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span class='line'><span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">pred</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, <br>
    decision_function_shape=None, degree=3, gamma=’auto’, kernel=’rbf’, <br>
    max_iter=-1, probability=False, random_state=None, shrinking=True, <br>
    tol=0.001, verbose=False) <br>
  0.986666666667</p>
</blockquote>




<p>本例使用的是<strong>sklearn</strong>库自带的<strong>iris</strong>数据集使用SVM算法进行训练，然后再进行回测。首先，我们可以看到在不做任意处理的前提下，SVM模型的预估效果也是相当不错的，其准确率高达98%（其结果主要因为使用的数据集优秀导致的，直接运用于工程上时不会有这么高的准确率）。</p>




<p>当然，上面例子中的算法模型的实现方式是十分简陋的。如果真正要使用SVM进行严格地建模，测试集与训练集的划分问题，数据的归一化处理问题等。都是我们需要考虑的元素。但由于本文主要为了介绍与探讨SVM算法，其他细节问题就不一一处理，详细方法可以参考我写的其他文章。</p>




<h2 id="svm的其他实现">SVM的其他实现</h2>




<p>除了Python的sklearn库外，SVM在其它语言及平台也有实现。其中： <br>
最流行的有</p>




<blockquote>
  <p><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM：</a><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">https://www.csie.ntu.edu.tw/~cjlin/libsvm/</a> <br>
  这是经典的svm库支持多种语言调用</p>
</blockquote>




<p>再者，在R语言中也有SVM算法的实现：</p>




<blockquote>
  <p><a href="https://cran.r-project.org/web/packages/e1071/index.html">e1071：</a> <br>
  <a href="https://cran.r-project.org/web/packages/e1071/index.html">https://cran.r-project.org/web/packages/e1071/index.html</a></p>
</blockquote>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/10/11/svmzhi-chi-xiang-liang-ji/">SVM支持向量机</a>
      <time datetime="2017-10-11T16:38:50+08:00" pubdate><span class='month'>Oct</span> <span class='day'>11</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/10/06/k-meansju-lei-jian-jie/">K-means聚类简介</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-10-06T14:28:25+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="k-means聚类简介">K-means聚类简介</h1></p>

<p>前面介绍了不少监督学习的各类算法，那么这次我们就来认识和了解一下无监督学习。首先，K-means聚类算法就是一种无监督学习的算法。这就意味着他可以通过没有分类标记的数据学习出训练数据本身的分组信息。（其实他的本质就是自动的将属性/特征类似的数据归到统一类别）而其最后分成的组数则由参数K来决定。</p>




<h2 id="算法基本步骤">算法基本步骤</h2>




<ol>
<li>随机初始化K个簇心。用作标识各组数据。</li>
<li>根据各个数据的特征/属性，将他们聚类到距离最接近的一个簇，并打上分类标识。</li>
<li>根据加入的数据重新计算每个簇的质心（均值，Means）</li>
<li>重复2，3步，直至最后所有数据被划分成k个簇。</li>
</ol>




<p>从以后的步骤我们也可以充分地看出，再聚类完毕之前数据是没有分组和标识的，而是通过聚类来查找和分析被划分在一起的数据。</p>




<p>同时，每个簇的质心是定义组的特征的代表，我们往往可以通过一个簇的质心看出该分组的特征以及属性。从而判断出这个簇代表了一个怎么样的组。</p>




<h2 id="应用领域">应用领域</h2>




<ul>
<li>网站，App的用户群体聚类</li>
<li>信用卡诈骗监测（这个是利用了聚类算法的反原理，寻找离群值）</li>
<li>文章自动归类</li>
<li>图像归类</li>
<li>人群健康状态监测（同信用卡诈骗检测同原理）</li>
</ul>




<p>此外，我们还可以通过监控数据点根据时间的变化而造成的组间切换现象找到状态变化的方法。</p>




<h2 id="算法主要原理">算法主要原理</h2>




<p>（1）在数据划分方面，我们主要依赖的思路是：<strong>欧氏距离</strong>。即，每个簇的质心定义了一种聚类，然后每个点根据其到每个簇的质心的欧几里德距离的平方的大小，将其分配到最近的簇中。我们假设<script type="math/tex" id="MathJax-Element-1">c_i</script>是簇集合C中质心i，那么我们可以将其聚类的过程表达成下列形式：</p>




<p><script type="math/tex" id="MathJax-Element-2">argmin_{c_i \in C} dist(c_i,x)^2</script></p>




<p>（2）<strong>质心的更新</strong>，在这一步骤中，各个簇的质心将要被重新计算，通过加入新的数据再重新计算包括i新数据在内的的整个簇的均值以此作为新的质心。该过程可以表达为一下形式：</p>




<p><script type="math/tex" id="MathJax-Element-3">c_i=\frac{1}{|S_i|}\sum_{x_i \in S_i }x_i</script></p>




<p>在多次迭代之后，该算法可以保证收敛于一个结果，虽然有可能只是一个局部的最优解而已。为了使得最后结果更加稳定和可靠，我们也可以通过多次运行算法然后再在多个结果中取得一个均衡（为什么说多次计算可以得到更好的结果呢？ 因为每次随机初始化的质心都是不同的，这样使得每次的运行结果都不尽相同，为了得到一个更加稳定的结果和更好的鲁棒性，多次运行往往是一个简单但却有效的方法。）</p>




<h2 id="有关k值的选择">有关K值的选择</h2>




<p>在K-means聚类算法中，K值的选择往往是一个较为难以抉择的问题。最后的情况是，在你应用这个算法之前，已经知道数据应该分为多少个类别合适，或者将这种方法应用在一个半监督学习的场合，使得最后的分类结果有据可依。</p>




<p>那么，在一般我们不太清楚分类的情况之下，我们能做的就是通过为K值制定一个范围，然后在这个范围之上，我们尝试运行我们的分类器，然后根据分类效果来评判我们的k的取值。</p>




<p>另外一方面，聚类算法通常会不断降低各个样本点到质心之间的距离，随着k值的增加，“距离”更是一直下降。但是，当k值增大到一定程度时，虽然“距离”仍在下降，但下降的速率已经变得十分缓慢了。我们常常称这个点的k值为<strong>肘点</strong>。往往到达肘点的k值已经能够很好地将各个类别之间的差异信息给描述出来，所以我们可以在不清楚数据具体分类信息的情况下，选择肘点值来作为我们的k值。</p>




<p><img src="https://www.datascience.com/hs-fs/hubfs/Blog/introduction-to-k-means-clustering-elbow-point-example.png?t=1507257936532&amp;width=760&amp;height=411&amp;name=introduction-to-k-means-clustering-elbow-point-example.png" alt="enter image description here" title=""></p>




<h2 id="example">Example</h2>




<p>在这里我们通过Python的Sklearn库来看一下K-means的应用实例</p>




<p><a href="https://raw.githubusercontent.com/datascienceinc/learn-data-science/master/Introduction-to-K-means-Clustering/Data/data_1024.csv">Delivery Fleet Data 数据下载</a></p>




<h3 id="数据读取">数据读取</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">&quot;data_1024.csv&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&quot;Distance_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&quot;Speeding_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Delivery Fleet Data&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote>
  <p>输出结果 <br>
    Driver_ID   Distance_Feature    Speeding_Feature <br>
  0   3423311935  71.24   28.0 <br>
  1   3423313212  52.53   25.0 <br>
  2   3423313724  64.54   27.0 <br>
  3   3423311373  55.69   22.0 <br>
  4   3423310999  54.58   25.0 <br>
  <img src="https://i.loli.net/2017/10/06/59d71bde43c28.png" alt="kmeans.png" title=""></p>
</blockquote>




<h3 id="算法使用">算法使用</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</span><span class='line'><span class="n">X_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">,</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">]]</span>
</span><span class='line'><span class="n">kmeas</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="o">/</span><span class="mf">255.</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">kmeas</span><span class="o">.</span><span class="n">labels_</span><span class="p">]</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&quot;Distance_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&quot;Speeding_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Delivery Fleet Data&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="n">kmeas</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="o">/</span><span class="mf">255.</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">kmeas</span><span class="o">.</span><span class="n">labels_</span><span class="p">]</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&quot;Distance_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&quot;Speeding_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Delivery Fleet Data&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  <img src="https://i.loli.net/2017/10/06/59d720b726068.png" alt="sk-kmeans.png" title=""></p>
</blockquote>




<p>上面的结果展示了，K分别等于2和4时对数据的聚类的结果，由于这个算法使用还算简单，在这里我也不做赘述了。那么有关K-means的简介到这里也就结束了，谢谢大家的阅读。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/10/06/k-meansju-lei-jian-jie/">K-means聚类简介</a>
      <time datetime="2017-10-06T14:28:25+08:00" pubdate><span class='month'>Oct</span> <span class='day'>06</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/09/30/ji-qi-xue-xi-zhi-ti-du-xia-jiang/">机器学习之梯度下降</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-09-30T20:19:04+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><h1 id="机器学习之梯度下降">机器学习之梯度下降</h1>




<h2 id="梯度下降gradient-descent">梯度下降(gradient descent)</h2>




<p>是线性回归的一种(Linear Regression)，在<a href="https://www.bilibili.com/video/av9912938/?from=search&amp;seid=3888228796805461518">Andrew Ng的machine learning</a>前期课程中有着详细的讲解，首先给出一个关于课程中经典的例子:预测房屋的价格。</p>




<table>
<thead>
<tr>
  <th>面积(feet2)</th>
  <th>房间个数</th>
  <th>价格（1000$）</th>
</tr>
</thead>
<tbody><tr>
  <td>2104</td>
  <td>3</td>
  <td>400</td>
</tr>
<tr>
  <td>1600</td>
  <td>3</td>
  <td>330</td>
</tr>
<tr>
  <td>2400</td>
  <td>3</td>
  <td>369</td>
</tr>
<tr>
  <td>1416</td>
  <td>2</td>
  <td>232</td>
</tr>
<tr>
  <td>3000</td>
  <td>4</td>
  <td>540</td>
</tr>
</tbody></table>




<p>在上面的表格中，房间的个数以及房屋的面积都是输入变量而，价格就是我们要预测输出的值。其中，面积和房屋个数分别表示一个特征，我们在这将他们一起用X来表示。价格用Y来表示。同时表格的每一行表示成一个样本，具体表示为：<script type="math/tex" id="MathJax-Element-1">f: X_1=[24104,3] \to Y_1=400</script>。</p>




<p>那么我们具体的任务就可以概括成给定一个训练集合，学习出一个函数<script type="math/tex" id="MathJax-Element-2">f</script>，使得<script type="math/tex" id="MathJax-Element-3">f(x)</script>能够符合结果Y，或者说能够使得<script type="math/tex" id="MathJax-Element-4">f(x)</script>与Y的之间的误差最小。</p>




<p>我们可以用以下的式子来表达上述的关系：</p>




<p><script type="math/tex" id="MathJax-Element-5">f(x) = \theta_1 x_1 + \theta_2 x_2 + \beta</script></p>




<p>其中，<script type="math/tex" id="MathJax-Element-6">\theta 表示X映射成Y的权重，而x表示为各组特征。</script> <br>
我们再分别用<script type="math/tex" id="MathJax-Element-7">x^{j},y^{j}来表示第J个样本</script>。这样我们就可以写出代价函数：</p>




<p><script type="math/tex" id="MathJax-Element-8">J(\theta) = \frac {1}{2}\sum ^m_{i=0}(f_\theta(x^{i})-y^{(i)})^2</script></p>




<p>然后我们要使得计算的结果无限接近真实值y的话，我们就要令得我们的代价函数（俗称的误差）最小化。要使得<script type="math/tex" id="MathJax-Element-9">J(\theta)</script>最小，即对<script type="math/tex" id="MathJax-Element-10">J(\theta)</script>进行求导操作，并使得其结果为0。</p>




<p><script type="math/tex" id="MathJax-Element-11">\theta_j = \theta_j - \frac{\partial J(\theta)}{\partial \theta_j}</script></p>




<p>当只有单个特征时，上式中的j表示系数（权重）的编号，右边的值赋给左边的变量后完成一次迭代过程。</p>




<p>而多个特征时，其迭代过程如下： <br>
<img src="https://i.loli.net/2017/09/23/59c5f7bb6ccee.png" alt="gd.png" title=""></p>




<p>上式就是<strong>批梯度下降算法(batch gradient descent)</strong>，当上式收敛时则退出迭代，何为收敛，即前后两次迭代的值不再发生变化了。一般情况下，会设置一个具体的参数，当前后两次迭代差值小于该参数时候结束迭代。注意以下几点：</p>




<p>(1) <strong>a 即学习率（learning rate</strong>），决定的下降步伐，如果太小，则找到函数最小值的速度就很慢，如果太大，则可能会出现无法逼近最小值的现象；</p>




<p>(2) 初始点不同，获得的最小值也不同，因此梯度下降求得的只是局部最小值；</p>




<p>(3) 越接近最小值时，下降速度越慢；</p>




<p>(4) 计算批梯度下降算法时候，计算每一个θ值都需要遍历计算所有样本，当数据量的时候这是比较费时的计算。</p>




<p>批梯度下降算法的步骤可以归纳为以下几步：</p>




<p>(1)先确定向下一步的步伐大小，我们称为Learning rate ；</p>




<p>(2)任意给定一个初始值：θ向量，一般为0向量</p>




<p>(3)确定一个向下的方向，并向下走预先规定的步伐，并更新θ向量</p>




<p>(4)当下降的高度小于某个定义的值，则停止下降；</p>




<h2 id="随机梯度下降算法">随机梯度下降算法</h2>




<p>因为每次计算梯度都需要遍历所有的样本点。这是因为梯度是J(θ)的导数，而J(θ)是需要考虑所有样本的误差和 ，这个方法问题就是，扩展性问题，当样本点很大的时候，基本就没法算了。</p>




<p>所以接下来又提出了<strong>随机梯度下降算法(stochastic gradient descent )</strong>。随机梯度下降算法，每次迭代只是考虑让该样本点的J(θ)趋向最小，而不管其他的样本点，这样算法会很快，但是收敛的过程会比较曲折，整体效果上，大多数时候它只能接近局部最优解，而无法真正达到局部最优解。所以适合用于较大训练集的例子。</p>




<p>其具体流程用公式表达如下：</p>




<p><img src="https://i.loli.net/2017/09/23/59c5f947573e4.png" alt="sgd.png" title=""></p>




<h2 id="代码实现">代码实现</h2>




<h3 id="批梯度下降算法">批梯度下降算法</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#Training data set</span>
</span><span class='line'><span class="c">#each element in x represents (x0,x1,x2)</span>
</span><span class='line'><span class="n">x</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">4.</span><span class="p">,</span><span class="mi">4</span><span class="p">)]</span>
</span><span class='line'><span class="c">#y[i] is the output of y = theta0 * x[0] + theta1 * x[1] +theta2 * x[2]</span>
</span><span class='line'><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">95.364</span><span class="p">,</span><span class="mf">97.217205</span><span class="p">,</span><span class="mf">75.195834</span><span class="p">,</span><span class="mf">60.105519</span><span class="p">,</span><span class="mf">49.342380</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.000001</span>
</span><span class='line'><span class="c">#learning rate</span>
</span><span class='line'><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.001</span>
</span><span class='line'><span class="n">diff</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="n">error1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">error0</span> <span class="o">=</span><span class="mi">0</span>
</span><span class='line'><span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">#init the parameters to zero</span>
</span><span class='line'><span class="n">theta0</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">theta1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">theta2</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">sum0</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">sum1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">sum2</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#calculate the parameters</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span><span class='line'>        <span class="c">#begin batch gradient descent</span>
</span><span class='line'>        <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="p">(</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">theta1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span>
</span><span class='line'>        <span class="n">sum0</span> <span class="o">=</span> <span class="n">sum0</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>        <span class="n">sum1</span> <span class="o">=</span> <span class="n">sum1</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</span><span class='line'>        <span class="n">sum2</span> <span class="o">=</span> <span class="n">sum2</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
</span><span class='line'>        <span class="c">#end  batch gradient descent</span>
</span><span class='line'>    <span class="n">theta0</span> <span class="o">=</span> <span class="n">sum0</span><span class="p">;</span>
</span><span class='line'>    <span class="n">theta1</span> <span class="o">=</span> <span class="n">sum1</span><span class="p">;</span>
</span><span class='line'>    <span class="n">theta2</span> <span class="o">=</span> <span class="n">sum2</span><span class="p">;</span>
</span><span class='line'>    <span class="c">#calculate the cost function</span>
</span><span class='line'>    <span class="n">error1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">lp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
</span><span class='line'>        <span class="n">error1</span> <span class="o">+=</span> <span class="p">(</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="p">(</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">theta1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span> <span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">error1</span><span class="o">-</span><span class="n">error0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
</span><span class='line'>        <span class="k">break</span>
</span><span class='line'>    <span class="k">else</span><span class="p">:</span>
</span><span class='line'>        <span class="n">error0</span> <span class="o">=</span> <span class="n">error1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">print</span><span class="p">(</span><span class="s">&#39; theta0 : </span><span class="si">%f</span><span class="s">, theta1 : </span><span class="si">%f</span><span class="s">, theta2 : </span><span class="si">%f</span><span class="s">, error1 : </span><span class="si">%f</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">,</span><span class="n">error1</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;Done: theta0 : </span><span class="si">%f</span><span class="s">, theta1 : </span><span class="si">%f</span><span class="s">, theta2 : </span><span class="si">%f</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
   theta0 : 0.377225, theta1 : 0.625295, theta2 : 1.120912, error1 : 4405.869965 <br>
   theta0 : 0.729497, theta1 : 1.193311, theta2 : 2.164098, error1 : 3094.652486 <br>
   theta0 : 1.058680, theta1 : 1.708424, theta2 : 3.135362, error1 : 2089.261446 <br>
   theta0 : 1.366497, theta1 : 2.174683, theta2 : 4.040070, error1 : 1335.974025 <br>
   theta0 : 1.654541, theta1 : 2.595831, theta2 : 4.883186, error1 : 789.589683 <br>
   theta0 : 1.924288, theta1 : 2.975327, theta2 : 5.669299, error1 : 412.137681 <br>
   theta0 : 2.177098, theta1 : 3.316371, theta2 : 6.402654, error1 : 171.776368 <br>
   theta0 : 2.414234, theta1 : 3.621921, theta2 : 7.087177, error1 : 41.856096 <br>
   theta0 : 2.636861, theta1 : 3.894714, theta2 : 7.726499, error1 : 0.121739 <br>
   theta0 : 2.846057, theta1 : 4.137277, theta2 : 8.323976, error1 : 28.034282 <br>
   theta0 : 3.042819, theta1 : 4.351950, theta2 : 8.882714, error1 : 110.193963 <br>
   …… <br>
    theta0 : 98.101057, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473679 <br>
   theta0 : 98.101058, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473678 <br>
   theta0 : 98.101058, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473677 <br>
   theta0 : 98.101059, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473676 <br>
   theta0 : 98.101059, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473675 <br>
   theta0 : 98.101060, theta1 : -13.028753, theta2 : 1.133772, error1 : 3.473674 <br>
   theta0 : 98.101061, theta1 : -13.028753, theta2 : 1.133772, error1 : 3.473673 <br>
  Done: theta0 : 98.101061, theta1 : -13.028753, theta2 : 1.133772</p>
</blockquote>




<p>由上面的输出结果可以知道，梯度下降算法会在迭代一定次数后收敛于一个较少的损失值（即error）然而这并不是最优解而只是一个局部最小值（因为我们也可以从结果看到 theta0 : 2.636861, theta1 : 3.894714, theta2 : 7.726499, error1 : 0.121739，这项数据的最终error反而优于我们的最终解）。</p>




<h3 id="随机梯度下降算法-1">随机梯度下降算法</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#Training data set</span>
</span><span class='line'><span class="c">#each element in x represents (x0,x1,x2)</span>
</span><span class='line'><span class="n">x</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">4.</span><span class="p">,</span><span class="mi">4</span><span class="p">)]</span>
</span><span class='line'><span class="c">#y[i] is the output of y = theta0 * x[0] + theta1 * x[1] +theta2 * x[2]</span>
</span><span class='line'><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">95.364</span><span class="p">,</span><span class="mf">97.217205</span><span class="p">,</span><span class="mf">75.195834</span><span class="p">,</span><span class="mf">60.105519</span><span class="p">,</span><span class="mf">49.342380</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.0001</span>
</span><span class='line'><span class="c">#learning rate</span>
</span><span class='line'><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
</span><span class='line'><span class="n">diff</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="n">error1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">error0</span> <span class="o">=</span><span class="mi">0</span>
</span><span class='line'><span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c">#init the parameters to zero</span>
</span><span class='line'><span class="n">theta0</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">theta1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">theta2</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>
</span><span class='line'><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#calculate the parameters</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="p">(</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">theta1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">theta0</span> <span class="o">=</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>        <span class="n">theta1</span> <span class="o">=</span> <span class="n">theta1</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</span><span class='line'>        <span class="n">theta2</span> <span class="o">=</span> <span class="n">theta2</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#calculate the cost function</span>
</span><span class='line'>    <span class="n">error1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">lp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
</span><span class='line'>        <span class="n">error1</span> <span class="o">+=</span> <span class="p">(</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="p">(</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">theta1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span> <span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">error1</span><span class="o">-</span><span class="n">error0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
</span><span class='line'>        <span class="k">break</span>
</span><span class='line'>    <span class="k">else</span><span class="p">:</span>
</span><span class='line'>        <span class="n">error0</span> <span class="o">=</span> <span class="n">error1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">print</span> <span class="p">(</span><span class="s">&#39; theta0 : </span><span class="si">%f</span><span class="s">, theta1 : </span><span class="si">%f</span><span class="s">, theta2 : </span><span class="si">%f</span><span class="s">, error1 : </span><span class="si">%f</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">,</span><span class="n">error1</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;Done: theta0 : </span><span class="si">%f</span><span class="s">, theta1 : </span><span class="si">%f</span><span class="s">, theta2 : </span><span class="si">%f</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
   theta0 : 2.782632, theta1 : 3.207850, theta2 : 7.998823, error1 : 7.508687 <br>
   theta0 : 4.254302, theta1 : 3.809652, theta2 : 11.972218, error1 : 813.550287 <br>
   theta0 : 5.154766, theta1 : 3.351648, theta2 : 14.188535, error1 : 1686.507256 <br>
   theta0 : 5.800348, theta1 : 2.489862, theta2 : 15.617995, error1 : 2086.492788 <br>
   theta0 : 6.326710, theta1 : 1.500854, theta2 : 16.676947, error1 : 2204.562407 <br>
   theta0 : 6.792409, theta1 : 0.499552, theta2 : 17.545335, error1 : 2194.779569 <br>
   theta0 : 7.223066, theta1 : -0.467855, theta2 : 18.302105, error1 : 2134.182794 <br>
   theta0 : 7.630213, theta1 : -1.384304, theta2 : 18.982980, error1 : 2056.719790 <br>
   …… <br>
    theta0 : 97.986505, theta1 : -13.221170, theta2 : 1.257223, error1 : 1.553680 <br>
   theta0 : 97.986620, theta1 : -13.221169, theta2 : 1.257186, error1 : 1.553579 <br>
   theta0 : 97.986735, theta1 : -13.221167, theta2 : 1.257150, error1 : 1.553479 <br>
   theta0 : 97.986849, theta1 : -13.221166, theta2 : 1.257113, error1 : 1.553379 <br>
   theta0 : 97.986963, theta1 : -13.221165, theta2 : 1.257077, error1 : 1.553278 <br>
  Done: theta0 : 97.987078, theta1 : -13.221163, theta2 : 1.257041</p>
</blockquote>




<p>通过上述批梯度下降和随机梯度下降算法代码的对比，不难发现两者的区别： <br>
随机梯度下降算法在迭代的时候，每迭代一个新的样本，就会更新一次所有的theta参数。 <br>
因此当样本数量很大时候，批梯度得做完所有样本的计算才能更新一次theta，从而花费的时间远大于随机梯度下降。但是随机梯度下降过早的结束了迭代，使得它获取的值只是接近局部最优解，而并非像批梯度下降算法那样就是局部最优解。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/09/30/ji-qi-xue-xi-zhi-ti-du-xia-jiang/">机器学习之梯度下降</a>
      <time datetime="2017-09-30T20:19:04+08:00" pubdate><span class='month'>Sep</span> <span class='day'>30</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/09/24/python-shi-xian-tui-jian-xi-tong/">Python 实现推荐系统</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-09-24T10:51:37+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><h1 id="python-实现推荐系统">Python 实现推荐系统</h1>




<h2 id="引言">引言</h2>




<p>最早的推荐系统应该是亚马逊为了提升长尾货物的用户抵达率而发明的。已经有数据证明，长尾商品的销售额以及利润总和与热门商品是基本持平的。亚马逊网站上在线销售的商品何止百万，但首页能够展示的商品数量又极其有限，给用户推荐他们可能喜欢的商品就成了一件非常重要的事情。当然，商品搜索也是一块大蛋糕，亚马逊的商品搜索早已经开始侵蚀谷歌的核心业务了。</p>




<p>从这些例子之中，我们可以看到我们能够使用许多不同的方式来搜集兴趣偏好。有时候，这些数据可能来自人们购买的商品，以及这些商品关联的评价信息。我们可以利用一组算法从中挖掘，建立几个有意思的推荐系统。</p>




<h2 id="推荐系统的简介">推荐系统的简介</h2>




<p>两种最普遍的推荐系统的类型是基于内容的推荐系统和协同过滤推荐系统（CF）。协同过滤基于用户对产品的态度产生推荐，基于内容的推荐系统基于物品属性的相似性进行推荐。CF可以分为基于内存的协同过滤和基于模型的协同过滤。</p>




<h3 id="基于内容推荐">基于内容推荐</h3>




<p><strong>基于内容的推荐（Content-based Recommendation）</strong>，它是建立在项目的内容信息上作出推荐的，而不需要依据用户对项目的评价意见，更多地需要用机器学习的方法从关于内容的特征描述的事例中得到用户的兴趣资料。在基于内容的推荐系统中，项目或对象是通过相关的特征的属性来定义，系统基于用户评价对象的特征，学习用户的兴趣，考察用户资料与待预测项目的相匹配程度。用户的资料模型取决于所用学习方法，常用的有决策树、神经网络和基于向量的表示方法等。</p>




<h4 id="基于内容推荐方法的优点是">基于内容推荐方法的优点是：</h4>




<ul>
<li>不需要其它用户的数据，没有冷开始问题和稀疏问题。</li>
<li>能为具有特殊兴趣爱好的用户进行推荐。</li>
<li>能推荐新的或不是很流行的项目，没有新项目问题。</li>
<li>通过列出推荐项目的内容特征，可以解释为什么推荐那些项目。</li>
<li>已有比较好的技术，如关于分类学习方面的技术已相当成熟。</li>
</ul>




<h4 id="缺点是">缺点是:</h4>




<p>要求内容能容易抽取成有意义的特征，要求特征内容有良好的结构性，并且用户的口味必须能够用内容特征形式来表达，不能显式地得到其它用户的判断情况。</p>




<h3 id="协同过滤推荐">协同过滤推荐</h3>




<p><strong>协同过滤推荐（Collaborative Filtering Recommendation）</strong>，是推荐系统中应用最早和最为成功的技术之一。它一般采用最近邻技术，利用用户的历史喜好信息计算用户之间的距离，然后利用目标用户的最近邻居用户对商品评价的加权评价值来预测目标用户对特定商品的喜好程度，系统从而根据这一喜好程度来对目标用户进行推荐。协同过滤最大优点是对推荐对象没有特殊的要求，能处理非结构化的复杂对象，如音乐、电影。</p>




<p>协同过滤是基于这样的假设：为一用户找到他真正感兴趣的内容的好方法是首先找到与此用户有相似兴趣的其他用户，然后将他们感兴趣的内容推荐给此用 户。其基本思想非常易于理解，在日常生活中，我们往往会利用好朋友的推荐来进行一些选择。协同过滤正是把这一思想运用到电子商务推荐系统中来，基于其他用 户对某一内容的评价来向目标用户进行推荐。</p>




<p>基于协同过滤的推荐系统可以说是从用户的角度来进行相应推荐的，而且是自动的即用户获得的推荐是系统从购买模式或浏览行为等隐式获得的，不需要用户努力地找到适合自己兴趣的推荐信息，如填写一些调查表格等。</p>




<p>和基于内容的过滤方法相比，</p>




<h4 id="协同过滤具有如下的优点">协同过滤具有如下的优点：</h4>




<ul>
<li>能够过滤难以进行机器自动内容分析的信息，如艺术品，音乐等。</li>
<li>共享其他人的经验，避免了内容分析的不完全和不精确，并且能够基于一些复杂的，难以表述的概念（如信息质量、个人品味）进行过滤。</li>
<li>有推荐新信息的能力。可以发现内容上完全不相似的信息，用户对推荐信息的内容事先是预料不到的。这也是协同过滤和基于内容的过滤一个较大的差别，基于内容的过滤推荐很多都是用户本来就熟悉的内容，而协同过滤可以发现用户潜在的但自己尚未发现的兴趣偏好。</li>
<li>能够有效的使用其他相似用户的反馈信息，较少用户的反馈量，加快个性化学习的速度。</li>
</ul>




<h4 id="缺点是-1">缺点是：</h4>




<p>最典型的问题有， <br>
稀疏问题（Sparsity） <br>
可扩展问题（Scalability） <br>
冷启动问题</p>




<h2 id="实例应用">实例应用</h2>




<p>我们下面通过使用MovieLens数据集（这是一个有关电影评分的经典数据集， 其中Movielens-100k和movielens-1M有用户对电影的打分，电影的title、genre、IMDB链接、用户的gender、age、occupation、zip code。movielens-10M中还有用户对电影使用的tag信息。）</p>




<p>数据集的<a href="http://files.grouplens.org/datasets/movielens/ml-100k.zip">下载地址</a></p>




<h3 id="数据读取">数据读取</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;user_id&#39;</span><span class="p">,</span><span class="s">&#39;item_id&#39;</span><span class="p">,</span><span class="s">&#39;rating&#39;</span><span class="p">,</span><span class="s">&#39;timestamp&#39;</span><span class="p">]</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">&#39;/home/ef/Desktop/ml-100k/u.data&#39;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">sep</span><span class="o">=</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">,</span><span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</span><span class='line'><span class="n">n_users</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">user_id</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="n">n_items</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">item_id</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Number of users = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_users</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39; | Number of movies = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_items</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
     user_id  item_id  rating  timestamp <br>
  0      196      242       3  881250949 <br>
  1      186      302       3  891717742 <br>
  2       22      377       1  878887116 <br>
  3      244       51       2  880606923 <br>
  4      166      346       1  886397596 <br>
  Number of users = 943 | Number of movies = 1682</p>
</blockquote>




<h3 id="数据划分">数据划分</h3>




<p>使用scikit-learn库来划分数据集</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span> <span class="k">as</span> <span class="n">cv</span>
</span><span class='line'><span class="n">X_train</span><span class="p">,</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<h3 id="基于内存的协同过滤">基于内存的协同过滤</h3>




<p>基于内存的协同过滤方法可以分为两个部分：</p>




<ul>
<li>用户－产品协同过滤，即：基于用户的协同过滤推荐</li>
<li>产品－产品协同过滤，即：基于物品的协同过滤推荐</li>
</ul>




<p>基于用户的协同过滤推荐，将选取一个特定的用户，基于打分的相似性发现类似于该用户的用户，并推荐那些相似用户喜欢的产品。基于物品的协同过滤推荐会选取一个产品，发现喜欢该产品的用户，并找到这些相似用户还喜欢的其它产品。</p>




<p>基于用户的协同过滤推荐：“喜欢这东西的人也喜欢……” <br>
基于物品的协同过滤推荐：“像你一样的人也喜欢（买个该商品的还买了）……”</p>




<p>在这两种情况下，从整个数据集构建一个用户产品矩阵。</p>




<h4 id="用户产品矩阵的例子">用户产品矩阵的例子：</h4>




<p>计算相似性，并创建一个相似性矩阵。 <br>
通常用于推荐系统中的距离矩阵是余弦相似性，其中，打分被看成n维空间中的向量，而相似性是基于这些向量之间的角度进行计算的。用户a和b的余弦相似性可以用下面的公式进行计算：</p>




<p><script type="math/tex" id="MathJax-Element-1">Similar_u^{cos}(U_a,U_b)=\frac{U_a*U_b}{||U_a|| * ||U_b||} = \frac {\sum x_{a,m}x_{b,m}}{\sqrt {\sum x^2_{a,m}\sum x^2_{b,m} }}</script></p>




<p>同时，物品a和b的相似读也可以写成以上形式。</p>




<p>创建用户产品矩阵，针对测试数据和训练数据，创建两个矩阵：</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span> <span class="k">as</span> <span class="n">cv</span>
</span><span class='line'><span class="n">X_train</span><span class="p">,</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">train_data_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_users</span><span class="p">,</span><span class="n">n_items</span><span class="p">))</span>
</span><span class='line'><span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
</span><span class='line'>    <span class="n">train_data_matrix</span><span class="p">[</span><span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">line</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</span><span class='line'><span class="n">test_data_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_users</span><span class="p">,</span> <span class="n">n_items</span><span class="p">))</span>
</span><span class='line'><span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">x_test</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
</span><span class='line'>    <span class="n">test_data_matrix</span><span class="p">[</span><span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">line</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="c">## 通过余弦相似度计算用户和物品的相似度</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
</span><span class='line'><span class="n">user_similarity</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">train_data_matrix</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="s">&quot;cosine&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">item_similarity</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">train_data_matrix</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="s">&quot;cosine&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<h4 id="评估">评估</h4>




<p>这里采用均方根误差(RMSE)来度量预测评分的准确性,可以使用sklearn的mean_square_error(MSE)函数，其中RMSE仅仅是MSE的平方根。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
</span><span class='line'><span class="k">def</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">):</span>
</span><span class='line'>    <span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</span><span class='line'>    <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">ground_truth</span><span class="p">[</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;User based CF RMSE: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">user_prediction</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;Item based CF RMSe: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">item_prediction</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;User based CF RMSE: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">user_prediction</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;Item based CF RMSe: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">item_prediction</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
  User based CF RMSE: 3.087357412872858 <br>
  Item based CF RMSe: 3.437038163412728</p>
</blockquote>




<p>但从结果来看，算法的推荐效果还算理想。</p>




<h3 id="基于模型的协同过滤">基于模型的协同过滤</h3>




<p>基于模型的协同过滤是基于<strong>矩阵分解(MF)的</strong>，矩阵分解广泛应用于推荐系统中，它比基于内存的CF有更好的扩展性和稀疏性。MF的目标是从已知的评分中学习用户的潜在喜好和产品的潜在属性，随后通过用户和产品的潜在特征的点积来预测未知的评分。 <br>
这是一个典型的机器学习的问题，可以将已有的用户喜好信息作为训练样本，训练出一个预测用户喜好的模型，这样以后用户在进入系统，可以基于此模型计算推荐。这种方法的问题在于如何将用户实时或者近期的喜好信息反馈给训练好的模型，从而提高推荐的准确度。</p>




<h4 id="svd">SVD</h4>




<p>SVD即：<strong>奇异值分解（Singular value decomposition）</strong>奇异值分解是线性代数中一种重要的矩阵分解，在信号处理、统计学等领域有重要应用。奇异值分解在某些方面与对称矩阵或Hermite矩阵基于特征向量的对角化类似。然而这两种矩阵分解尽管有其相关性，但还是有明显的不同。对称阵特征向量分解的基础是谱分析，而奇异值分解则是谱分析理论在任意矩阵上的推广。</p>




<p>在矩阵M的奇异值分解中</p>




<p><script type="math/tex" id="MathJax-Element-2">M=UΣV^T</script> </p>




<ul>
<li><strong>U的列(columns)</strong>组成一套对M的正交”输入”或”分析”的基向量。这些向量是MM*的特征向量。</li>
<li><strong>V的列(columns)</strong>组成一套对M的正交”输出”的基向量。这些向量是M*M的特征向量。</li>
<li><strong>Σ对角线上的元素</strong>是奇异值，可视为是在输入与输出间进行的标量的”膨胀控制”。这些是M*M及MM*的奇异值，并与U和V的列向量相对应。</li>
</ul>




<p>那么矩阵M就可以分解成U，Σ，V。 <br>
U矩阵表示对应于隐藏特性空间中的用户的特性矩阵，而V矩阵表示对应于隐藏特性空间中的产品的特性矩阵。</p>




<p>现在，我们可以通过U，Σ和<script type="math/tex" id="MathJax-Element-3">V^T</script>的点积进行预测了。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># 计算矩阵的稀疏度</span>
</span><span class='line'><span class="n">sparsity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">n_users</span><span class="o">*</span><span class="n">n_items</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;The sparsity level of MovieLen100K is &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sparsity</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39;%&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="kn">as</span> <span class="nn">sp</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scipy.sparse.linalg</span> <span class="kn">import</span> <span class="n">svds</span>
</span><span class='line'><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vt</span> <span class="o">=</span> <span class="n">svds</span><span class="p">(</span><span class="n">train_data_matrix</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
</span><span class='line'><span class="n">s_diag_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</span><span class='line'><span class="n">x_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">s_diag_matrix</span><span class="p">),</span><span class="n">vt</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;User-based CF MSE: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
  The sparsity level of MovieLen100K is 93.7% <br>
  User-based CF MSE: 2.63901831155016</p>
</blockquote>




<p>最后，我们可以发现，采用SVD分解矩阵的基于模型的协同过滤方法在推荐的表现上更胜一筹。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/09/24/python-shi-xian-tui-jian-xi-tong/">Python 实现推荐系统</a>
      <time datetime="2017-09-24T10:51:37+08:00" pubdate><span class='month'>Sep</span> <span class='day'>24</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/09/19/aprioriyu-guan-lian-fen-xi/">Apriori与关联分析</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-09-19T13:33:11+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><h1 id="关联分析">关联分析</h1>




<h2 id="相关概念">相关概念</h2>




<p>作为经典的机器学习算法来说，关联分析并不算复杂。简单来说，从大规模数据集中寻找物品间的隐含关系被称作<strong>关联分析(association analysis)</strong>或者<strong>关联规则学习(association rule learning)</strong>。而其中关联分析的关键就是在众多的物品组成的<strong>项集(itemset)</strong>中找到那些经常一起出现的物品集合，也就是我们所谓的<strong>频繁项集</strong>。由于寻找物品的不同组合是一项非常耗时的任务，所需的计算代价也非常的高，这样显然用蛮力的搜索方法是不可取的。为了解决这样的问题，我们需要用到<strong>Apriori算法</strong>来解决。</p>




<h4 id="有关关联分析的一些应用">有关关联分析的一些应用</h4>




<ol>
<li>购物篮分析，这是关联分析最经典的一项应用。我们耳熟能详的<a href="http://www.jianshu.com/p/a22890153f93"><em>尿布与啤酒</em></a>就是来源于此（虽然这个故事的真实性有待考据，但这并不影响它成为一个营销界的小故事）。</li>
<li>公众热点发现</li>
<li>新闻及流行趋势挖掘</li>
<li>搜索引擎推荐</li>
<li>发现毒蘑菇的相似特征（该例子取自《机器学习实战》一书）</li>
</ol>




<h2 id="apriori算法">Apriori算法</h2>




<p>优点：易编码实现 <br>
缺点：在大数据集上计算效果较慢</p>




<p>既然关联分析是一种在大规模数据集中寻找有趣的关系的任务。这些关系可以有两种形式：一种就是我们上面所说的<strong>频繁项集(frequent itemsets)</strong>;另外一种则是<strong>关联规则(association rules)</strong>。关联规则，其暗示了两种物品之间可能存在很强的关系。</p>




<p>那么我们该如何定义有趣的关系呢？以及，频繁项集中的频繁有怎么划定呢？虽然，许多概念都可以说明这些问题，但是最重要及最通用的莫过于其<strong>支持度</strong>和<strong>可信度</strong>。</p>




<p><strong>支持度(support)：</strong>一个项集的支持度被定义为数据集包含该项集的记录比例。</p>




<blockquote>
  <p>举个例子: <br>
<img src="https://i.loli.net/2017/09/30/59ce75c2b9080.jpg" alt="apriori.jpg" title="apriori.jpg" /><br>
  如上图所示，因为5项记录中有4条包含了{豆奶}，所以其支持度为4/5;依此类推，{豆奶，尿布}的支持读为3/5。</p>
</blockquote>




<p><strong>可信度或置信度(confidence)：</strong>这个概念是针对一条{尿布} -&gt; {葡萄酒}这样的关联规则来定义的。</p>




<blockquote>
  <p><script type="math/tex" id="MathJax-Element-1">置信度({尿布} -> {葡萄酒} )= 支持度({尿布,葡萄酒}) / 支持度({尿布})</script></p>
</blockquote>




<p>支持度和可信度是用来量化关联分析是否成功的方法。</p>




<h4 id="apriori原理">Apriori原理</h4>




<p>如果计算一个集合中的频繁项集的支持度，首先需要遍历全部可能的项集，比如针对一个包含了4个产品的集合，那么购买该集合产品的可能集合数目为2^4-1=15，而针对包含N项的集合，就需要遍历2^N-1。显然，这样的计算量很大。为了降低所需计算时间，就需要我们所谓的Apriori原理。</p>




<p><strong>其基本思路：</strong>如果某个项集是频繁的，那么它的所有子集也是频繁的。该定理的逆反定理为：如果某一个项集是非频繁的，那么它的所有超集（包含该集合的集合）也是非频繁的。Apriori原理的出现，可以在得知某些项集是非频繁之后，不需要计算该集合的超集，有效地避免项集数目的指数增长，从而在合理时间内计算出频繁项集。</p>




<h4 id="算法基本流程">算法基本流程</h4>




<p>当集合中项的个数大于0时： <br>
    创建一个长度为k的候选项集列表 <br>
    检查数据以确认每个项集都是频繁的 <br>
    保留频繁项集，并构建k+1项组成的候选集列表</p>




<h4 id="代码实现">代码实现</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">load_dataset</span><span class="p">():</span>
</span><span class='line'>    <span class="s">&quot;Load the sample dataset.&quot;</span>
</span><span class='line'>    <span class="k">return</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
</span><span class='line'><span class="k">def</span> <span class="nf">createC1</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Create a list of candidate item sets of size one.&quot;</span>
</span><span class='line'>    <span class="n">c1</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">transaction</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">transaction</span><span class="p">:</span>
</span><span class='line'>            <span class="k">if</span> <span class="ow">not</span> <span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="ow">in</span> <span class="n">c1</span><span class="p">:</span>
</span><span class='line'>                <span class="n">c1</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">item</span><span class="p">])</span>
</span><span class='line'>    <span class="n">c1</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</span><span class='line'>    <span class="c">#frozenset because it will be a ket of a dictionary.</span>
</span><span class='line'>    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">,</span> <span class="n">c1</span><span class="p">))</span>
</span><span class='line'><span class="k">def</span> <span class="nf">scanD</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">min_support</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Returns all candidates that meets a minimum support level&quot;</span>
</span><span class='line'>    <span class="n">sscnt</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">tid</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
</span><span class='line'>        <span class="c">#print(tid)</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">can</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">can</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">tid</span><span class="p">):</span>
</span><span class='line'>                <span class="n">sscnt</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">can</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span class='line'>                <span class="n">sscnt</span><span class="p">[</span><span class="n">can</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">num_items</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
</span><span class='line'>    <span class="n">retlist</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="n">support_data</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">sscnt</span><span class="p">:</span>
</span><span class='line'>        <span class="n">support</span> <span class="o">=</span> <span class="n">sscnt</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="n">num_items</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">support</span> <span class="o">&gt;=</span> <span class="n">min_support</span><span class="p">:</span>
</span><span class='line'>            <span class="n">retlist</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
</span><span class='line'>        <span class="n">support_data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">support</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">retlist</span><span class="p">,</span> <span class="n">support_data</span>
</span><span class='line'><span class="k">def</span> <span class="nf">aprioriGen</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Generate the joint transactions from candidate sets&quot;</span>
</span><span class='line'>    <span class="n">retList</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="n">lenLk</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">)</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">lenLk</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">lenLk</span><span class="p">):</span>
</span><span class='line'>            <span class="n">L1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">[</span><span class="n">i</span><span class="p">])[:</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span>
</span><span class='line'>            <span class="n">L2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">[</span><span class="n">j</span><span class="p">])[:</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span>
</span><span class='line'>            <span class="n">L1</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</span><span class='line'>            <span class="n">L2</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">L1</span> <span class="o">==</span> <span class="n">L2</span><span class="p">:</span>
</span><span class='line'>                <span class="n">retList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">|</span> <span class="n">freq_sets</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">retList</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">apriori</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">minsupport</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Generate a list of candidate item sets&quot;</span>
</span><span class='line'>    <span class="n">C1</span> <span class="o">=</span> <span class="n">createC1</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</span><span class='line'>    <span class="n">D</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">set</span><span class="p">,</span> <span class="n">dataset</span><span class="p">))</span>
</span><span class='line'>    <span class="n">L1</span><span class="p">,</span> <span class="n">support_data</span> <span class="o">=</span> <span class="n">scanD</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">minsupport</span><span class="p">)</span>
</span><span class='line'>    <span class="n">L</span> <span class="o">=</span> <span class="p">[</span><span class="n">L1</span><span class="p">]</span>
</span><span class='line'>    <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span>
</span><span class='line'>    <span class="k">while</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">L</span><span class="p">[</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
</span><span class='line'>        <span class="n">Ck</span> <span class="o">=</span> <span class="n">aprioriGen</span><span class="p">(</span><span class="n">L</span><span class="p">[</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">],</span> <span class="n">k</span><span class="p">)</span>
</span><span class='line'>        <span class="n">Lk</span><span class="p">,</span> <span class="n">supK</span> <span class="o">=</span> <span class="n">scanD</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">Ck</span><span class="p">,</span> <span class="n">minsupport</span><span class="p">)</span>
</span><span class='line'>        <span class="n">support_data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">supK</span><span class="p">)</span>
</span><span class='line'>        <span class="n">L</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Lk</span><span class="p">)</span>
</span><span class='line'>        <span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">L</span><span class="p">,</span> <span class="n">support_data</span>
</span></code></pre></td></tr></table></div></figure>


<h4 id="挖掘关联规则">挖掘关联规则</h4>




<p>上面，我们实现了用apriori算法找出了频繁项集。现在我们来尝试找出关联规则。那么什么是关联规则呢？我们可以举这样一个例子：假设我们有一个频繁项集是：{豆奶，莴苣}。那么则意味着一个人如果他已经购买了豆奶，那么他也有很大的几率会购买莴苣;但反过来却不一定成立：则如果一个人购买了莴苣，但还是不能说明他有很大几率会接着购买豆奶。</p>




<p>既然，在上面的例子中我们已经用支持度作为一种参考单位去量化一个集合的频繁关系，在这里我们同理也可以通过另一个概念来度量关联规则。没错，它就是我们已经在上面提过的<strong>可信度</strong>。根据可信度的计算法则和定义可知：</p>




<blockquote>
  <p><script type="math/tex" id="MathJax-Element-2">置信度({尿布} -> {葡萄酒} )= 支持度({尿布,葡萄酒}) / 支持度({尿布})</script></p>
</blockquote>




<p>这也是我们上面已经提及过的问题。加上，在上面的例子之中我们已经得到了所有的频繁项集的支持度，那么为了求出各关联规则的可信度也就是剩下一个除法的问题而已。</p>




<h4 id="如何从频繁项集中生成关联规则">如何从频繁项集中生成关联规则</h4>




<p>一般对于一个频繁项集而言，如果我们直接生成关联规则的话，往往会有很多条。例如：我们对一个频繁项集{0，1，2，3}直接生成关联规则的话结果就如下图所示一样： <br>
<img src="https://i.loli.net/2017/09/30/59ce75dc70dd2.png" alt="assrule.png" title="assrule.png" /><br>
从上图我们就可以看出仅仅含4项的频繁项集就会生成出如此多的关联规则，那么如果频繁项集中含有10，20，甚至100个元素那么生成的候选关联规则的数据是相当庞大。</p>




<p>在此，我们可以参考apriori算法中挖掘频繁项集的思路。在发现频繁项集时我们通过最低支持度的方法来忽略掉一些项集支持度的计算;同理，在这里我们将这个思想应用在关联规则的生成之上，即：如果一条规则的不满足最低可信度的要求，那么其子集自然也不能满足最低可信度的要求。对于这部分规则的可信度计算我们可以直接忽略。如上图中的阴影部分。我们假设规则{0，1，2} -&gt; 3不能满足最低可信度，那么，他的子集{1，2}-&gt;{0，3}，{0，2}-&gt;{1，3}等将不能满足最低可信度。</p>




<h4 id="代码实现-1">代码实现</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">generateRules</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">min_confidence</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;Create the association rules</span>
</span><span class='line'><span class="sd">    L: list of frequent item sets</span>
</span><span class='line'><span class="sd">    support_data: support data for those itemsets</span>
</span><span class='line'><span class="sd">    min_confidence: minimum confidence threshold</span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">rules</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">L</span><span class="p">)):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">freqSet</span> <span class="ow">in</span> <span class="n">L</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
</span><span class='line'>            <span class="n">H1</span> <span class="o">=</span> <span class="p">[</span><span class="nb">frozenset</span><span class="p">([</span><span class="n">item</span><span class="p">])</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">freqSet</span><span class="p">]</span>
</span><span class='line'>            <span class="k">print</span><span class="p">(</span><span class="s">&quot;freqSet&quot;</span><span class="p">,</span> <span class="n">freqSet</span><span class="p">,</span> <span class="s">&#39;H1&#39;</span><span class="p">,</span> <span class="n">H1</span><span class="p">)</span>
</span><span class='line'>            <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
</span><span class='line'>                <span class="n">rules_from_conseq</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">H1</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="p">)</span>
</span><span class='line'>            <span class="k">else</span><span class="p">:</span>
</span><span class='line'>                <span class="n">calc_confidence</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">H1</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">rules</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">calc_confidence</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Evaluate the rule generated&quot;</span>
</span><span class='line'>    <span class="n">pruned_H</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">conseq</span> <span class="ow">in</span> <span class="n">H</span><span class="p">:</span>
</span><span class='line'>        <span class="n">conf</span> <span class="o">=</span> <span class="n">support_data</span><span class="p">[</span><span class="n">freqSet</span><span class="p">]</span> <span class="o">/</span> <span class="n">support_data</span><span class="p">[</span><span class="n">freqSet</span> <span class="o">-</span> <span class="n">conseq</span><span class="p">]</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">conf</span> <span class="o">&gt;=</span> <span class="n">min_confidence</span><span class="p">:</span>
</span><span class='line'>            <span class="k">print</span><span class="p">(</span><span class="n">freqSet</span> <span class="o">-</span> <span class="n">conseq</span><span class="p">,</span> <span class="s">&#39;---&gt;&#39;</span><span class="p">,</span> <span class="n">conseq</span><span class="p">,</span> <span class="s">&#39;conf:&#39;</span><span class="p">,</span> <span class="n">conf</span><span class="p">)</span>
</span><span class='line'>            <span class="n">rules</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">freqSet</span> <span class="o">-</span> <span class="n">conseq</span><span class="p">,</span> <span class="n">conseq</span><span class="p">,</span> <span class="n">conf</span><span class="p">))</span>
</span><span class='line'>            <span class="n">pruned_H</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conseq</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">pruned_H</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">rules_from_conseq</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Generate a set of candidate rules&quot;</span>
</span><span class='line'>    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">H</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">freqSet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
</span><span class='line'>        <span class="n">Hmp1</span> <span class="o">=</span> <span class="n">aprioriGen</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>        <span class="n">Hmp1</span> <span class="o">=</span> <span class="n">calc_confidence</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">Hmp1</span><span class="p">,</span>  <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="p">)</span>
</span><span class='line'>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Hmp1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span class='line'>            <span class="n">rules_from_conseq</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">Hmp1</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>运行测试</p>
</blockquote>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">()</span>
</span><span class='line'><span class="n">L</span><span class="p">,</span><span class="n">support_data</span> <span class="o">=</span> <span class="n">apriori</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</span><span class='line'><span class="n">generateRules</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">support_data</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  freqSet frozenset({3, 5}) H1 [frozenset({3}), frozenset({5})] <br>
  freqSet frozenset({1, 3}) H1 [frozenset({1}), frozenset({3})] <br>
  frozenset({1}) —&gt; frozenset({3}) conf: 1.0 <br>
  freqSet frozenset({2, 5}) H1 [frozenset({2}), frozenset({5})] <br>
  frozenset({5}) —&gt; frozenset({2}) conf: 1.0 <br>
  frozenset({2}) —&gt; frozenset({5}) conf: 1.0 <br>
  freqSet frozenset({2, 3}) H1 [frozenset({2}), frozenset({3})] <br>
  freqSet frozenset({2, 3, 5}) H1 [frozenset({2}), frozenset({3}), frozenset({5})] <br>
  Out[6]: <br>
  [(frozenset({1}), frozenset({3}), 1.0), <br>
   (frozenset({5}), frozenset({2}), 1.0), <br>
   (frozenset({2}), frozenset({5}), 1.0)]</p>
</blockquote>




<p>从输出结果可以看出，其中{1} —&gt; {3}，{5} —&gt; {2}，{2} —&gt; {5}这三条关联规则的可信度居然达到了1.0，而且{2}，{5}还存在一个相互关联的关系。除此之外，我们还可以发现：虽然{1} —&gt; {3}这条关联的可信度达到了1.0，但是{3} —&gt; {1}却不足0.7（因为我们的最低可信度标准为0.7，没有输出显示的规则，则意味着它们的可信度低于0.7)。为了可以看见输出更多的规则，我们可以降低下最低可信度的标准，再来执行一遍代码。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">()</span>
</span><span class='line'><span class="n">L</span><span class="p">,</span><span class="n">support_data</span> <span class="o">=</span> <span class="n">apriori</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</span><span class='line'><span class="n">generateRules</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">support_data</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  freqSet frozenset({3, 5}) H1 [frozenset({3}), frozenset({5})] <br>
  frozenset({5}) —&gt; frozenset({3}) conf: 0.6666666666666666 <br>
  frozenset({3}) —&gt; frozenset({5}) conf: 0.6666666666666666 <br>
  freqSet frozenset({1, 3}) H1 [frozenset({1}), frozenset({3})] <br>
  frozenset({3}) —&gt; frozenset({1}) conf: 0.6666666666666666 <br>
  frozenset({1}) —&gt; frozenset({3}) conf: 1.0 <br>
  freqSet frozenset({2, 5}) H1 [frozenset({2}), frozenset({5})] <br>
  frozenset({5}) —&gt; frozenset({2}) conf: 1.0 <br>
  frozenset({2}) —&gt; frozenset({5}) conf: 1.0 <br>
  freqSet frozenset({2, 3}) H1 [frozenset({2}), frozenset({3})] <br>
  frozenset({3}) —&gt; frozenset({2}) conf: 0.6666666666666666 <br>
  frozenset({2}) —&gt; frozenset({3}) conf: 0.6666666666666666 <br>
  freqSet frozenset({2, 3, 5}) H1 [frozenset({2}), frozenset({3}), frozenset({5})] <br>
  frozenset({5}) —&gt; frozenset({2, 3}) conf: 0.6666666666666666 <br>
  frozenset({3}) —&gt; frozenset({2, 5}) conf: 0.6666666666666666 <br>
  frozenset({2}) —&gt; frozenset({3, 5}) conf: 0.6666666666666666 <br>
  Out[7]: <br>
  [(frozenset({5}), frozenset({3}), 0.6666666666666666), <br>
   (frozenset({3}), frozenset({5}), 0.6666666666666666), <br>
   (frozenset({3}), frozenset({1}), 0.6666666666666666), <br>
   (frozenset({1}), frozenset({3}), 1.0), <br>
   (frozenset({5}), frozenset({2}), 1.0), <br>
   (frozenset({2}), frozenset({5}), 1.0), <br>
   (frozenset({3}), frozenset({2}), 0.6666666666666666), <br>
   (frozenset({2}), frozenset({3}), 0.6666666666666666), <br>
   (frozenset({5}), frozenset({2, 3}), 0.6666666666666666), <br>
   (frozenset({3}), frozenset({2, 5}), 0.6666666666666666), <br>
   (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)]</p>
</blockquote>




<p>这次我们就可以在输出中看见{3} —&gt; {1}了，它的可信度为0.6666666666666666。</p>




<p>到此，有关关联分析的apriori算法就告一段落了。后续还会有有关关联分析FP-growth算法的文章讲解。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/09/19/aprioriyu-guan-lian-fen-xi/">Apriori与关联分析</a>
      <time datetime="2017-09-19T13:33:11+08:00" pubdate><span class='month'>Sep</span> <span class='day'>19</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/09/14/geekde-xie-zuo-fang-shi-latex-ru-men/">Geek的写作方式——LaTeX 入门</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-09-14T21:25:58+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><h1 id="geek的写作方式latex-入门">Geek的写作方式——LaTeX 入门</h1>




<h2 id="有关latex的简介">有关LaTex的简介</h2>




<p>说道LaTex首先要提到<strong>TeX （文本排版系统）</strong>  <br>
TeX是由著名的计算机科学家Donald E. Knuth（高德纳）发明的排版系统，利用TeX可以很容易地生成高质量的dvi文件，打印输出。利用dvips,dvipdfmx,pdfLaTeX等程序生成pdf，ps，文件，LaTeX2html生成html文件。它在学术界十分流行，特别是数学、物理学和计算机科学界。TeX被普遍认为是一个很好的排版工具，特别是在处理复杂的数学公式时。</p>




<p>而LaTeX使用TeX作为它的格式化引擎。 <br>
Leslie Lamport开发的LaTeX是当今世界上最流行和使用最为广泛的TeX宏集。它构筑在Plain TeX的基础之上，并加进了很多的功能以使得使用者可以更为方便的利用TeX的强大功能。使用LaTeX基本上不需要使用者自己设计命令和宏等，因为LaTeX已经替你做好了。因此，即使使用者并不是很了解TeX，也可以在短短的时间内生成高质量的文档。对于生成复杂的数学公式，LaTeX表现的更为出色。</p>




<h2 id="latex的应用">LaTex的应用</h2>




<ol>
<li>使用 (La)TeX进行简单的中英混排；</li>
<li>简单的文章组织结构；</li>
<li>使用 (La)TeX 进行数学公式的排版；</li>
<li>在 (La)TeX 的文档中插入图片/表格；</li>
<li>最常见的带有 TeX 的单词的含义；</li>
</ol>




<h4 id="简单的规则">简单的规则</h4>




<p>为了实现强大的排版能力，LaTex背后定义了一些非常严谨的语法和规则。 <br>
（1）空格：Latex中空格不起作用。 <br>
（2）换行：用控制命令“\”,或“ \newline”. <br>
（3）分段：用控制命令“\par” 或空出一行。 <br>
（4）换页：用控制命令“\newpage”或“\clearpage” <br>
（5）特殊控制字符：#，$, %, &amp;, - ,{, }, ^, ~ <br>
要想输出这些控制符用下列命令：</p>




<blockquote>
  <p>\# <span>\</span>$   \%  \&amp;  \-  \{  \}    \^{}  \~{}    其中 \blackslash 表示“ \”。</p>
</blockquote>




<p>在讲具体如何使用LaTex之前，先给大家推荐一下LaTex在线编辑器方便大家做测试。</p>




<p><a href="http://gongshi.baidu.com/latex.html">kityformula：WEB mathematical formulas projects</a> ，同时项目的Github地址在「<a href="https://github.com/fex-team/kityformula">这里</a>」</p>




<h3 id="尝试第一次中英文排版">尝试第一次中英文排版</h3>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">[</span>UTF8<span class="hljs-special">]</span><span class="hljs-special">{</span>article<span class="hljs-special">}</span>
<span class="hljs-comment">%这里是导言区</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
Blahblahblah... 
你好，世界。etc.
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<p>此处的第一行 \documentclass{article} 中包含了一个控制序列（或称命令/标记）。所谓控制序列，是以反斜杠\开头，以第一个空格或非字母 的字符结束的一串文字，他们并不被输出，但是他们会影响输出文档的效果。这里的控制序列是 documentclass，它后面紧跟着的 {article} 代表这个控制序列有一个必要的参数，该参数的值为 article。这个控制序列的作用，是调用名为 “article” 的文档类。</p>




<p>方括号[]包括的可选参数，这里表示采用UTF-8编码。</p>




<p><strong>请注意，(La)TeX 对控制序列的大小写是敏感的。</strong></p>




<p>此处的第二行以 % 开头。在 TeX 风格的文档中，从 “%” 开始，到该行末尾的所有字符，都会被 TeX 系统无视，只作为供人类阅读的注释。除非在 “%” 前加上反斜杠来取消这一特性。</p>




<h3 id="组织你的文章">组织你的文章</h3>




<h4 id="作者标题日期">作者、标题、日期</h4>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">{</span>article<span class="hljs-special">}</span>
<span class="hljs-command">\title</span><span class="hljs-special">{</span>Cartesian closed categories and the price of eggs<span class="hljs-special">}</span>
<span class="hljs-command">\author</span><span class="hljs-special">{</span>Jane Doe<span class="hljs-special">}</span>
<span class="hljs-command">\date</span><span class="hljs-special">{</span>September 1994<span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
   <span class="hljs-command">\maketitle</span>
   Hello world!
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<h4 id="章节和段落">章节和段落</h4>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">[</span>UTF8<span class="hljs-special">]</span><span class="hljs-special">{</span>ctexart<span class="hljs-special">}</span>
<span class="hljs-command">\title</span><span class="hljs-special">{</span>hello，world!<span class="hljs-special">}</span>
<span class="hljs-command">\author</span><span class="hljs-special">{</span>Liam<span class="hljs-special">}</span>
<span class="hljs-command">\date</span><span class="hljs-special">{</span><span class="hljs-command">\today</span><span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
<span class="hljs-command">\maketitle</span>
<span class="hljs-command">\section</span><span class="hljs-special">{</span>你好，世界<span class="hljs-special">}</span>
Welcome to 中国.
<span class="hljs-command">\subsection</span><span class="hljs-special">{</span>Hello China<span class="hljs-special">}</span>
北京是capital of China.
<span class="hljs-command">\subsubsection</span><span class="hljs-special">{</span>Hello BeiJing<span class="hljs-special">}</span>
<span class="hljs-command">\paragraph</span><span class="hljs-special">{</span>Tian'anmen Square<span class="hljs-special">}</span>
is in the center of Beijing
<span class="hljs-command">\subparagraph</span><span class="hljs-special">{</span>Chairman Mao<span class="hljs-special">}</span>
is in the center of 天安门广场。
<span class="hljs-command">\subsection</span><span class="hljs-special">{</span>Hello 广东<span class="hljs-special">}</span>
<span class="hljs-command">\paragraph</span><span class="hljs-special">{</span>中山大学<span class="hljs-special">}</span> is one of the best university in 广东。
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<p>在文档类 article/ctexart 中，定义了五个控制序列来调整行文组织结构。他们分别是</p>




<ul>
<li>\section{·}</li>
<li>\subsection{·}</li>
<li>\subsubsection{·}</li>
<li>\paragraph{·}</li>
<li>\subparagraph{·}</li>
</ul>




<h4 id="插入目录">插入目录</h4>




<p>在上一节的文档中，找到 \maketitle，在它的下面插入控制序列 \tableofcontents</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">[</span>UTF8<span class="hljs-special">]</span><span class="hljs-special">{</span>ctexart<span class="hljs-special">}</span>
<span class="hljs-command">\title</span><span class="hljs-special">{</span>hello，world!<span class="hljs-special">}</span>
<span class="hljs-command">\author</span><span class="hljs-special">{</span>Liam<span class="hljs-special">}</span>
<span class="hljs-command">\date</span><span class="hljs-special">{</span><span class="hljs-command">\today</span><span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
<span class="hljs-command">\maketitle</span>
<span class="hljs-command">\tableofcontents</span>
<span class="hljs-command">\section</span><span class="hljs-special">{</span>你好，世界<span class="hljs-special">}</span>
Welcome to 中国.
<span class="hljs-command">\subsection</span><span class="hljs-special">{</span>Hello China<span class="hljs-special">}</span>
北京是capital of China.
<span class="hljs-command">\subsubsection</span><span class="hljs-special">{</span>Hello BeiJing<span class="hljs-special">}</span>
<span class="hljs-command">\paragraph</span><span class="hljs-special">{</span>Tian'anmen Square<span class="hljs-special">}</span>
is in the center of Beijing
<span class="hljs-command">\subparagraph</span><span class="hljs-special">{</span>Chairman Mao<span class="hljs-special">}</span>
is in the center of 天安门广场。
<span class="hljs-command">\subsection</span><span class="hljs-special">{</span>Hello 广东<span class="hljs-special">}</span>
<span class="hljs-command">\paragraph</span><span class="hljs-special">{</span>中山大学<span class="hljs-special">}</span> is one of the best university in 广东。
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<h3 id="数学公式排版">数学公式排版</h3>




<p>数学公式排版功能是LaTeX 最为强大的部分。</p>




<h4 id="数学模式">数学模式</h4>




<p>LaTeX 的数学模式有两种：<strong>行内模式 (inline)</strong> 和<strong>行间模式 (display)</strong>。前者在正文的行文中，插入数学公式；后者独立排列单独成行，并自动居中。</p>




<p>在行文中，使用 <script type="math/tex" id="MathJax-Element-77"> ... </script> 可以插入行内公式，使用 [ … ] 可以插入行间公式，如果需要对行间公式进行编号，则可以使用 equation 环境： <br>
<strong>eg：</strong></p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\begin</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span>
...
<span class="hljs-command">\end</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span></code></pre>




<h4 id="上下标">上下标</h4>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">{</span>article<span class="hljs-special">}</span>
<span class="hljs-command">\usepackage</span><span class="hljs-special">{</span>amsmath<span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
Einstein 's <span class="hljs-formula">$E=mc^2$</span>.

<span class="hljs-command">\[</span> E=mc^2. <span class="hljs-command">\]</span>

<span class="hljs-command">\begin</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span>
E=mc^2.
<span class="hljs-command">\end</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span>
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex; mode=display" id="MathJax-Element-149">\begin{equation}
E=mc^2 \\
2H_2+O_2==2H_2O
\end{equation}</script></p>




<p>在数学模式中，需要表示上标，可以使用 ^ 来实现（下标则是 _）。它默认只作用于之后的一个字符，如果想对连续的几个字符起作用，请将这些字符用花括号 {} 括起来。</p>




<h4 id="根式与分式">根式与分式</h4>




<p>根式用 \sqrt{·} 来表示，分式用 \frac{·}{·} 来表示（第一个参数为分子，第二个为分母）。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">{</span>article<span class="hljs-special">}</span>
<span class="hljs-command">\usepackage</span><span class="hljs-special">{</span>amsmath<span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
<span class="hljs-command">\sqrt</span><span class="hljs-special">{</span>x<span class="hljs-special">}</span><span class="hljs-formula">$, $</span><span class="hljs-command">\frac</span><span class="hljs-special">{</span>1<span class="hljs-special">}</span><span class="hljs-special">{</span>2<span class="hljs-special">}</span><span class="hljs-formula">$.
<span class="hljs-command">\[</span> <span class="hljs-command">\sqrt</span><span class="hljs-special">{</span>x<span class="hljs-special">}</span>, <span class="hljs-command">\]</span>
<span class="hljs-command">\[</span> <span class="hljs-command">\frac</span><span class="hljs-special">{</span>1<span class="hljs-special">}</span><span class="hljs-special">{</span>2<span class="hljs-special">}</span>. <span class="hljs-command">\]</span>
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-151">\sqrt{x} \\ \frac{1}{2}</script></p>




<h4 id="运算符号">运算符号</h4>




<p>一些小的运算符，可以在数学模式下直接输入；另一些需要用控制序列生成。 <br>
[ \pm\; \times \; \div\; \cdot\; \cap\; \cup\; <br>
\geq\; \leq\; \neq\; \approx \; \equiv ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-400">[ \pm\; \times \; \div\; \cdot\; \cap\; \cup\;  
\geq\; \leq\; \neq\; \approx \; \equiv ]</script></p>




<p>连加、连乘、极限、积分等大型运算符分别用 \sum, \prod, \lim, \int生成。他们的上下标在行内公式中被压缩，以适应行高。我们可以用 \limits 和 \nolimits 来强制显式地指定是否压缩这些上下标。 <br>
 \sum_{i=1}^n i <br>
 \prod_{i=1}^n  <br>
 \sum\limits <em>{i=1}^n i\quad \prod\limits </em>{i=1}^n  <br>
[ \lim_{x\to0}x^2 \quad \int_a^b x^2 dx ] <br>
[ \lim\nolimits _{x\to0}x^2\quad \int\nolimits_a^b x^2 dx ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-401">\sum_{i=1}^n i</script>  <br>
<script type="math/tex" id="MathJax-Element-402">\prod_{i=1}^n</script> <br>
<script type="math/tex" id="MathJax-Element-403">\sum\limits _{i=1}^n i\quad \prod\limits _{i=1}^n</script> <br>
<script type="math/tex" id="MathJax-Element-404">[ \lim_{x\to0}x^2 \quad \int_a^b x^2 dx ]</script> <br>
<script type="math/tex" id="MathJax-Element-405">[ \lim\nolimits _{x\to0}x^2\quad \int\nolimits_a^b x^2 dx ]</script></p>




<p>多重积分可以使用 \iint, \iiint, \iiiint, \idotsint 等命令输入。 <br>
[ \iint\quad \iiint\quad \iiiint\quad \idotsint ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-406">[ \iint\quad \iiint\quad \iiiint\quad \idotsint ]</script></p>




<h4 id="定界符括号等">定界符（括号等）</h4>




<p>各种括号用 (), [], {}, \langle\rangle 等命令表示； <br>
注意花括号通常用来输入命令和环境的参数，所以在数学公式中它们前面要加 \。</p>




<p>[ \Biggl(\biggl(\Bigl(\bigl((x)\bigr)\Bigr)\biggr)\Biggr) ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-413"> \Biggl(\biggl(\Bigl(\bigl((x)\bigr)\Bigr)\biggr)\Biggr) </script></p>




<h4 id="省略号">省略号</h4>




<p>省略号用 \dots, \cdots, \vdots, \ddots 等命令表示。\dots 和 \cdots 的纵向位置不同，前者一般用于有下标的序列。 <br>
[ x_1,x_2,\dots ,x_n\quad 1,2,\cdots ,n\quad <br>
\vdots\quad \ddots ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-418">  
[ x_1,x_2,\dots ,x_n\quad 1,2,\cdots ,n\quad  
\vdots\quad \ddots ]</script></p>




<h4 id="矩阵">矩阵</h4>




<p>pmatrix, bmatrix, Bmatrix, vmatrix, Vmatrix 等环境可以在矩阵两边加上各种分隔符。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\[</span> <span class="hljs-command">\begin</span><span class="hljs-special">{</span>pmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>pmatrix<span class="hljs-special">}</span> <span class="hljs-command">\quad</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>bmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>bmatrix<span class="hljs-special">}</span> <span class="hljs-command">\quad</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>Bmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>Bmatrix<span class="hljs-special">}</span> <span class="hljs-command">\quad</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>vmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>vmatrix<span class="hljs-special">}</span> <span class="hljs-command">\quad</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>Vmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>Vmatrix<span class="hljs-special">}</span> <span class="hljs-command">\]</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex; mode=display" id="MathJax-Element-649">\begin{pmatrix} a&b\\c&d \end{pmatrix}</script>  <br>
<script type="math/tex; mode=display" id="MathJax-Element-650">\begin{bmatrix} a&b\\c&d \end{bmatrix}</script>  <br>
<script type="math/tex; mode=display" id="MathJax-Element-651">\begin{Bmatrix} a&b\\c&d \end{Bmatrix}</script>  <br>
<script type="math/tex; mode=display" id="MathJax-Element-652">\begin{vmatrix} a&b\\c&d \end{vmatrix}</script>  <br>
<script type="math/tex; mode=display" id="MathJax-Element-653">\begin{Vmatrix} a&b\\c&d \end{Vmatrix}</script></p>




<p>而使用 smallmatrix 环境，可以生成行内公式的小矩阵。</p>




<p><code>( \begin{smallmatrix} a&amp;b\\c&amp;d \end{smallmatrix} )</code> </p>




<p><strong>示例如下：</strong> <br>
this is a little matrix <script type="math/tex" id="MathJax-Element-654"> ( \begin{smallmatrix} a&b\\c&d \end{smallmatrix} ) </script>.</p>




<h4 id="公式组">公式组</h4>




<p>无需对齐的公式组可以使用 gather 环境，需要对齐的公式组可以使用 align 环境。他们都带有编号，如果不需要编号可以使用带星花的版本。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\begin</span><span class="hljs-special">{</span>gather<span class="hljs-special">}</span>
a = b+c+d <span class="hljs-command">\\</span>
x = y+z
<span class="hljs-command">\end</span><span class="hljs-special">{</span>gather<span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>align<span class="hljs-special">}</span>
a <span class="hljs-special">&amp;</span>= b+c+d <span class="hljs-command">\\</span>
x <span class="hljs-special">&amp;</span>= y+z
<span class="hljs-command">\end</span><span class="hljs-special">{</span>align<span class="hljs-special">}</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex; mode=display" id="MathJax-Element-673">\begin{gather}
a = b+c+d \\
x = y+z
\end{gather}</script> <br>
<script type="math/tex; mode=display" id="MathJax-Element-674">\begin{align}
a &= b+c+d \\
x &= y+z
\end{align}</script></p>




<h4 id="分段函数">分段函数</h4>




<p>分段函数可以用cases次环境来实现，它必须包含在数学环境之内。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\begin</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span> y=<span class="hljs-command">\begin</span><span class="hljs-special">{</span>cases<span class="hljs-special">}</span>
-x,<span class="hljs-command">\quad</span> x<span class="hljs-command">\leq</span> 0 <span class="hljs-command">\\</span>
x,<span class="hljs-command">\quad</span> x&gt;0
<span class="hljs-command">\end</span><span class="hljs-special">{</span>cases<span class="hljs-special">}</span>
<span class="hljs-command">\end</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex; mode=display" id="MathJax-Element-730">\begin{equation} y=\begin{cases}
-x,\quad x\leq 0 \\
x,\quad x>0
\end{cases}
\end{equation}</script></p>




<h3 id="插入图表">插入图表</h3>




<p>在LaTeX文档中插入图片都是通过使用一些latex图形处理宏命令来实现的, 有很多宏命令都支持在在LaTeX文档中插入eps格式的图形文件, 主要有: <br>
（1）用includegraphics宏命令(graphicx包)  <br>
（2）用psfig宏命令 <br>
（3）用epsfig宏命令  <br>
（4）用epsf宏命令 <br>
由于插入图片较为麻烦，且不如Markdown语法方便，这里就略过了。有兴趣的朋友可以自行查询下命令的使用方法。</p>




<h4 id="表格">表格</h4>




<p>tabular 环境提供了最简单的表格功能。它用 \hline 命令表示横线，在列格式中用 | 表示竖线；用 &amp; 来分列，用 \\ 来换行；每列可以采用居左、居中、居右等横向对齐方式，分别用 l、c、r 来表示。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\begin</span><span class="hljs-special">{</span>tabular<span class="hljs-special">}</span><span class="hljs-special">{</span>|l|c|r|<span class="hljs-special">}</span>
 <span class="hljs-command">\hline</span>
OS<span class="hljs-special">&amp;</span> Release<span class="hljs-special">&amp;</span> Editor<span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
Windows <span class="hljs-special">&amp;</span> MikTeX <span class="hljs-special">&amp;</span> TexMakerX <span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
Unix/Linux <span class="hljs-special">&amp;</span> teTeX <span class="hljs-special">&amp;</span> Kile <span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
Mac OS <span class="hljs-special">&amp;</span> MacTeX <span class="hljs-special">&amp;</span> TeXShop <span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
通用<span class="hljs-special">&amp;</span> TeX Live <span class="hljs-special">&amp;</span> TeXworks <span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
<span class="hljs-command">\end</span><span class="hljs-special">{</span>tabular<span class="hljs-special">}</span></code></pre>




<p><strong>示例如下：</strong></p>




<table>
<thead>
<tr>
  <th align="center">OS</th>
  <th>Release</th>
  <th>Editor</th>
</tr>
</thead>
<tbody><tr>
  <td align="center">Windows</td>
  <td>MikTeX</td>
  <td>TexMakerX</td>
</tr>
<tr>
  <td align="center">Unix/Linux</td>
  <td>teTeX</td>
  <td>Kile</td>
</tr>
<tr>
  <td align="center">Mac OS</td>
  <td>MacTeX</td>
  <td>TeXShop</td>
</tr>
<tr>
  <td align="center">通用</td>
  <td>TeX LIve</td>
  <td>TeXworks</td>
</tr>
</tbody></table>




<h3 id="其他">其他</h3>




<p>到目前为止，常用的(La)Tex常用的功能已经介绍的基本差不多了。 <br>
当然，除此之外，(La)Tex还有一些版面设置，以及常用字母符号输入等功能。 <br>
例如我们常用的希腊字母</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\alpha</span> <span class="hljs-command">\beta</span> <span class="hljs-command">\gamma</span> <span class="hljs-command">\theta</span><span class="hljs-command">\omega</span> <span class="hljs-command">\mu</span> <span class="hljs-command">\pi</span> <span class="hljs-command">\dots</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-844">\alpha \beta \gamma \theta\omega \mu \pi \dots</script></p>




<p>到此文章基本结束了，但依旧还有十分多的功能（不常用）没有在此文提及。有兴趣的朋友可以自行查询<a href="http://texdoc.net/texmf-dist/doc/latex/latex2e-help-texinfo/latex2e.pdf">LaTex相关手册</a>。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/09/14/geekde-xie-zuo-fang-shi-latex-ru-men/">Geek的写作方式——LaTeX 入门</a>
      <time datetime="2017-09-14T21:25:58+08:00" pubdate><span class='month'>Sep</span> <span class='day'>14</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-zhu-za-tan/'>技术杂谈</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/09/09/ru-he-zai-pythonzhong-shi-xian-jue-ce-shu-suan-fa/">如何在Python中实现决策树算法</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-09-09T15:33:50+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><h1 id="如何在python中实现决策树算法">如何在Python中实现决策树算法</h1>




<p>决策树算法是一种简单的预测算法，但正是因为它模型的简单性，常作为一些高级的组合算法的基础，例如<strong>bagging，random forests ，gradient boosting</strong> 等等。再者，由于决策树的最终模型和预估行为具有较强的业务相关与可解析性，使得它十分受从业者与领域专家的欢迎，在各行各业中也有十分多的应用。</p>




<h4 id="决策树的优缺点">决策树的优缺点</h4>




<p>优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据</p>




<p>缺点：可能会产生过拟合问题</p>




<h2 id="决策树的构建">决策树的构建</h2>




<p>在构建决策树之前，我们首先要明确的第一个问题就是：在当前的数据集上哪个特征在划分数据分类时起决定性作用。而其中划分数据集的最大原则就是：<strong><em>将无序的数据变得更加有序。</em></strong></p>




<p>在选择如何去划分数据集的时候，我们可以采用各种不同的方法。但是每种方法都有各自的优缺点。组织杂乱无章的数据的一种方法就是使用信息论度量信息。</p>




<p>在划分数据集之前之后信息发生的变化称为<strong>信息增益</strong>，而获得信息增益最高的特征就是我们用于划分数据的最好选择。</p>




<p>在评测哪种数据划分方式是最好的数据划分之前，我们必须学习如何计算信息增益，而为了能够计算和理解信息增益，我们又必须先了解一个概念，即：集合信息的度量方式，其被称为<strong>香农熵</strong>或简称<strong>熵</strong>。这个名字来源于信息论之父<a href="https://baike.baidu.com/item/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E8%89%BE%E5%B0%94%E4%BC%8D%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C/10588593?fr=aladdin&amp;fromid=1146248&amp;fromtitle=%E9%A6%99%E5%86%9C">克劳德×香农</a></p>




<p>熵：被定义为信息的<strong>期望值</strong>，如果一个事件发生的概率是<script type="math/tex" id="MathJax-Element-1">p(x)</script>,则其信息熵为:</p>




<blockquote>
  <p><script type="math/tex" id="MathJax-Element-2">H(X)=-\sum _{i=i}^n p(x_i) \log  \left (p (x_i)\right)</script></p>
  
  <p>Eg:<img src="http://www.saedsayad.com/images/Entropy_3.png" alt="enter image description here" title=""></p>
</blockquote>




<p>其中n是分类的数目。</p>




<p>可以这样验证一下：如果这件事发生的概率是1，其信息熵<script type="math/tex" id="MathJax-Element-3">H</script>则等于0，因为你知道他一定会发生，丝毫不会觉得惊喜;但是如果这件事的概率趋向于无穷小，比如国足夺得世界杯冠军，那么他的信息熵就会趋向于无穷大。就像你心中听完上一条信息之后，心中可能就有数十万只草泥马奔过一样。</p>




<h4 id="使用python计算信息的熵">使用Python计算信息的熵</h4>




<p>下面我们将以《机器学习实战》一书中给出的例子为基础进一步探讨本文所讲内容。</p>




<blockquote>
  <p><strong>海洋生物数据表</strong></p>
  
  <table>
<thead>
<tr>
  <th>index</th>
  <th>不浮出水面是否可以生存</th>
  <th>是否有脚蹼</th>
  <th>是否属于鱼类</th>
</tr>
</thead>
<tbody><tr>
  <td>0</td>
  <td>是</td>
  <td>是</td>
  <td>是</td>
</tr>
<tr>
  <td>1</td>
  <td>是</td>
  <td>是</td>
  <td>是</td>
</tr>
<tr>
  <td>2</td>
  <td>是</td>
  <td>否</td>
  <td>否</td>
</tr>
<tr>
  <td>3</td>
  <td>否</td>
  <td>是</td>
  <td>否</td>
</tr>
<tr>
  <td>4</td>
  <td>否</td>
  <td>是</td>
  <td>否</td>
</tr>
</tbody></table>

</blockquote>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#coding:utf-8</span>
</span><span class='line'><span class="c"># 代码功能：计算香农熵，本代码来源于书籍《机器学习实战》</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">log</span> <span class="c">#我们要用到对数函数，所以我们需要引入math模块中定义好的log函数（对数函数）</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">calcShannonEnt</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span><span class="c">#传入数据集</span>
</span><span class='line'><span class="c"># 在这里dataSet是一个链表形式的的数据集</span>
</span><span class='line'>    <span class="n">countDataSet</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span> <span class="c"># 我们计算出这个数据集中的数据个数，在这里我们的值是5个数据集</span>
</span><span class='line'>    <span class="n">labelCounts</span><span class="o">=</span><span class="p">{}</span> <span class="c"># 构建字典，用键值对的关系我们表示出 我们数据集中的类别还有对应的关系</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">featVec</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">:</span> <span class="c">#通过for循环，我们每次取出一个数据集，如featVec=[1,1,&#39;yes&#39;]</span>
</span><span class='line'>        <span class="n">currentLabel</span><span class="o">=</span><span class="n">featVec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c"># 取出最后一列 也就是类别的那一类，比如说‘yes’或者是‘no’</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">currentLabel</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">labelCounts</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>            <span class="n">labelCounts</span><span class="p">[</span><span class="n">currentLabel</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="n">labelCounts</span><span class="p">[</span><span class="n">currentLabel</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">shannonEnt</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c"># 计算香农熵， 根据公式</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">labelCounts</span><span class="p">:</span>
</span><span class='line'>        <span class="n">prob</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">labelCounts</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="o">/</span><span class="n">countDataSet</span>
</span><span class='line'>        <span class="n">shannonEnt</span> <span class="o">-=</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">shannonEnt</span>
</span><span class='line'><span class="k">def</span> <span class="nf">createDataSet</span><span class="p">():</span>
</span><span class='line'>    <span class="n">dataSet</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;yes&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;yes&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="s">&#39;no&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;no&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;no&#39;</span><span class="p">]]</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;no surfacing&#39;</span><span class="p">,</span><span class="s">&#39;flippers&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">dataSet</span><span class="p">,</span> <span class="n">labels</span>
</span><span class='line'>
</span><span class='line'><span class="n">myDat</span><span class="p">,</span><span class="n">labels</span> <span class="o">=</span> <span class="n">createDataSet</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span class='line'><span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果: <br>
  [[1, 1, ‘yes’], [1, 1, ‘yes’], [1, 0, ‘no’], [0, 1, ‘no’], [0, 1, ‘no’]] <br>
  [‘no surfacing’, ‘flippers’] <br>
  0.9709505944546686</p>
</blockquote>




<p>其中，香农熵越高，则代表混合的数据越多，这点我们可以通过在数据集中添加更多的分类来验证。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">myDat</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="s">&#39;maybe&#39;</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span><span class='line'><span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果: <br>
  [[1, 1, ‘maybe’], [1, 1, ‘yes’], [1, 0, ‘no’], [0, 1, ‘no’], [0, 1, ‘no’]] <br>
  1.3709505944546687</p>
</blockquote>




<h4 id="划分数据集">划分数据集</h4>




<p>分类算法除了需要测量信息熵之外，还需要划分数据集，度量划分数据集的熵，以便判断当前是否正确地划分了数据集。</p>




<p>那么，我们如何确定目前划分数据的方法是否就是最优的划分方法呢？答案就是：<strong>信息增益</strong>。我们仅需选择使得划分后数据集信息增益最大的特征作为分类的最佳特征即可。</p>




<p>首先假设我们选取了第一个特征<strong>“是否需要浮出水面生存”</strong>的第一种可能<strong>“是”</strong>来划分数据集，我们得到划分之后的数据集就是：</p>




<blockquote>
  <p>[[1, 1, ‘maybe’], [1, 1, ‘yes’], [1, 0, ‘no’]</p>
</blockquote>




<p><strong>“否”</strong>的话，得到的划分集则是：</p>




<blockquote>
  <p>[[0, 1, ‘no’], [0, 1, ‘no’]]</p>
</blockquote>




<p>其他特征的划分方式也以此类推。</p>




<p>知道如何划分数据集之后，让我们来构建我们下一步的数据划分代码。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># 代码功能：划分数据集</span>
</span><span class='line'><span class="k">def</span> <span class="nf">splitDataSet</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">axis</span><span class="p">,</span><span class="n">value</span><span class="p">):</span> <span class="c">#传入三个参数第一个参数是我们的数据集，是一个链表形式的数据集；第二个参数是我们的要依据某个特征来划分数据集</span>
</span><span class='line'>    <span class="n">retDataSet</span> <span class="o">=</span> <span class="p">[]</span> <span class="c">#由于参数的链表dataSet我们拿到的是它的地址，也就是引用，直接在链表上操作会改变它的数值，所以我们新建一格链表来做操作</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">featVec</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">:</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">featVec</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="p">:</span> <span class="c">#如果某个特征和我们指定的特征值相等</span>
</span><span class='line'>        <span class="c">#除去这个特征然后创建一个子特征</span>
</span><span class='line'>            <span class="n">reduceFeatVec</span> <span class="o">=</span> <span class="n">featVec</span><span class="p">[:</span><span class="n">axis</span><span class="p">]</span>
</span><span class='line'>            <span class="n">reduceFeatVec</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">featVec</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
</span><span class='line'>            <span class="c">#将满足条件的样本并且经过切割后的样本都加入到我们新建立的样本中</span>
</span><span class='line'>            <span class="n">retDataSet</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduceFeatVec</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">retDataSet</span>
</span></code></pre></td></tr></table></div></figure>




<p>下面来测试下我们的代码</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">splitDataSet</span><span class="p">(</span><span class="n">myDat</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>[Out] [[1, ‘maybe’], [1, ‘yes’], [0, ‘no’]]</p>
</blockquote>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">splitDataSet</span><span class="p">(</span><span class="n">myDat</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>[Out]  [[1, ‘no’], [1, ‘no’]]</p>
</blockquote>




<p>知道怎么划分数据集之后，我们接下来要做的就是遍历整个数据集的特征值，然后循环计算熵，找出最好的分类特征了。</p>




<h4 id="选择最好的数据划分方式">选择最好的数据划分方式</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">chooseBestFeatureToSplit</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span>
</span><span class='line'>    <span class="n">numFeatures</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span>
</span><span class='line'>    <span class="n">baseEntropy</span> <span class="o">=</span> <span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
</span><span class='line'>    <span class="n">bestInfoGain</span> <span class="o">=</span><span class="mf">0.0</span>
</span><span class='line'>    <span class="n">bestFeature</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numFeatures</span><span class="p">):</span>
</span><span class='line'>        <span class="n">featList</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">]</span>
</span><span class='line'>        <span class="n">uniqueVals</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">featList</span><span class="p">)</span>
</span><span class='line'>        <span class="n">newEntropy</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">uniqueVals</span><span class="p">:</span>
</span><span class='line'>            <span class="n">subDataSet</span> <span class="o">=</span> <span class="n">splitDataSet</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">value</span><span class="p">)</span>
</span><span class='line'>            <span class="n">prob</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">subDataSet</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">))</span>
</span><span class='line'>            <span class="n">newEntropy</span> <span class="o">+=</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">subDataSet</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">infoGain</span> <span class="o">=</span> <span class="n">baseEntropy</span> <span class="o">-</span> <span class="n">newEntropy</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">if</span><span class="p">(</span><span class="n">infoGain</span> <span class="o">&gt;</span> <span class="n">bestInfoGain</span><span class="p">):</span>
</span><span class='line'>            <span class="n">bestInfoGain</span> <span class="o">=</span> <span class="n">infoGain</span>
</span><span class='line'>            <span class="n">bestFeature</span> <span class="o">=</span> <span class="n">i</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">bestFeature</span>
</span></code></pre></td></tr></table></div></figure>




<p>这里的choseBestFeatureToSplit()函数的使用是需要满足一定条件的： <br>
1.  数据必须是一种有列表元素组成的列表，而且所有的列表元素都要具有相同的数据长度。 <br>
2. 数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签 </p>




<p>接下来，我们来运行choseBestFeatureToSplit()函数来计算出最佳分类特征。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">chooseBestFeatureToSplit</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>[Out] 0</p>
</blockquote>




<p>从这里我们可以得到第0个特征是最好用于划分数据集的特征。确实，这个分类特征的选择就我们目测而言也是最好的选择。</p>




<p>知道如何选取特征之后，下一步我们就要如何将上面的函数有机结合在一起构建出决策树。</p>




<h4 id="处理特殊情况">处理特殊情况</h4>




<p>工作原理： <br>
1.  得到原始数据集 <br>
2. 基于最好的属性值划分数据集 <br>
3.  由于特征值不止一个，将划分后的数据传递到树分支的下一个节点，再重复2操作 <br>
4. 程序遍历完所有划分数据集属性或每个分支下所有实例都具有相同分类后结束</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">majorityCnt</span><span class="p">(</span><span class="n">classList</span><span class="p">):</span> <span class="c"># 传入的参数是已经划分完所有特征之后剩余的数据集，</span>
</span><span class='line'>    <span class="c">#例如[[&#39;yes&#39;],[&#39;yes&#39;],[&#39;maybe&#39;]]</span>
</span><span class='line'>    <span class="n">classCount</span><span class="o">=</span><span class="p">{}</span> <span class="c">#创建一个字典</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">vote</span> <span class="ow">in</span> <span class="n">classList</span><span class="p">:</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">vote</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">classCount</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>            <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>        <span class="c"># 根据上述的语句，以及我们的例子，我们最终可以得到的结果如下： {&#39;yes&#39;:2,&#39;maybe&#39;:1}</span>
</span><span class='line'>        <span class="n">sortedClassCount</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">classCount</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="n">operator</span><span class="o">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="c">#这个语句比较复杂，我们在下面详细讲解一下。</span>
</span><span class='line'><span class="c"># 使用字典iteritems</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">sortedClassCount</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>




<p>这里的majorityCnt()函数是为了处理<strong>特殊分类</strong>而存在的。我们知道如果根据特征来划分属性，每划分一次就会消耗一个特征，如果我们使用完了所有的特征但是类别还没有划分完那我们就可以采用多数表决的方法来确定叶子节点了。</p>




<p>在上面的代码中，我们发现最后我们用排序函数对剩余的类作了降序处理，并只返回了分类个数最多的元素的那个类。这是一种折中的方法，因为对于一些已经使用完特征的数据集，我们不可能清楚地将一些类分离出来，我们就只能统计其中数量最多的那个分类，以次划分。</p>




<h4 id="递归构建决策树">递归构建决策树</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">createTree</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">labels</span><span class="p">):</span>
</span><span class='line'>    <span class="n">classList</span> <span class="o">=</span> <span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="n">classList</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="nb">len</span> <span class="p">(</span><span class="n">classList</span><span class="p">):</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">majorityCnt</span><span class="p">(</span><span class="n">classList</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">bestFeat</span> <span class="o">=</span> <span class="n">chooseBestFeatureToSplit</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
</span><span class='line'>    <span class="n">bestFeatLabel</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">bestFeat</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">myTree</span> <span class="o">=</span> <span class="p">{</span><span class="n">bestFeatLabel</span><span class="p">:{}}</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">del</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">bestFeatL</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">featValues</span> <span class="o">=</span> <span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="n">bestFeat</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">uniqueVals</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">featValues</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">uniqueVals</span><span class="p">:</span>
</span><span class='line'>        <span class="n">subLabels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:]</span>
</span><span class='line'>        <span class="n">myTree</span><span class="p">[</span><span class="n">bestFeatLabel</span><span class="p">][</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">createTree</span><span class="p">(</span><span class="n">splitDataSet</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">bestFeat</span><span class="p">,</span><span class="n">value</span><span class="p">),</span><span class="n">subLabels</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">myTree</span>
</span></code></pre></td></tr></table></div></figure>




<p>最后，我们来运行我们的代码来构建出一棵决策树看看。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">createTree</span><span class="p">(</span><span class="n">myDat</span><span class="p">,</span><span class="n">labels</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  [‘no surfacing’, ‘flippers’] <br>
  0 <br>
  no surfacing <br>
  [‘flippers’] <br>
  0 <br>
  flippers <br>
  {‘no surfacing’: {0: ‘no’, 1: {‘flippers’: {0: ‘no’, 1: ‘yes’}}}}</p>
</blockquote>




<p>根据返回的结果，我们可以画出以下的决策树。 <br>
<img src="https://i.loli.net/2017/09/09/59b397d98b6e3.png" alt="dt.png" title=""></p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/09/09/ru-he-zai-pythonzhong-shi-xian-jue-ce-shu-suan-fa/">如何在Python中实现决策树算法</a>
      <time datetime="2017-09-09T15:33:50+08:00" pubdate><span class='month'>Sep</span> <span class='day'>09</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/09/05/laplacebian-huan/">Laplace变换</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-09-05T21:20:57+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><h1 id="拉普拉斯变换">拉普拉斯变换</h1>




<p>对于复值函数<script type="math/tex" id="MathJax-Element-1978">f(t)</script>,若<script type="math/tex" id="MathJax-Element-1979">\int_0^{\infty } f(t) \epsilon ^{-s t} \, dt</script>在复平面上的某一个区域<script type="math/tex" id="MathJax-Element-1980">D(s\in D)</script> 内收敛于<script type="math/tex" id="MathJax-Element-1981">F(s)</script>,则称：</p>




<p><script type="math/tex" id="MathJax-Element-1982">F(s)=\int_0^{\infty } f(t) \epsilon ^{-s t} \, dt</script></p>




<p>为函数的拉普拉斯变换（Laplace）变换（简称拉氏变换），记为</p>




<p><script type="math/tex" id="MathJax-Element-1983">F(s)=L[f(t)]</script></p>




<p>在科技领域，一般是对时间为自变量的函数进行拉普拉斯变换，即在t &lt; 0时，函数无意义或不需要考虑。</p>




<h3 id="线性性质">线性性质</h3>




<p>设<script type="math/tex" id="MathJax-Element-893">\alpha _1,\alpha _2</script>为常数， <br>
<script type="math/tex" id="MathJax-Element-894">F_1(s) = L[f_1(t)] , F_2(s) = L[f_2(t)] </script> 则  <br>
<script type="math/tex" id="MathJax-Element-895"> L[\alpha _1f_1(t) + \alpha _2f_2(t)] = \alpha_1F_1(s) + \alpha_2F_2(s)</script></p>




<h3 id="时移性质">时移性质</h3>




<p>若 <script type="math/tex" id="MathJax-Element-905">L[f(t)] = F(s)</script>，对于<script type="math/tex" id="MathJax-Element-906">t_0 > 0</script>，有<script type="math/tex" id="MathJax-Element-907">L[f( t-t_0 )] = e^{-st_0} F(s)</script></p>




<h3 id="频移性质">频移性质</h3>




<p>若 <script type="math/tex" id="MathJax-Element-947">L[f(t)] = F(s)</script>，则对任意常数a，有 <br>
<script type="math/tex" id="MathJax-Element-948">L[e^{at}f(t)] = F(s-a)</script></p>




<h3 id="微分性质">微分性质</h3>




<p>若 <script type="math/tex" id="MathJax-Element-1369">L[f(t)] = F(s)</script>，且<script type="math/tex" id="MathJax-Element-1370">f'(t)也是象原函数，则</script> <br>
<script type="math/tex" id="MathJax-Element-1371">L[f'(t)] = sF(s) - f(0^+)</script> <br>
这里，<script type="math/tex" id="MathJax-Element-1372"> \lim_{t\to 0^+}f( t)</script></p>




<p>若 <script type="math/tex" id="MathJax-Element-1373">L[f(t)] = F(s)</script>，则 <br>
<script type="math/tex" id="MathJax-Element-1374">L[ (-t)^n f(t)] = F^{(n)}(s) , n=0,1,2,...</script></p>




<h3 id="积分性质">积分性质</h3>




<p>若 <script type="math/tex" id="MathJax-Element-1631">L[f(t)] = F(s)</script>，则 <br>
<script type="math/tex" id="MathJax-Element-1632">L[\int_0^t f(\tau ) \, d\tau] = \frac{1}{s}F(s)</script></p>




<p>若 <script type="math/tex" id="MathJax-Element-1633">L[f(t)] = F(s)</script>，积分<script type="math/tex" id="MathJax-Element-1634">\int_s^\infty F(u ) \, du</script>收敛，则<script type="math/tex" id="MathJax-Element-1635">\frac{f(t)}{t}</script>的拉普拉斯变换存在，且</p>




<p><script type="math/tex" id="MathJax-Element-1636">L[\frac{f(t)}{t}] = \int_s^\infty F(u ) \, du</script></p>




<h3 id="极限性质">极限性质</h3>




<p>1.初值关系 <br>
若<script type="math/tex" id="MathJax-Element-1973">L[f(t)] = F(s)</script>，则<script type="math/tex" id="MathJax-Element-1974">f(0^+) =  \lim_{s\to \infty} sF( s)</script></p>




<p>2.终值关系 <br>
若<script type="math/tex" id="MathJax-Element-1975">L[f(t)] = F(s),且f(+\infty)存在,sF(s)</script>的所有奇点在半平面<script type="math/tex" id="MathJax-Element-1976">Re(s) < \sigma _0内，其中\sigma是f(t)的增长指数</script>，则</p>




<p><script type="math/tex" id="MathJax-Element-1977">f(+\infty) = lim_{s\to0}sF(s)</script></p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/09/05/laplacebian-huan/">Laplace变换</a>
      <time datetime="2017-09-05T21:20:57+08:00" pubdate><span class='month'>Sep</span> <span class='day'>05</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ke-cheng-bi-ji/'>课程笔记</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/09/03/ru-he-gou-jian-%5B%3F%5D-ge-po-su-bei-xie-si-fen-lei-qi/">如何构建一个朴素贝叶斯分类器</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-09-03T13:22:23+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><h1 id="如何构建一个朴素贝叶斯分类器">如何构建一个朴素贝叶斯分类器</h1>




<h3 id="概念">概念</h3>




<p><strong>朴素贝叶斯分类</strong>是一些使用概率论来进行分类的方法中的一种代表。之所以成为为<strong>朴素</strong>，是因为整个形式化过程只做了最原始，最简单的假设。其具体表现为：在分类过程中，我们都假设为特征条件都是<strong>相互独立</strong>的，不互相构成影响。而贝叶斯即说明该方法是基于贝叶斯定理的。</p>




<p>朴素贝叶斯是贝叶斯决策理论的一部分，对比其他分类方法而言，其<strong>优点</strong>有：在数据较少的情况下仍然有效，并且可以处理多类别的问题，而不仅仅是二分类。<strong>但</strong>也存在对输入数据的准备方式较为敏感的缺点。</p>




<h3 id="目前在各方面的应用">目前在各方面的应用</h3>




<ol>
<li>垃圾邮件分类，即著名的贝叶斯过滤器</li>
<li>文本自动归类</li>
<li>文本情感的分析，话题分析。</li>
</ol>




<h3 id="核心思想">核心思想</h3>




<p><img src="https://i.loli.net/2017/09/02/59aa6f0d7afce.png" alt="beyas.png" title=""></p>




<p>现在假设我们有一张如上所示的两类数据的统计参数。 <br>
我们现在用p1(x,y)来表示数据点(x,y)属于类别X（图中的蓝点）的概率，用p2(x,y)表示数据点属于类别Y（图中的黄点）的概率。那么对于一个新的数据点(x,y)，我们可以用以下的规则来判断它的类别：</p>




<ul>
<li><script type="math/tex" id="MathJax-Element-24">If p1(x,y) > p2(x,y) then (x,y) -> X</script></li>
<li><script type="math/tex" id="MathJax-Element-25">If p2(x,y) > p1(x,y) then (x,y) -> Y</script></li>
</ul>




<p>也就是说，我们更倾向于选择高概率所对应的类别。这就是<strong>贝叶斯决策理论</strong>的核心思想。用一句话总结即：选择具有最高概率的决策。</p>




<h3 id="使用条件概率进行分类">使用条件概率进行分类</h3>




<p>从上面的推理我们得到两个分类准则：</p>




<ul>
<li><script type="math/tex" id="MathJax-Element-61">If p1(x,y) > p2(x,y) then (x,y) -> X</script></li>
<li><script type="math/tex" id="MathJax-Element-62">If p2(x,y) > p1(x,y) then (x,y) -> Y</script></li>
</ul>




<p>但是，这两个准则只是为了简化描述整个分类问题，而真正来说，在使用贝叶斯方法进行分类时，我们需要计算和比较的应该是 p(X|x,y) 和 p(Y|x,y) ，它们所代表的意义是：在给定某个由（x，y）表示的数据点之后，它来自X类别的概率和它来自Y类别的概率分别是多少？知道这点之后，我们来重新定义我们的分类准则：</p>




<ul>
<li><script type="math/tex" id="MathJax-Element-63">If P(X|x,y) > P(Y|x,y) then (x,y) -> X</script></li>
<li><script type="math/tex" id="MathJax-Element-64">If P(X|x,y) < P(Y|x,y) then (x,y) -> Y</script></li>
</ul>




<p>然后，我们可以再通过贝叶斯公式的转换把未知的概率用已知的概率计算出来。</p>




<p><strong>使用实例：垃圾邮件判别</strong> <br>
首先，我们假设有以下的统计数据：</p>




<ul>
<li>在74封电子邮件中，有30封为垃圾邮件。</li>
<li>在以上的74封电子邮件中，有51封邮件包含“sex”一词。</li>
<li>其中，20封包含了“sex”一词的邮件被认为是垃圾邮件。</li>
</ul>




<p>知道了以上这些简单的前提条件之后，我们可以尝试通过贝叶斯方法来求解我们下一封收到包含“sex”一词的邮件是垃圾邮件的概率是多少？</p>




<p><script type="math/tex" id="MathJax-Element-65">P (\text{spam}|\text{sex})=\frac{P(spam) * P  (\text{sex}|\text{spam})}{P (\text{sex})}=\frac {(20\div30)* (30\div74)} {51\div74} =\frac{20}{51}=0.39</script></p>




<p>其中，公式中的<strong>spam</strong>代表垃圾邮件的意思（1937年7月5日，美国罐头肉制造商Jay Hormel发布以其名字命名的「Hormel Spiced Ham（荷美尔香料火腿）」，后来通过命名比赛改名为 SPAM(Spiced Pork and Ham)，有添加香料（Spices）的猪肉火腿罐头。至于为何 SPAM演变成垃圾邮件呢？有一说法是源于一部英国喜剧团（Monty Python）曾在一出讽刺剧「spam-loving vikings（爱吃肉罐头的维京人），剧中有对夫妻去餐厅用餐，妻子不想吃SPAM罐头，可是在餐厅里有一大群人，高声地唱讼赞美「SPAM」称颂肉罐头的美味多达120次，让其他的用餐客人无可奈何。从此 SPAM就成为「重复、毫无益处、喧宾夺主、令人厌烦邮件」的代名词。就像当年经济萧条，人们买不起鲜肉，而吃的SPAM 肉罐头一样,没有营养成分。）</p>




<p>上面我们得出了一个词对整篇文章的分类判断情况，接下来我们可以进一步扩展这个问题，通过再增加以下为已知前提：</p>




<ul>
<li>25封邮件包含“money”一词，而其中24封被认为是垃圾邮件。</li>
</ul>




<p>那么现在当收到一封同时包含“sex”，“money”这两个词的邮件，它为垃圾邮件的可能性又有多大呢？</p>




<p><script type="math/tex" id="MathJax-Element-66">\frac{P(\text{spam}) P(\text{money}|\text{spam}) P(\text{sex}|\text{spam}\cap  
   \text{money})}{P(\text{money}) P(\text{sex}|\text{monry})}</script></p>




<p>写到这里我们发现，当我们不断增加相关词进行判定时，上述的贝叶斯推理公式也将越来越复杂。这时，就要开始应用朴素思想了，我们假设“sex”和“money”两者出现的事件都相互独立（虽然现实情况往往并不是这样的，当出现一些广告相关的词词语时，“金钱”一词往往就有很大的几率出现在后文，但这里采用朴素的思想来近似在分类上也足够准确了），这样我们就可以把上面的公式简化成：</p>




<p><script type="math/tex" id="MathJax-Element-67">P(\text{spam}|\text{money},\text{sex})=\frac{P(\text{spam})  
   P(\text{money}|\text{spam}) P(\text{sex}|\text{spam})}{p(\text{money})  
   P(\text{sex})}</script></p>




<p>这样，假如我们需要对一封收到的电子邮件进行分类的话，我们只要计算出在给出邮件内的词汇的情况下，它为一封垃圾邮件的条件概率即可。当然，这里存在的一个较大的缺陷就是，当一些词语极度相关时，而我们通过假设他们相互独立计算出来的概率可能并不是那么准确。</p>




<h3 id="分类实现">分类实现</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># -*- encoding : utf-8 -*-</span>
</span><span class='line'><span class="k">class</span> <span class="nc">BeyesClassifier</span><span class="o">::</span><span class="no">Base</span>
</span><span class='line'>  <span class="kp">extend</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">Storage</span><span class="o">::</span><span class="no">ActAsStorable</span>
</span><span class='line'>  <span class="kp">attr_reader</span> <span class="ss">:name</span>
</span><span class='line'>  <span class="kp">attr_reader</span> <span class="ss">:word_list</span>
</span><span class='line'>  <span class="kp">attr_reader</span> <span class="ss">:category_list</span>
</span><span class='line'>  <span class="kp">attr_reader</span> <span class="ss">:training_count</span>
</span><span class='line'>
</span><span class='line'>  <span class="kp">attr_accessor</span> <span class="ss">:tokenizer</span>
</span><span class='line'>  <span class="kp">attr_accessor</span> <span class="ss">:language</span>
</span><span class='line'>
</span><span class='line'>  <span class="kp">attr_accessor</span> <span class="ss">:thresholds</span>
</span><span class='line'>  <span class="kp">attr_accessor</span> <span class="ss">:min_prob</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>  <span class="n">storable</span> <span class="ss">:version</span><span class="p">,</span><span class="ss">:word_list</span><span class="p">,</span><span class="ss">:category_list</span><span class="p">,</span><span class="ss">:training_count</span><span class="p">,</span><span class="ss">:thresholds</span><span class="p">,</span><span class="ss">:min_prob</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># opts :</span>
</span><span class='line'>  <span class="c1"># language</span>
</span><span class='line'>  <span class="c1"># stemming : true | false</span>
</span><span class='line'>  <span class="c1"># weight</span>
</span><span class='line'>  <span class="c1"># assumed_prob</span>
</span><span class='line'>  <span class="c1"># storage</span>
</span><span class='line'>  <span class="c1"># purge_state ?</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="nb">name</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="p">{})</span>
</span><span class='line'>    <span class="vi">@version</span> <span class="o">=</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">VERSION</span>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@name</span> <span class="o">=</span> <span class="nb">name</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># This values are nil or are loaded from storage</span>
</span><span class='line'>    <span class="vi">@word_list</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@category_list</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@training_count</span><span class="o">=</span><span class="mi">0</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># storage</span>
</span><span class='line'>    <span class="n">purge_state</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:purge_state</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@storage</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:storage</span><span class="o">]</span> <span class="o">||</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">Base</span><span class="o">.</span><span class="n">storage</span>
</span><span class='line'>    <span class="k">unless</span> <span class="n">purge_state</span>
</span><span class='line'>      <span class="vi">@storage</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="nb">self</span><span class="p">)</span>
</span><span class='line'>    <span class="k">else</span>
</span><span class='line'>      <span class="vi">@storage</span><span class="o">.</span><span class="n">purge_state</span><span class="p">(</span><span class="nb">self</span><span class="p">)</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># This value can be set during initialization or overrided after load_state</span>
</span><span class='line'>    <span class="vi">@thresholds</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:thresholds</span><span class="o">]</span> <span class="o">||</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@min_prob</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:min_prob</span><span class="o">]</span> <span class="o">||</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@ignore_words</span> <span class="o">=</span> <span class="kp">nil</span>
</span><span class='line'>    <span class="vi">@tokenizer</span> <span class="o">=</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">Tokenizer</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">incr_word</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">]</span> <span class="o">||=</span> <span class="p">{}</span>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">]</span> <span class="o">||=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">][</span><span class="n">category</span><span class="o">]</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">][</span><span class="n">category</span><span class="o">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># words count by categroy</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">]</span> <span class="o">||=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">incr_cat</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">]</span> <span class="o">||=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_count</span><span class="o">]</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_count</span><span class="o">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@training_count</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@training_count</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return number of times the word appears in a category</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">word_count</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span> <span class="k">unless</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">][</span><span class="n">category</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">][</span><span class="n">category</span><span class="o">].</span><span class="n">to_f</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of times the word appears in all categories</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">total_word_count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span> <span class="k">unless</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">].</span><span class="n">to_f</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of words in a categories</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">total_word_count_in_cat</span><span class="p">(</span><span class="n">cat</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span> <span class="k">unless</span> <span class="vi">@category_list</span><span class="o">[</span><span class="n">cat</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@category_list</span><span class="o">[</span><span class="n">cat</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">cat</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">].</span><span class="n">to_f</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of training item</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">total_cat_count</span>
</span><span class='line'>    <span class="vi">@training_count</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of training document for a category</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">cat_count</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_count</span><span class="o">]</span> <span class="p">?</span> <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_count</span><span class="o">].</span><span class="n">to_f</span> <span class="p">:</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of time categories in wich a word appear</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">categories_with_word_count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="mi">0</span> <span class="k">unless</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">].</span><span class="n">length</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of categories</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">total_categories</span>
</span><span class='line'>    <span class="n">categories</span><span class="o">.</span><span class="n">length</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return categories list</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">categories</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">.</span><span class="n">keys</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># train the classifier</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</span><span class='line'>    <span class="vi">@tokenizer</span><span class="o">.</span><span class="n">each_word</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="p">{</span><span class="o">|</span><span class="n">w</span><span class="o">|</span> <span class="n">incr_word</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span> <span class="p">}</span>
</span><span class='line'>    <span class="n">incr_cat</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># classify a text</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kp">nil</span><span class="p">)</span>
</span><span class='line'>    <span class="c1"># Find the category with the highest probability</span>
</span><span class='line'>    <span class="n">max_prob</span> <span class="o">=</span> <span class="vi">@min_prob</span>
</span><span class='line'>    <span class="n">best</span> <span class="o">=</span> <span class="kp">nil</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">scores</span> <span class="o">=</span> <span class="n">cat_scores</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span><span class='line'>    <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
</span><span class='line'>      <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
</span><span class='line'>      <span class="k">if</span> <span class="n">prob</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
</span><span class='line'>        <span class="n">max_prob</span> <span class="o">=</span> <span class="n">prob</span>
</span><span class='line'>        <span class="n">best</span> <span class="o">=</span> <span class="n">cat</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># Return the default category in case the threshold condition was</span>
</span><span class='line'>    <span class="c1"># not met. For example, if the threshold for :spam is 1.2</span>
</span><span class='line'>    <span class="c1">#</span>
</span><span class='line'>    <span class="c1">#    :spam =&gt; 0.73, :ham =&gt; 0.40  (OK)</span>
</span><span class='line'>    <span class="c1">#    :spam =&gt; 0.80, :ham =&gt; 0.70  (Fail, :ham is too close)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">default</span> <span class="k">unless</span> <span class="n">best</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">threshold</span> <span class="o">=</span> <span class="vi">@thresholds</span><span class="o">[</span><span class="n">best</span><span class="o">]</span> <span class="o">||</span> <span class="mi">1</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
</span><span class='line'>      <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
</span><span class='line'>      <span class="k">next</span> <span class="k">if</span> <span class="n">cat</span> <span class="o">==</span> <span class="n">best</span>
</span><span class='line'>      <span class="k">return</span> <span class="n">default</span> <span class="k">if</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">threshold</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">best</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">save_state</span>
</span><span class='line'>    <span class="vi">@storage</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="nb">self</span><span class="p">)</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">class</span> <span class="o">&lt;&lt;</span> <span class="nb">self</span>
</span><span class='line'>    <span class="kp">attr_writer</span> <span class="ss">:storage</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">storage</span>
</span><span class='line'>      <span class="vi">@storage</span> <span class="o">=</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">InMemoryStorage</span><span class="o">.</span><span class="n">new</span> <span class="k">unless</span> <span class="n">defined?</span> <span class="vi">@storage</span>
</span><span class='line'>      <span class="vi">@storage</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">open</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
</span><span class='line'>      <span class="n">inst</span> <span class="o">=</span> <span class="nb">self</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
</span><span class='line'>      <span class="k">if</span> <span class="nb">block_given?</span>
</span><span class='line'>        <span class="k">yield</span> <span class="n">inst</span>
</span><span class='line'>        <span class="n">inst</span><span class="o">.</span><span class="n">save_state</span>
</span><span class='line'>      <span class="k">else</span>
</span><span class='line'>        <span class="n">inst</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>完整代码实现可以参考<a href="https://github.com/alexandru/stuff-classifier"><strong>alexandru大神的github项目stuff-classifier</strong></a></p>




<h3 id="算法训练和使用">算法训练和使用</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># 训练函数</span>
</span><span class='line'><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</span><span class='line'>  <span class="n">each_word</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="p">{</span><span class="o">|</span><span class="n">w</span><span class="o">|</span> <span class="n">increment_word</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span> <span class="p">}</span>
</span><span class='line'>  <span class="n">increment_cat</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
</span><span class='line'><span class="k">end</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># 使用</span>
</span><span class='line'><span class="n">classifier</span><span class="o">.</span><span class="n">train</span> <span class="ss">:spam</span><span class="p">,</span> <span class="s2">&quot;Grow your penis to 20 inches in just 1 week&quot;</span>
</span><span class='line'><span class="n">classifier</span><span class="o">.</span><span class="n">train</span> <span class="ss">:ham</span><span class="p">,</span>  <span class="s2">&quot;I&#39;m hungry, no I don&#39;t want your penis&quot;</span>
</span></code></pre></td></tr></table></div></figure>




<p>由于本文主要的目标是讲解贝叶斯算法，所以为了方便分词，主要使用英文语料训练，对于中文邮件分类而言，只要采用分词库分词即可，其他部分不变。</p>




<h3 id="提高准确度与算法优化">提高准确度与算法优化</h3>




<h4 id="计算优化">计算优化</h4>




<p>由于浮点数计算的一些先天性问题，如计算效率慢，精度不准确等。因此我们可以用自然对数来代替原本概率的形式。 <br>
<script type="math/tex" id="MathJax-Element-3265">claaify(word_1,word_2,…word_n)=\text{argmax}\sum _{i=1}^n \frac{\log  
   \left(P\left(\left.\text{word}_i\right|\text{spam}\right)\right)}{\log  
   (e)}+\frac{\log (P(\text{spam}))}{\log (e)}</script></p>




<h4 id="拉普拉斯平滑">拉普拉斯平滑</h4>




<p>由于贝叶斯公式依赖的都是用已知概率求未知概率，但是在分类中无法避免的一个情况就是当我们计算<script type="math/tex" id="MathJax-Element-4127">P(word_i|spam)</script>即：在已有的训练的垃圾邮件样本中出现<script type="math/tex" id="MathJax-Element-4128">word_i</script>的概率是多少时，我们遇到了一个从未在训练样本中出现过的词，那么此时就会导致<script type="math/tex" id="MathJax-Element-4129">P(word_i|spam)=0</script>。这样就会影响整体的判别。</p>




<p>这样由于训练样本不足导致分类器整体质量大大下降的问题很常见，为了解决这个问题，我们可以引入<strong>Laplace校准</strong>（即我们要讲的拉普拉斯平滑公式），它的原理非常简单，给未出现特征值，赋予一个“小”的值而不是0。</p>




<p>具体平滑方法如下： <br>
假设离散型随机变量z有{1,2,…,k}个值，我们用<script type="math/tex" id="MathJax-Element-4130">\phi _i=P(z=i)</script>来表示每个值的概率。假设有m个训练样本中，z的观察值是<script type="math/tex" id="MathJax-Element-4131">\left\{z^1,\text{...},z^m\right\}</script>其中每一个观察值对应k个值中的一个。那么根据原来的估计方法可以得到</p>




<p><script type="math/tex" id="MathJax-Element-4132">\phi _j=\frac{\sum _{i=1}^m 1 \left\{z^i=j\right\}}{m}</script></p>




<p>简单来说就是<script type="math/tex" id="MathJax-Element-4133">z=j</script>出现的比例。</p>




<p>拉普拉斯平滑法将每个k值出现次数事先都加1，即假设他们都出现过一次。 <br>
那么修改后的表达式为：</p>




<p><script type="math/tex" id="MathJax-Element-4134">\phi _j=\frac{\sum _{i=1}^m 1 \left\{z^i=j\right\}+1}{m+k}</script></p>




<p>每个z=j的分子都加1，分母加k。可见<script type="math/tex" id="MathJax-Element-4135">\sum _{j=1}^k \phi _j=1</script>。</p>




<p>这样在保持总体事件发现概率比例基本不变的同时，又避免了0概率的问题。</p>




<h4 id="去除停用词">去除停用词</h4>




<p><strong>停用词</strong>是指在信息检索中，为节省存储空间和提高搜索效率，在处理自然语言数据（或文本）之前或之后会自动过滤掉某些字或词，这些字或词即被称为<strong>Stop Words</strong>（停用词）。这些停用词都是人工输入、非自动化生成的，生成后的停用词会形成一个停用词表。但是，并没有一个明确的停用词表能够适用于所有的工具。</p>




<p>通常意义上，Stop Words大致为如下两类：</p>




<ol>
<li>第一类是那些应用十分广泛的词，在Internet上随处可见，比如“Web”一词几乎在每个网站上均会出现，对这样的词搜索引擎无 法保证能够给出真正相关的搜索结果，难以帮助缩小搜索范围，同时还会降低搜索的效率。</li>
<li>第二类就更多了，包括了语气助词、副词、介词、连接词等，通常自身并无明确的意义，只有将其放入一个完整的句子中才有一定作用，如常见的“的”、“在”之类。</li>
</ol>




<p>为了使得最后用于判别邮件类型的词向量能够更加贴近邮件本身真正想表达的含义，我们可以在读取扫描文本并生成词列表时，先<strong>剔除停用词</strong>，再进行下一步的概率计算。</p>




<p>常用中文停用词表： <br>
链接: <a href="https://pan.baidu.com/s/1o8hw5Cm">https://pan.baidu.com/s/1o8hw5Cm</a> 密码: crti</p>




<p>常用英文停用词表： <br>
链接: <a href="https://pan.baidu.com/s/1jIOOfgM">https://pan.baidu.com/s/1jIOOfgM</a> 密码: 7g95</p>




<h4 id="阈值选取">阈值选取</h4>




<p>假设我们计算出一封邮件的<script type="math/tex" id="MathJax-Element-4368">P(spam) = 0.6 </script>那么是否我们因为 <script type="math/tex" id="MathJax-Element-4369">P(spam) = 0.6 > P(not spam)=1-0.6=0.4</script> 就可以把它定义为垃圾邮件呢？显然这样做是不合理的，一个好的概率阈值应该是在训练及测试样本上使得发生误判情况最少时所取得的值。通常我们可以定义一个误差评判函数再通过不同阈值在样本上的评分来选取出最佳的阈值。简单实现就如下面的代码所示：</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kp">nil</span><span class="p">)</span>
</span><span class='line'>  <span class="c1"># Find the category with the highest probability</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">max_prob</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>  <span class="n">best</span> <span class="o">=</span> <span class="kp">nil</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">scores</span> <span class="o">=</span> <span class="n">cat_scores</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span><span class='line'>  <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
</span><span class='line'>    <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">prob</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
</span><span class='line'>      <span class="n">max_prob</span> <span class="o">=</span> <span class="n">prob</span>
</span><span class='line'>      <span class="n">best</span> <span class="o">=</span> <span class="n">cat</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># Return the default category in case the threshold condition was</span>
</span><span class='line'>  <span class="c1"># not met. For example, if the threshold for :spam is 1.2</span>
</span><span class='line'>  <span class="c1">#</span>
</span><span class='line'>  <span class="c1">#    :spam =&gt; 0.73, :ham =&gt; 0.40  (OK)</span>
</span><span class='line'>  <span class="c1">#    :spam =&gt; 0.80, :ham =&gt; 0.70  (Fail, :ham is too close)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="n">default</span> <span class="k">unless</span> <span class="n">best</span>
</span><span class='line'>  <span class="n">threshold</span> <span class="o">=</span> <span class="vi">@thresholds</span><span class="o">[</span><span class="n">best</span><span class="o">]</span> <span class="o">||</span> <span class="mi">1</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
</span><span class='line'>    <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
</span><span class='line'>    <span class="k">next</span> <span class="k">if</span> <span class="n">cat</span> <span class="o">==</span> <span class="n">best</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">default</span> <span class="k">if</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">threshold</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>  <span class="k">return</span> <span class="n">best</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>




<p>最后，写到这里，贝叶斯分类器构建的讲解基本就结束了。通观全篇，我们依旧有个问题并没有解决：朴素贝叶斯分类有一个限制条件，就是特征属性必须有条件独立或基本独立（实际上在现实应用中几乎不可能做到完全独立）。当这个条件成立时，朴素贝叶斯分类法的准确率是最高的，但不幸的是，现实中各个特征属性间往往并不条件独立，而是具有较强的相关性，这样就限制了朴素贝叶斯分类的能力。然而，这个问题也并不是无解的，贝叶斯分类中有一种更高级、应用范围更广的一种算法——<strong>贝叶斯网络（又称贝叶斯信念网络或信念网络）</strong>，信念网络在一定程度上使得模型更接近真实的实际情况，有兴趣的读者可以进一步深入了解。</p>



</div>
  
  


      <footer>
      
      - <a href="/blog/2017/09/03/ru-he-gou-jian-%5B%3F%5D-ge-po-su-bei-xie-si-fen-lei-qi/">如何构建一个朴素贝叶斯分类器</a>
      <time datetime="2017-09-03T13:22:23+08:00" pubdate><span class='month'>Sep</span> <span class='day'>03</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/08/30/pythonshi-xian-fisherpan-bie-fen-xi/">Python实现Fisher判别分析</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-08-30T09:06:21+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><h1 id="python实现fisher-判别分析">Python实现Fisher 判别分析</h1>




<h2 id="fisher原理">Fisher原理</h2>




<p>费歇（Fisher）判别思想是投影，使多维问题化为一维问题来处理。选择一个适当的投影轴，使所有的样本点都投影在这个轴上得到一个投影值。对这个投影轴的方向的要求是：使每一类内的投影值所形成的类内距离差尽可能小，而不同类间的投影值所形成的类间距离差尽可能大。 <br>
<img src="https://i.loli.net/2017/09/01/59a90dda8790e.png" alt="" title=""></p>




<p><img src="https://i.loli.net/2017/09/01/59a9136f647d1.png" alt="enter image description here" title=""></p>




<p>这样如果我们想要同类样列的投影点尽可能接近，可以让同类样列投影点的协方差尽可能小，即<script type="math/tex" id="MathJax-Element-1">w^T \left(\sum _0 w\right)+w^T \left(\sum _1 w\right)</script>尽可能小;而欲使异类样列的投影点尽可能远离，可以让类中心之间的距离尽可能大，即<script type="math/tex" id="MathJax-Element-2">\left[\left[u_0 w^T-u_1 w^T\right]\right]</script>尽可能大。同时结合两者我们可以得到欲最大化的目标： <br>
<img src="https://i.loli.net/2017/09/01/59a9136f56af9.png" alt="enter image description here" title=""></p>




<p>(本文图片截取自<a href="https://book.douban.com/subject/26708119/">《机器学习》</a>周志华)</p>




<p><img src="https://i.loli.net/2017/09/01/59a9136f635c6.png" alt="enter image description here" title=""></p>




<p>有了上面的推理之后我们接下来就以DNA分类为例来实现一下Fisher线性判别。</p>




<h2 id="数据准备">数据准备</h2>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span><span class='line'><span class="n">dna_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;dna2&#39;</span><span class="p">,</span><span class="s">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span class='line'>    <span class="n">dna_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">strip</span><span class="p">,</span><span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()))</span>
</span><span class='line'>    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dna_list</span><span class="p">))</span>
</span><span class='line'><span class="k">def</span> <span class="nf">generate_feature</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">:</span>
</span><span class='line'>        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span class='line'>        <span class="k">yield</span> <span class="p">[</span>
</span><span class='line'>        <span class="n">chary</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s">&#39;a&#39;</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">,</span>
</span><span class='line'>        <span class="n">chary</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s">&#39;t&#39;</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">,</span>
</span><span class='line'>        <span class="n">chary</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s">&#39;c&#39;</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">,</span>
</span><span class='line'>        <span class="n">chary</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s">&#39;g&#39;</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">generate_feature</span><span class="p">(</span><span class="n">dna_list</span><span class="p">)),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span class='line'><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</span><span class='line'><span class="n">y</span><span class="p">[</span><span class="mi">10</span><span class="p">:]</span><span class="o">=</span><span class="mi">2</span>
</span><span class='line'><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="s">&#39;</span><span class="se">\n</span><span class="s">&#39;</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote>
  <p>输出结果： <br>
  40 <br>
  [[ 0.2972973   0.13513514  0.17117117  0.3963964 ] <br>
   [ 0.35454545  0.5         0.04545455  0.1       ] <br>
   [ 0.42342342  0.28828829  0.10810811  0.18018018] <br>
   [ 0.35135135  0.12612613  0.12612613  0.3963964 ] <br>
   [ 0.27927928  0.18918919  0.16216216  0.36936937] <br>
   [ 0.21818182  0.56363636  0.14545455  0.07272727] <br>
   [ 0.20720721  0.15315315  0.20720721  0.43243243] <br>
   [ 0.3         0.5         0.08181818  0.11818182] <br>
   [ 0.2         0.56363636  0.17272727  0.06363636] <br>
   [ 0.27027027  0.06306306  0.21621622  0.45045045] <br>
   [ 0.32727273  0.5         0.02727273  0.14545455] <br>
   [ 0.23423423  0.10810811  0.23423423  0.42342342] <br>
   [ 0.29090909  0.64545455  0.          0.06363636] <br>
   [ 0.18181818  0.13636364  0.27272727  0.40909091] <br>
   [ 0.29090909  0.5         0.11818182  0.09090909] <br>
   [ 0.25454545  0.51818182  0.1         0.12727273] <br>
   [ 0.27433628  0.36283186  0.19469027  0.16814159] <br>
   [ 0.27027027  0.15315315  0.16216216  0.41441441]]  <br>
   [ 1.  2.  1.  1.  1.  2.  1.  2.  2.  1.  2.  1.  2.  1.  2.  2.  2.  1.]</p>
</blockquote>




<h2 id="fisher算法实现">Fisher算法实现</h2>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">cal_cov_and_avg</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    给定一个类别的数据，计算协方差矩阵和平均向量</span>
</span><span class='line'><span class="sd">    :param samples: </span>
</span><span class='line'><span class="sd">    :return: </span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">u1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>    <span class="n">cov_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
</span><span class='line'>        <span class="n">t</span> <span class="o">=</span> <span class="n">s</span> <span class="o">-</span> <span class="n">u1</span>
</span><span class='line'>        <span class="n">cov_m</span> <span class="o">+=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">cov_m</span><span class="p">,</span> <span class="n">u1</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">fisher</span><span class="p">(</span><span class="n">c_1</span><span class="p">,</span> <span class="n">c_2</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    fisher算法实现(请参考上面推导出来的公式，那个才是精华部分)</span>
</span><span class='line'><span class="sd">    :param c_1: </span>
</span><span class='line'><span class="sd">    :param c_2: </span>
</span><span class='line'><span class="sd">    :return: </span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">cov_1</span><span class="p">,</span> <span class="n">u1</span> <span class="o">=</span> <span class="n">cal_cov_and_avg</span><span class="p">(</span><span class="n">c_1</span><span class="p">)</span>
</span><span class='line'>    <span class="n">cov_2</span><span class="p">,</span> <span class="n">u2</span> <span class="o">=</span> <span class="n">cal_cov_and_avg</span><span class="p">(</span><span class="n">c_2</span><span class="p">)</span>
</span><span class='line'>    <span class="n">s_w</span> <span class="o">=</span> <span class="n">cov_1</span> <span class="o">+</span> <span class="n">cov_2</span>
</span><span class='line'>    <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">s_w</span><span class="p">)</span>  <span class="c"># 奇异值分解</span>
</span><span class='line'>    <span class="n">s_w_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">))),</span> <span class="n">u</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">s_w_inv</span><span class="p">,</span> <span class="n">u1</span> <span class="o">-</span> <span class="n">u2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<h2 id="判别类型">判别类型</h2>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">judge</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c_1</span><span class="p">,</span> <span class="n">c_2</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    true 属于1</span>
</span><span class='line'><span class="sd">    false 属于2</span>
</span><span class='line'><span class="sd">    :param sample:</span>
</span><span class='line'><span class="sd">    :param w:</span>
</span><span class='line'><span class="sd">    :param center_1:</span>
</span><span class='line'><span class="sd">    :param center_2:</span>
</span><span class='line'><span class="sd">    :return:</span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">u1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">c_1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>    <span class="n">u2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">c_2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>    <span class="n">center_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">u1</span><span class="p">)</span>
</span><span class='line'>    <span class="n">center_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">u2</span><span class="p">)</span>
</span><span class='line'>    <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="nb">abs</span><span class="p">(</span><span class="n">pos</span> <span class="o">-</span> <span class="n">center_1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">abs</span><span class="p">(</span><span class="n">pos</span> <span class="o">-</span> <span class="n">center_2</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="n">w</span> <span class="o">=</span> <span class="n">fisher</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span>  <span class="c"># 调用函数，得到参数w</span>
</span><span class='line'><span class="n">pred</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
</span><span class='line'>    <span class="n">pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">judge</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>   <span class="c"># 判断所属的类别</span>
</span><span class='line'><span class="c"># evaluate accuracy</span>
</span><span class='line'><span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">pred</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
</span><span class='line'><span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">40</span><span class="p">):</span>
</span><span class='line'>    <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">judge</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>   <span class="c"># 判断所属的类别</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote>
  <p>输出结果： <br>
  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2. <br>
    2.  2.] [1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1] <br>
  0.95 <br>
  [1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1]</p>
</blockquote>




<p>在这我们可以看出我们的Fisher算法在测试集中的误差率还算理想，误判率仅有5%。但是，我们可以看出其预测分类并不如其他KNN，SVM，等算法的预测效果。</p>




<p>最后，有关Fisher算法的介绍也就到此结束了！</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/08/30/pythonshi-xian-fisherpan-bie-fen-xi/">Python实现Fisher判别分析</a>
      <time datetime="2017-08-30T09:06:21+08:00" pubdate><span class='month'>Aug</span> <span class='day'>30</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/4">&larr; Older</a>
    
    <a href="/archives">Blog Archives</a>
    
    <a class="next" href="/posts/2">Newer &rarr;</a>
    
  </div><!-- /div.pagination -->
</div><!-- /div.blog-index -->

      </div><!-- /div#content -->
    </div><!-- /div#main -->
  </div><!-- /div.container -->
  <footer><div id="footer-widgets-wrapper">
  <div id="footer-first" class="footer-widget">
    <h3>About Me</h3>
    <section class="about-me">
      
        <img class="icon-image" src="https://avatars0.githubusercontent.com/u/13914416?s=240" alt="icon_image">
      
      <div>
        <ul>
          
            <li>GitHub: <a href="https://github.com/EdmondFrank">@EdmondFrank</a></li>
          
          
            <li>Twitter: <a href="https://twitter.com/EdmondFrank4">@EdmondFrank4</a></li>
          
            <li>Blog: <a href="https://edmondfrank.github.io">https://edmondfrank.github.io</a></li>
        </ul>
        <p>
          この町、冗談と気まぐれと偶然でてきっているらしい。
        </p>
      </div>
    </section>
  </div><!-- /div#footer-second -->

  <div id="footer-second" class="footer-widget">
    <h3>Recent Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="https://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "https://edmondfrank.github.io";
        Hatena.BookmarkWidget.title = "Recent Posts";
        Hatena.BookmarkWidget.sort  = "hot";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-second -->

  <div id="footer-third" class="footer-widget">
    <h3>Popular Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="https://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "https://edmondfrank.github.io";
        Hatena.BookmarkWidget.title = "Popular Posts";
        Hatena.BookmarkWidget.sort  = "count";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-third -->
</div><!-- /div#footer-widgets-wrapper -->

<div id="credit" role="contentinfo">
  <p>
    Copyright &copy; 2018 - <a href="https://github.com/EdmondFrank/">EdmondFrank</a> -
    <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  </p>
</div>

</footer>
  










  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
