
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="ja"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>EdmondFrank's 时光足迹</title>
  <meta name="author" content="EdmondFrank">

  
  <meta name="description" content="﻿深度学习入门简介 背景 深度学习的概念源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。 概念 深度学习的概念由Hinton等人于2006年提出。基于深度置信网络(DBN) &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://edmondfrank.github.io/posts/2/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="EdmondFrank's 时光足迹" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.cat.net/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
   <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_SVG"></script>
  
  

</head>

<body >
  <div id="container">
    <header role="banner"><hgroup>
  <h1><a href="/">EdmondFrank's 时光足迹</a></h1>
  
    <h2>この先は暗い夜道だけかもしれない　それでも信じて進むんだ。星がその道を少しでも照らしてくれるのを。<br>或许前路永夜，即便如此我也要前进，因为星光即使微弱也会我为照亮前途。<br>——《四月は君の嘘》</h2>
  
</hgroup>

</header>
    <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="site:edmondfrank.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
</ul>

</nav>
    <div id="main">
      <div id="content">
        <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/12/02/shen-du-xue-xi-ru-men-jian-jie/">深度学习入门简介</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-12-02T17:17:32+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="深度学习入门简介">深度学习入门简介</h1></p>

<h2 id="背景">背景</h2>




<p><strong>深度学习</strong>的概念源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。</p>




<h2 id="概念">概念</h2>




<p><strong>深度学习</strong>的概念由Hinton等人于2006年提出。基于深度置信网络(DBN)提出非监督贪心逐层训练算法，为解决深层结构相关的优化难题带来希望，随后提出多层自动编码器深层结构。此外Lecun等人提出的卷积神经网络是第一个真正多层结构学习算法，它利用空间相对关系减少参数数目以提高训练性能。</p>




<h2 id="原理">原理</h2>




<p><strong>深度学习</strong>是机器学习中一种基于对数据进行表征学习的方法。观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的向量，或者更抽象地表示成一系列边、特定形状的区域等。而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。</p>




<p>（以上内容摘取自百度百科）</p>




<p><strong>个人理解：</strong>如果说机器学习是为了找出一个能够代表输入变量和输出变量的关系的函数的话；那么深度学习就是先根据输入和输出变量之间的关系，列出一系列能够代表他们之间关系的函数，然后再从这个函数集之中提取一个最优的函数。</p>




<h2 id="结构">结构</h2>




<h3 id="神经元">神经元</h3>




<p>随着神经网络的应用和深度学习在人工智能领域的大放异彩，很多人都说神经网络的是最成功的仿真模型。那么他的结构究竟是怎样子的呢？</p>




<p><img src="https://i.loli.net/2017/12/01/5a217a29cf015.png" alt="nn.png" title=""></p>




<p>一个简单的神经网咯函数（一般称作：神经元），就如上图所示。</p>




<p>他的主要执行过程：</p>




<blockquote>
  <p>多个输入a X 各自的权重w + 偏置值b =&gt; 激活函数 =&gt; 输出</p>
</blockquote>




<p>其中，在这个流程之中，我们可能比较迷惑的是那个激活函数Activation function。</p>




<p><strong>Activation Function：</strong>即激活函数，目前的常用的激活函数由挺多的，例如，Simmoid Function，tanh，relu等等。虽然形式上不同，但是他们大体的目的都是较为一致的，就是用来加入非线性因素的，因为线性模型的表达能力不够。</p>




<p><script type="math/tex; mode=display" id="MathJax-Element-1"> 如下所示的Sigmoid Function \\\sigma(z)=\frac{1}{1+e^{-z}}</script></p>




<p>同时，激活函数可以将非常大或非常小的数据映射到“逻辑空间”[-1,1]之间，这样映射过后的数据更适合在反向传播算法中进行梯度下降。</p>




<h3 id="连接方式">连接方式</h3>




<p>上面我们提及的仅仅是神经网络中的一个神经元，他是神经网络之中最基本的组成单位。但是如果要构建一个强大智能的神经网络，仅仅靠一个神经元是不行的。于是，我们便可以将多个神经元分层连接起来，这样才构成了我们所知道的神经网络。</p>




<p>既然，神经网络的构成本质就是神经元的连接，那么不同的连接方式就会形成不同的神经网络结构如全连接前馈网络，多层感知器，卷积神经网络，循环神经网络等等。</p>




<h2 id="全连接前馈网络">全连接前馈网络</h2>




<p>在众多的连接之间，全连接的前馈网络不仅较为简单，也是很多深层网络的基础。他的基本连接方式如下图片所示：</p>




<p><img src="https://i.loli.net/2017/12/02/5a2180e6120e2.png" alt="feedforward.png" title=""></p>




<p>其中，一般来说神经网络的第一层通常都是输入层，而最后一层便是输出层以及中间的都统一称作隐藏层。深度神经网络中的“深”便代表了这个网络中间有非常多的隐藏层。</p>




<h2 id="输出层">输出层</h2>




<p>通常，输出层一般为Softmax 层，并且其可以为任意值。在应用中，输出的结果通常用概率的形式表达，其具体形式如下图所示： <br>
<img src="https://i.loli.net/2017/12/02/5a218350cc19b.png" alt="output.png" title=""></p>




<p>那么，我们知道了神经网络的组成之后，我们要是想自己构建一个神经网络，我们又该如何确定神经网络的层数和每层的神经元的个数呢？</p>




<p><strong>就目前来说，</strong>并没有相当的严谨的理论来指导神经网络的构建。我们往往需要依靠直觉和训练测试结果的误差反馈来一步一步选择我们的层数和神经元数以达到要求的效果。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/12/02/shen-du-xue-xi-ru-men-jian-jie/">深度学习入门简介</a>
      <time datetime="2017-12-02T17:17:32+08:00" pubdate><span class='month'>Dec</span> <span class='day'>02</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/shen-jing-wang-luo-yu-shen-du-xue-xi/'>神经网络与深度学习</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/11/27/pythonzai-sparkshang-de-ji-qi-xue-xi-zhi-ji-qi-xue-xi-shi-zhan-xia/">Python在Spark上的机器学习之机器学习实战(下)</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-11-27T12:45:01+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="python在spark上的机器学习之机器学习实战下">Python在Spark上的机器学习之机器学习实战(下)</h1></p>

<h2 id="mllib-的使用续">MLlib 的使用（续）</h2>




<p>我们在上篇讲到了：数据相关性分析和特征选取，但是我们在上篇中所提及的方法基本都是针对标准的数值型的数据特征；那么，我们下篇就继续将分类变量的统计检验分析，以及最后的建模过程讲述完整。</p>




<h3 id="统计校验">　统计校验</h3>




<p>在通过特征变量的相关系数选择特征时，对于一般的分类变量而言，我们无法计算它们之间的相关系数，但是我们可以通过对它们进行卡方校验来检测它们的分布之间是否存在较大的差异。</p>




<p><strong>卡方检验</strong>：是用途非常广的一种假设检验方法，它在分类资料统计推断中的应用，包括：两个样本率或两个构成比比较的卡方检验；多个样本率或多个构成比比较的卡方检验以及分类资料的相关分析等。</p>




<p><strong>卡方检验</strong>就是统计样本的实际观测值与理论推断值之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，卡方值越大，越不符合；卡方值越小，偏差越小，越趋于符合，若两个值完全相等时，卡方值就为0，表明理论值完全符合。</p>




<p>而在PySpark中你可以用 <strong>.chiSqTest()</strong> 方法来轻松实现卡方检验。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pyspark.mllib.linalg</span> <span class="kn">as</span> <span class="nn">ln</span>
</span><span class='line'><span class="k">for</span> <span class="n">cat</span> <span class="ow">in</span> <span class="n">categorical_cols</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
</span><span class='line'>  <span class="n">agg</span> <span class="o">=</span> <span class="n">births_transformed</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">&#39;INFANT_ALIVE_AT_REPORT&#39;</span><span class="p">)</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">cat</span><span class="p">)</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">count</span><span class="p">()</span>
</span><span class='line'>  <span class="n">agg_rdd</span> <span class="o">=</span> <span class="n">agg</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">rdd</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">e</span> <span class="o">==</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">e</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">row</span><span class="p">])</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span><span class='line'>  <span class="n">row_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">agg</span><span class="o">.</span><span class="n">collect</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>
</span><span class='line'>  <span class="n">agg</span> <span class="o">=</span> <span class="n">ln</span><span class="o">.</span><span class="n">Matrices</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">row_length</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">agg_rdd</span><span class="p">)</span>
</span><span class='line'>  <span class="n">test</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">Statistics</span><span class="o">.</span><span class="n">chiSqTest</span><span class="p">(</span><span class="n">agg</span><span class="p">)</span>
</span><span class='line'>  <span class="k">print</span><span class="p">(</span><span class="n">cat</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">pValue</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<p>我们遍历所有的分类变量并以 <strong>infant_alive_ at_report</strong>进行分类统计。下一步，我们需要将其转化成RDD，所以我们要先利用pyspark.mllib.linalg模将它们转换成一个矩阵。 <br>
当我们成功将其转换成矩阵的形式之后，我们就可以用<strong>.chiSqTest()</strong>来校验我们的结果。</p>




<p>最后结果显示如下：</p>




<p><img src="https://i.loli.net/2017/11/16/5a0daece4fae9.png" alt="chisqtest.png" title=""></p>




<p>从结果我们可以看出，所有分类变量对理论值的预测都是有意义的，因此，我们在构建最后的预测模型的时候都要考虑上这些分类型特征变量。</p>




<h3 id="创建最后的待训练数据集">创建最后的待训练数据集</h3>




<p>经过一轮的数据分析和特征变量筛选之后，最终到了我们最终的建模阶段了。首先我们将筛选出来以DataFrame数据结构模型表达的数据转换成以LabeledPoints形式表示的RDD。</p>




<p>LabeledPoint 是 MLlib 中的一种数据结构，它包含了两个属性值：label（标识），features（特征）一般用作机器学习模型的训练。</p>




<p>其中，label就是我们目标的分类的标识而features就是我们用于分类的特征， <br>
通常是一个Numpy 数组，列表，psyspark.mllib.linalg.SparseVector,pyspark.mllib,linalg.DenseVector或者是scipy.sparse的形式。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pyspark.mllib.feature</span> <span class="kn">as</span> <span class="nn">ft</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">pyspark.mllib.regression</span> <span class="kn">as</span> <span class="nn">reg</span>
</span><span class='line'><span class="n">hashing</span> <span class="o">=</span> <span class="n">ft</span><span class="o">.</span><span class="n">HashingTF</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
</span><span class='line'><span class="n">births_hashed</span> <span class="o">=</span> <span class="n">births_transformed</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">rdd</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>      <span class="nb">list</span><span class="p">(</span><span class="n">hashing</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">toArray</span><span class="p">())</span>
</span><span class='line'>          <span class="k">if</span> <span class="n">col</span> <span class="o">==</span> <span class="s">&#39;BIRTH_PLACE&#39;</span>
</span><span class='line'>          <span class="k">else</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span class='line'>      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span>
</span><span class='line'>      <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">features_to_keep</span><span class="p">)])</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">[[</span><span class="n">e</span><span class="p">]</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="o">==</span> <span class="nb">int</span> <span class="k">else</span> <span class="n">e</span>
</span><span class='line'>          <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">row</span><span class="p">])</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">row</span>
</span><span class='line'>          <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">])</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">reg</span><span class="o">.</span><span class="n">LabeledPoint</span><span class="p">(</span>
</span><span class='line'>      <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
</span><span class='line'>      <span class="n">ln</span><span class="o">.</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
</span><span class='line'>      <span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<h3 id="划分训练集和测试集">划分训练集和测试集</h3>




<p>形如sklearn.model_selection.train_test_split随机划分训练集和测试集的模块一般，在PySpark中RDDs也有一个便利的<strong>.randomSplit(…)</strong>方法用于随机划分训练集和测试集。</p>




<p>在本例中可以这样使用</p>




<pre class="prettyprint"><code class="language-python hljs ">births_train, births_test = births_hashed.randomSplit([<span class="hljs-number">0.6</span>, <span class="hljs-number">0.4</span>])</code></pre>




<p>没错，仅仅需要上面这样一行的代码，我们就可以将我们的待训练数据按照随机60%，40%来划分好我们的训练集和测试集了。</p>




<h3 id="开始建模">开始建模</h3>




<p>在一切准备就绪之后，我们就可以开始通过我们上面的训练数据集来建模了。在这里我们来尝试建立两个模型：一个线性的Logistic回归模型，一个非线性的随机森林模型。然后，在初次建模的时候，我们先采用筛选出来的全部特征来建模，然后我们再通过<strong>ChiSqSelector（…）</strong>方法来归纳出最能代表全部整体的四个主成分。</p>




<h4 id="logistic-回归模型">Logistic 回归模型</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">pyspark.mllib.classification</span> \
</span><span class='line'><span class="kn">import</span> <span class="n">LogisticRegressionWithLBFGS</span>
</span><span class='line'><span class="n">LR_Model</span> <span class="o">=</span> <span class="n">LogisticRegressionWithLBFGS</span> \
</span><span class='line'><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">births_train</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">LR_results</span> <span class="o">=</span> <span class="p">(</span>
</span><span class='line'><span class="n">births_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">label</span><span class="p">)</span> \
</span><span class='line'><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">LR_Model</span> \
</span><span class='line'><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">births_test</span>\
</span><span class='line'><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">features</span><span class="p">)))</span>
</span><span class='line'><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">pyspark.mllib.evaluation</span> <span class="kn">as</span> <span class="nn">ev</span>
</span><span class='line'><span class="n">LR_evaluation</span> <span class="o">=</span> <span class="n">ev</span><span class="o">.</span><span class="n">BinaryClassificationMetrics</span><span class="p">(</span><span class="n">LR_results</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Area under PR: {0:.2f}&#39;</span> \
</span><span class='line'><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">LR_evaluation</span><span class="o">.</span><span class="n">areaUnderPR</span><span class="p">))</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Area under ROC: {0:.2f}&#39;</span> \
</span><span class='line'><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">LR_evaluation</span><span class="o">.</span><span class="n">areaUnderROC</span><span class="p">))</span>
</span><span class='line'><span class="n">LR_evaluation</span><span class="o">.</span><span class="n">unpersist</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<p>从上面的建模过程可以看出，使用PySpark训练一个模型也是非常简单的。我们只需要调用<strong>.train(…)</strong>方法，并传入之前处理好的LabeledPoints数据即可。不过需要注意的一点是我们要提前指定一个较小训练的迭代次数以免训练时间过长。</p>




<p>同时，在上面的代码中，我们在训练完一个模型之后使用MLlib中为我们提供的评估分类和回归准确度的<strong>.BinaryClassificationMetrics（…）</strong>方法来分析我们最后预测的结果。</p>




<p>最后，结果图示如下：</p>




<p><img src="https://i.loli.net/2017/11/17/5a0dc13a5ea1a.png" alt="logistic_roc.png" title=""></p>




<p>通过PR，ROC的结果，我们可以看出，这个模型还是可接受的。</p>




<h3 id="选取出最具代表性的分类特征">选取出最具代表性的分类特征</h3>




<p>通常来说，一个采取更少的特征的简单模型，往往会比一个复杂的模型，在分类问题上更具有代表性和可解释性。而在MLlib中，则可以通过<strong>.Chi-Square selector</strong>来提取出模型中最具代表性的一些分类特征变量来简化我们的模型。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">selector</span> <span class="o">=</span> <span class="n">ft</span><span class="o">.</span><span class="n">ChiSqSelector</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">births_train</span><span class="p">)</span>
</span><span class='line'><span class="n">topFeatures_train</span> <span class="o">=</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">births_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">label</span><span class="p">)</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">selector</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">births_train</span> \
</span><span class='line'>          <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">features</span><span class="p">)))</span>
</span><span class='line'>  <span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">reg</span><span class="o">.</span><span class="n">LabeledPoint</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span><span class='line'><span class="n">topFeatures_test</span> <span class="o">=</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">births_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">label</span><span class="p">)</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">selector</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">births_test</span> \
</span><span class='line'>          <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">features</span><span class="p">)))</span>
</span><span class='line'><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">reg</span><span class="o">.</span><span class="n">LabeledPoint</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span></code></pre></td></tr></table></div></figure>




<h3 id="随机森林模型">随机森林模型</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">pyspark.mllib.tree</span> <span class="kn">import</span> <span class="n">RandomForest</span>
</span><span class='line'><span class="n">RF_model</span> <span class="o">=</span> <span class="n">RandomForest</span> \
</span><span class='line'><span class="o">.</span><span class="n">trainClassifier</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">topFeatures_train</span><span class="p">,</span>
</span><span class='line'><span class="n">numClasses</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span class='line'><span class="n">categoricalFeaturesInfo</span><span class="o">=</span><span class="p">{},</span>
</span><span class='line'><span class="n">numTrees</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
</span><span class='line'><span class="n">featureSubsetStrategy</span><span class="o">=</span><span class="s">&#39;all&#39;</span><span class="p">,</span>
</span><span class='line'><span class="n">seed</span><span class="o">=</span><span class="mi">666</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">RF_results</span> <span class="o">=</span> <span class="p">(</span>
</span><span class='line'><span class="n">topFeatures_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">label</span><span class="p">)</span> \
</span><span class='line'><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">RF_model</span> \
</span><span class='line'><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">topFeatures_test</span> \
</span><span class='line'><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">features</span><span class="p">)))</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="n">RF_evaluation</span> <span class="o">=</span> <span class="n">ev</span><span class="o">.</span><span class="n">BinaryClassificationMetrics</span><span class="p">(</span><span class="n">RF_results</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Area under PR: {0:.2f}&#39;</span> \
</span><span class='line'><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">RF_evaluation</span><span class="o">.</span><span class="n">areaUnderPR</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Area under ROC: {0:.2f}&#39;</span> \
</span><span class='line'><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">RF_evaluation</span><span class="o">.</span><span class="n">areaUnderROC</span><span class="p">))</span>
</span><span class='line'><span class="n">model_evaluation</span><span class="o">.</span><span class="n">unpersist</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<p>随机森林模型（Random forest 后面简称RF）在训练上总体与Logistic类似，不同的参数是RF在训练前需要指定类别总数：numClasses，树的棵数：numTrees（这两个参数的意义大家可以参照下随机森林模型的<a href="https://baike.baidu.com/item/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/1974765?fr=aladdin">百科介绍</a>）</p>




<p><strong>注：在随机森林模型的创建中，我们采用的是上面提取出来的最具代表性的有效特征，这就意味着模型用到的特征是比之前的Logistic要少的。</strong></p>




<p>最后，结果图示如下：</p>




<p><img src="https://i.loli.net/2017/11/17/5a0dc8621d985.png" alt="rf_roc.png" title=""></p>




<p>通过结果我们可以看出，随机森林模型，在采用比之前更少的特征下的建模的最终预测效果是由于之前的Logistic回归模型的。</p>




<p>下面我们同样使用代表性特征来重建一次Logistic回归模型</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">LR_Model_2</span> <span class="o">=</span> <span class="n">LogisticRegressionWithLBFGS</span> \
</span><span class='line'><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">topFeatures_train</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span class='line'><span class="n">LR_results_2</span> <span class="o">=</span> <span class="p">(</span>
</span><span class='line'><span class="n">topFeatures_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">label</span><span class="p">)</span> \
</span><span class='line'><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">LR_Model_2</span> \
</span><span class='line'><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">topFeatures_test</span> \
</span><span class='line'><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">features</span><span class="p">)))</span>
</span><span class='line'><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">))</span>
</span><span class='line'><span class="n">LR_evaluation_2</span> <span class="o">=</span> <span class="n">ev</span><span class="o">.</span><span class="n">BinaryClassificationMetrics</span><span class="p">(</span><span class="n">LR_results_2</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Area under PR: {0:.2f}&#39;</span> \
</span><span class='line'><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">LR_evaluation_2</span><span class="o">.</span><span class="n">areaUnderPR</span><span class="p">))</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Area under ROC: {0:.2f}&#39;</span> \
</span><span class='line'><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">LR_evaluation_2</span><span class="o">.</span><span class="n">areaUnderROC</span><span class="p">))</span>
</span><span class='line'><span class="n">LR_evaluation_2</span><span class="o">.</span><span class="n">unpersist</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>最终结果： <br>
<img src="https://i.loli.net/2017/11/17/5a0dc9d2aa75c.png" alt="logistic_lbfgs.png" title=""></p>




<p>通过结果，我们可以看出，虽然没有达到RF模型的准确度，但是与采用了全特征的Logistic回归模型处于同一水平。所以，我们在可选的情况下，通常采用更少的特征来构建更为简化和有效的模型。</p>




<h2 id="小结">小结</h2>




<p>到这里，Python在Spark上的机器学习的实战案例也结束了，欢迎大家继续关注我的博客。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/11/27/pythonzai-sparkshang-de-ji-qi-xue-xi-zhi-ji-qi-xue-xi-shi-zhan-xia/">Python在Spark上的机器学习之机器学习实战(下)</a>
      <time datetime="2017-11-27T12:45:01+08:00" pubdate><span class='month'>Nov</span> <span class='day'>27</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/pyspark-and-spark/'>pyspark&spark</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/11/17/pythonzai-sparkshang-de-ji-qi-xue-xi-zhi-ji-qi-xue-xi-shi-zhan-shang/">Python在Spark上的机器学习之机器学习实战(上)</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-11-17T09:16:10+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="python在spark上的机器学习之机器学习实战上">Python在Spark上的机器学习之机器学习实战(上)</h1></p>

<h2 id="mllib-的使用">MLlib 的使用</h2>




<p>在上面的章节之中，我们已经讲过了如何利用PySpark进行数据操作和分析了。那么在这篇文章中，我们就真正利用PySpark结合MLlib来建立一个分类模型。</p>




<p><strong>MLlib</strong>：即Machine Learning Library，MLlib 是Spark对常用的机器学习算法的实现库，同时包括相关的测试和数据生成器。MLlib 目前支持四种常见的机器学习问题：二元分类，回归，聚类以及协同过滤，同时也包括一个底层的梯度下降优化基础算法。</p>




<h3 id="载入和转化数据">载入和转化数据</h3>




<p>首先，我们在建立一个DataFrame之前，我们先针对性的指定下DataFrame中数据类型，方便我们数据后期的分析与计算。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pyspark.sql.types</span> <span class="kn">as</span> <span class="nn">typ</span>
</span><span class='line'><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;INFANT_ALIVE_AT_REPORT&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">StringType</span><span class="p">()),</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;BIRTH_YEAR&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">()),</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;BIRTH_MONTH&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">()),</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;BIRTH_PLACE&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">StringType</span><span class="p">()),</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;MOTHER_AGE_YEARS&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">()),</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;MOTHER_RACE_6CODE&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">StringType</span><span class="p">()),</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;MOTHER_EDUCATION&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">StringType</span><span class="p">()),</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;FATHER_COMBINED_AGE&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">()),</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;FATHER_EDUCATION&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">StringType</span><span class="p">()),</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;MONTH_PRECARE_RECODE&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">StringType</span><span class="p">()),</span>
</span><span class='line'><span class="o">...</span>
</span><span class='line'><span class="p">(</span><span class="s">&#39;INFANT_BREASTFED&#39;</span><span class="p">,</span> <span class="n">typ</span><span class="o">.</span><span class="n">StringType</span><span class="p">())</span>
</span><span class='line'><span class="p">]</span>
</span><span class='line'><span class="n">schema</span> <span class="o">=</span> <span class="n">typ</span><span class="o">.</span><span class="n">StructType</span><span class="p">([</span>
</span><span class='line'><span class="n">typ</span><span class="o">.</span><span class="n">StructField</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">labels</span>
</span><span class='line'><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure>




<p>下一步，我们通过 <strong>.read.csv()</strong> 方法来载入数据，这个方法除了能够载入原数据之外还可以载入GZipped压缩后的csv数据。其实header参数设为 True 代表数据文件的第一行是数据的元信息（即为列表的说明字段）。</p>




<pre class="prettyprint"><code class="language-python hljs ">births = spark.read.csv(<span class="hljs-string">'births_train.csv.gz'</span>,
header=<span class="hljs-keyword">True</span>,
schema=schema)</code></pre>




<p>由于在我们的数据集中有大量的分类变量都是字符串，所以我们首先要想办法将这一类变量转换成数字的形式。</p>




<pre class="prettyprint"><code class=" hljs ruleslanguage"><span class="hljs-array"># </span>转换<span class="hljs-string">'INFANT_ALIVE_AT_REPORT'</span>
recode_dictionary = {
    <span class="hljs-string">'YNU'</span>: {
        <span class="hljs-string">'Y'</span>: <span class="hljs-number">1</span>,
        <span class="hljs-string">'N'</span>: <span class="hljs-number">0</span>,
        <span class="hljs-string">'U'</span>: <span class="hljs-number">0</span>
            }
}</code></pre>




<p>在这里总的来说，我们的目的就是一个二分类问题，即预测婴儿的存活情况，也就是“存活 1 ”或“死亡 0 ”。因为，要做到一种未雨绸缪的效果，我们要先去除所有与婴儿有关的特征信息，仅仅是通过婴儿父母的基本信息以及婴儿的出生地来预测一下婴儿出生后存活的概率。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">selected_features</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'><span class="s">&#39;INFANT_ALIVE_AT_REPORT&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;BIRTH_PLACE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_AGE_YEARS&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;FATHER_COMBINED_AGE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;CIG_BEFORE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;CIG_1_TRI&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;CIG_2_TRI&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;CIG_3_TRI&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_HEIGHT_IN&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_PRE_WEIGHT&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_DELIVERY_WEIGHT&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_WEIGHT_GAIN&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;DIABETES_PRE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;DIABETES_GEST&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;HYP_TENS_PRE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;HYP_TENS_GEST&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;PREV_BIRTH_PRETERM&#39;</span>
</span><span class='line'><span class="p">]</span>
</span><span class='line'><span class="n">births_trimmed</span> <span class="o">=</span> <span class="n">births</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<p>在这个数据集中，大量的变量特征值都是Yes/No/Unknown值，我们将Yes编码成1，另外的其他值编码成0。</p>




<p>而在代表怀孕妈妈的吸烟数量的这个特征值的编码上，我们采用这样的规则。0：代表妈妈在怀孕期间没有抽过烟；而1-97：代表妈妈在怀孕期间真实的抽烟次数，而98：则代表孕期抽烟次数高达98次及以上；但99：意味着妈妈的孕期抽烟情况未知。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">as</span> <span class="nn">func</span>
</span><span class='line'><span class="k">def</span> <span class="nf">recode</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
</span><span class='line'>  <span class="k">return</span> <span class="n">recode_dictionary</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">col</span><span class="p">]</span>
</span><span class='line'><span class="k">def</span> <span class="nf">correct_cig</span><span class="p">(</span><span class="n">feat</span><span class="p">):</span>
</span><span class='line'>  <span class="k">return</span> <span class="n">func</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">99</span><span class="p">,</span>
</span><span class='line'>      <span class="n">func</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feat</span><span class="p">))</span>\
</span><span class='line'>      <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>  <span class="n">rec_integer</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">udf</span><span class="p">(</span><span class="n">recode</span><span class="p">,</span><span class="n">typ</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">())</span>
</span></code></pre></td></tr></table></div></figure>




<p>由于Spark的机制问题，我们无法直接将DataFrame来用recode函数进行处理，所以我们首先要先它转换成Spark能够理解的UDF。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">births_transformed</span> <span class="o">=</span> <span class="n">births_trimmed</span> \
</span><span class='line'><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;CIG_BEFORE&#39;</span><span class="p">,</span> <span class="n">correct_cig</span><span class="p">(</span><span class="s">&#39;CIG_BEFORE&#39;</span><span class="p">))</span>\
</span><span class='line'><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;CIG_1_TRI&#39;</span><span class="p">,</span> <span class="n">correct_cig</span><span class="p">(</span><span class="s">&#39;CIG_1_TRI&#39;</span><span class="p">))</span>\
</span><span class='line'><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;CIG_2_TRI&#39;</span><span class="p">,</span> <span class="n">correct_cig</span><span class="p">(</span><span class="s">&#39;CIG_2_TRI&#39;</span><span class="p">))</span>\
</span><span class='line'><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;CIG_3_TRI&#39;</span><span class="p">,</span> <span class="n">correct_cig</span><span class="p">(</span><span class="s">&#39;CIG_3_TRI&#39;</span><span class="p">))</span>
</span><span class='line'><span class="n">cols</span> <span class="o">=</span> <span class="p">[(</span><span class="n">col</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">col</span><span class="o">.</span><span class="n">dataType</span><span class="p">)</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">births_trimmed</span><span class="o">.</span><span class="n">schema</span><span class="p">]</span>
</span><span class='line'><span class="n">YNU_cols</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>
</span><span class='line'><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cols</span><span class="p">):</span>
</span><span class='line'><span class="k">if</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">typ</span><span class="o">.</span><span class="n">StringType</span><span class="p">():</span>
</span><span class='line'><span class="n">dis</span> <span class="o">=</span> <span class="n">births</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> \
</span><span class='line'><span class="o">.</span><span class="n">distinct</span><span class="p">()</span> \
</span><span class='line'><span class="o">.</span><span class="n">rdd</span> \
</span><span class='line'><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span><span class='line'><span class="k">if</span> <span class="s">&#39;Y&#39;</span> <span class="ow">in</span> <span class="n">dis</span><span class="p">:</span>
</span><span class='line'>  <span class="n">YNU_cols</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure>




<p>最后，为了一次性转换所有的 YNU_cols 数据，我们用以下的方法：</p>




<pre class="prettyprint"><code class="language-python hljs ">exprs_YNU = [
    rec_integer(x,
    func.lit(<span class="hljs-string">'YNU'</span>)).alias(x)
    <span class="hljs-keyword">if</span> x <span class="hljs-keyword">in</span> YNU_cols
    <span class="hljs-keyword">else</span> x
    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> births_transformed.columns
]
births_transformed = births_transformed.select(exprs_YNU)</code></pre>




<p>让我们来检查一下转换的结果吧：</p>




<blockquote>
  <p>births_transformed.select(YNU_cols[-5:]).show(5)</p>
</blockquote>




<p><img src="https://ooo.0o0.ooo/2017/11/01/59f9cda7add15.png" alt="translate_res.png" title=""></p>




<h3 id="数据预分析">数据预分析</h3>




<p>为了建立一个良好的统计模型，我们首先需要了解清楚数据的组成分布以及背后的含义。</p>




<p>下面我们可以通过Spark提供的一些函数来对数据进行描述性分析。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pyspark.mllib.stat</span> <span class="kn">as</span> <span class="nn">st</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="n">numeric_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;MOTHER_AGE_YEARS&#39;</span><span class="p">,</span><span class="s">&#39;FATHER_COMBINED_AGE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;CIG_BEFORE&#39;</span><span class="p">,</span><span class="s">&#39;CIG_1_TRI&#39;</span><span class="p">,</span><span class="s">&#39;CIG_2_TRI&#39;</span><span class="p">,</span><span class="s">&#39;CIG_3_TRI&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_HEIGHT_IN&#39;</span><span class="p">,</span><span class="s">&#39;MOTHER_PRE_WEIGHT&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_DELIVERY_WEIGHT&#39;</span><span class="p">,</span><span class="s">&#39;MOTHER_WEIGHT_GAIN&#39;</span>
</span><span class='line'><span class="p">]</span>
</span><span class='line'><span class="n">numeric_rdd</span> <span class="o">=</span> <span class="n">births_transformed</span>\
</span><span class='line'>  <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">numeric_cols</span><span class="p">)</span>\
</span><span class='line'>  <span class="o">.</span><span class="n">rdd</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">[</span><span class="n">e</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">row</span><span class="p">])</span>
</span><span class='line'><span class="n">mllib_stats</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">Statistics</span><span class="o">.</span><span class="n">colStats</span><span class="p">(</span><span class="n">numeric_rdd</span><span class="p">)</span>
</span><span class='line'><span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">numeric_cols</span><span class="p">,</span>
</span><span class='line'>  <span class="n">mllib_stats</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
</span><span class='line'>  <span class="n">mllib_stats</span><span class="o">.</span><span class="n">variance</span><span class="p">()):</span>
</span><span class='line'>  <span class="k">print</span><span class="p">(</span><span class="s">&#39;{0}: </span><span class="se">\t</span><span class="s">{1:.2f} </span><span class="se">\t</span><span class="s"> {2:.2f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>




<p><img src="https://ooo.0o0.ooo/2017/11/01/59f9cf95819ec.png" alt="statics.png" title=""></p>




<p>根据输出的统计结果我们可以看出：在婴儿父母的年龄对比上，妈妈是明显比爸爸年轻的。妈妈的平均年龄在28岁左右，而爸爸的平均年龄确是44岁。</p>




<p>对于大部分的分类变量，我们也可以一一的来统计下他们的各个数值出现的频数：</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">categorical_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">births_transformed</span><span class="o">.</span><span class="n">columns</span>
</span><span class='line'><span class="k">if</span> <span class="n">e</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">numeric_cols</span><span class="p">]</span>
</span><span class='line'><span class="n">categorical_rdd</span> <span class="o">=</span> <span class="n">births_transformed</span>\
</span><span class='line'>  <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">categorical_cols</span><span class="p">)</span>\
</span><span class='line'>  <span class="o">.</span><span class="n">rdd</span> \
</span><span class='line'>  <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">[</span><span class="n">e</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">row</span><span class="p">])</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">categorical_cols</span><span class="p">):</span>
</span><span class='line'>  <span class="n">agg</span> <span class="o">=</span> <span class="n">categorical_rdd</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> \
</span><span class='line'>      <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
</span><span class='line'>  <span class="k">print</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">agg</span><span class="o">.</span><span class="n">collect</span><span class="p">(),</span>
</span><span class='line'><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">el</span><span class="p">:</span> <span class="n">el</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
</span><span class='line'><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<p><img src="https://ooo.0o0.ooo/2017/11/01/59f9d1109a62e.png" alt="frequence.png" title=""></p>




<p>根据这次的结果，我们又可以看出大部分的婴儿都是在医院出现的（医院的出生地代号BIRTH_PLACE=1）</p>




<h3 id="相关系数">相关系数</h3>




<p>相关性的分析有利于我们发现特征变量中的多重共线性的情况，而多重共线性则是影响我们模型的鲁棒性的关键因素之一。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">corrs</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">Statistics</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">numeric_rdd</span><span class="p">)</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">el</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">corrs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">):</span>
</span><span class='line'>  <span class="n">correlated</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'>      <span class="p">(</span><span class="n">numeric_cols</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">corrs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
</span><span class='line'>      <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">el</span><span class="p">)</span>
</span><span class='line'>      <span class="k">if</span> <span class="n">e</span> <span class="o">==</span> <span class="mf">1.0</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">!=</span> <span class="n">i</span><span class="p">]</span>
</span><span class='line'>  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">correlated</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>      <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">correlated</span><span class="p">:</span>
</span><span class='line'>          <span class="k">print</span><span class="p">(</span><span class="s">&#39;{0}-to-{1}: {2:.2f}&#39;</span> \
</span><span class='line'>          <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">numeric_cols</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span></code></pre></td></tr></table></div></figure>




<p>上面的代码会替我们计算特征变量之间的相关系数矩阵，并输出相关系数高于0.5的特征。</p>




<p><img src="https://ooo.0o0.ooo/2017/11/01/59f9d3831bd0f.png" alt="cor_matrix.png" title=""></p>




<p>根据上图输出的结果，我们又可以看出 CIG_XXX 系列的特征都有些非常高的相关性，所以在这个系列的特征之中保留一个即可。 在这里我只保留 <strong>CIG_1_TRI</strong>这个特征。同理在WEIGHT系列中我只保留<strong>MOTHER_PRE_WEIGHT</strong>这个特征。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">features_to_keep</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'><span class="s">&#39;INFANT_ALIVE_AT_REPORT&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;BIRTH_PLACE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_AGE_YEARS&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;FATHER_COMBINED_AGE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;CIG_1_TRI&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_HEIGHT_IN&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;MOTHER_PRE_WEIGHT&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;DIABETES_PRE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;DIABETES_GEST&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;HYP_TENS_PRE&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;HYP_TENS_GEST&#39;</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;PREV_BIRTH_PRETERM&#39;</span>
</span><span class='line'><span class="p">]</span>
</span><span class='line'><span class="n">births_transformed</span> <span class="o">=</span> <span class="n">births_transformed</span><span class="o">.</span><span class="n">select</span><span class="p">([</span><span class="n">e</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">features_</span>
</span><span class='line'><span class="n">to_keep</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure>




<h3 id="小结">小结</h3>




<p>在这一篇实战的文章中，我讲解了：</p>




<ul>
<li>数据的载入和转换</li>
<li>数据的描述性分析</li>
<li>数据相关性分析</li>
</ul>




<p>限于时间和篇幅，我打算将有关分类变量的统计检验分析，以及最后的特征选取和建模放在下一篇文章之中，欢迎大家继续阅读我的下一篇文件。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/11/17/pythonzai-sparkshang-de-ji-qi-xue-xi-zhi-ji-qi-xue-xi-shi-zhan-shang/">Python在Spark上的机器学习之机器学习实战(上)</a>
      <time datetime="2017-11-17T09:16:10+08:00" pubdate><span class='month'>Nov</span> <span class='day'>17</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/pyspark-and-spark/'>pyspark&spark</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/11/10/shen-ru-li-jie-spark-bian-cheng-mo-xing/">深入理解Spark 编程模型</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-11-10T13:14:53+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="深入理解spark-编程模型">深入理解Spark 编程模型</h1></p>

<h2 id="spark的编程模型">Spark的编程模型</h2>




<p>Spark的应用程序主要由两部分组成：</p>




<ul>
<li>Driver</li>
<li>Executor</li>
</ul>




<p>除此之外，在Spark的编程模型的构成还包括许多其他的成分，如：<strong>SparkContext</strong>，这是Spark的应用程序的入口，负责调度各个运算资源，协调各个Worker节点上的Executor；</p>




<p>而<strong>Dirver program</strong>则负责运行Spark应用的main()函数并创建SparkContext，通常情况下，我们用SparkContext来指代Driver program。</p>




<p><strong>Executor</strong>：这是Spark应用中运行在Work Node上的一个进程，该进程负责运行Task，并且负责将数据存在内存和磁盘上，每个应用都会申请自己的Executors来负责调度和处理。</p>




<p>其次，在Spark编程模型中还有以下重要的概念，需要了解：</p>




<ul>
<li><strong>Application</strong>：Spark的应用程序，包含一个Driver program 和 若干个Executor</li>
<li><strong>Cluster Manager</strong>：在集群上获取资源的外部服务</li>
<li><strong>Work Node</strong>：集群中任何可以运行Application代码的节点，其中运行着一个或多个Executor进程。</li>
<li><strong>Job</strong>：可以被拆分成Task的并行计算的工作单元，一般由Spark Action触发的一次执行作业</li>
<li><strong>Stage</strong>：每个Job会被拆分成很多个Task，而每组任务就被称作Stage（相当于一个TaskSet）</li>
<li><strong>Task</strong>：运行在Executor上的工作单元</li>
<li><strong>RDD</strong>：弹性分布式数据集的简称，是Spark的最核心的模块和类之一</li>
</ul>




<h2 id="hadoop数据集">Hadoop数据集</h2>




<p>Spark可以将任何Hadoop所支持的存储资源转化成RDD，例如：本地文件，HDFS，Cassandra，HBase等。同时，Spark不仅支持文本文件和SequenceFiles还兼容任何Hadoop InputFormat的格式。</p>




<h3 id="textfile方法">textFile()方法</h3>




<p>使用textFile()可以将本地文件或HDFS文件转化成RDD</p>




<p><strong>读取整个文件目录</strong></p>




<blockquote>
  <p>textFile(“file:///hfds/directory”)</p>
</blockquote>




<p><strong>读取文本或压缩文件（可以自动执行解压缩并加载文件数据）</strong></p>




<blockquote>
  <p>textFile(“file:///hfds/directory/data.gz”)</p>
</blockquote>




<p><strong>使用通配符进行读取</strong></p>




<blockquote>
  <p>textFile(“file:///hfds/data/*.csv”)</p>
</blockquote>




<p>对于其他格式数据的读取有以下的方法：</p>




<ul>
<li><strong>wholeTextFiles()</strong>:读取目录里的小文件，返回由（用户名，内容）结构构成的键值对</li>
<li><strong>sequenceFile<a href="">K,V</a></strong>:可以将SequenceFile转换成RDD</li>
<li><strong>SparkContext.hadoopRDD</strong>:可以将其他任何Hadoop输入类型转换成RDD使用</li>
</ul>




<h2 id="rdd">RDD</h2>




<p><strong>RDD</strong>，弹性分布数据集，是Spark最核心的东西，他表示已被分区，不可变的并能够被并行操作的数据集合，不同的数据集格式对应着不同的RDD的实现。RDD的前提是其必须是可序列化的，同时RDD可以cache到内存之中</p>




<h3 id="特点">特点</h3>




<ol>
<li>只能通过转换操作（如map/filter/groupBy/join等）来从规定数据源（稳定存储的数据或其他RDD）中创建RDD</li>
<li>状态不可变，即不能修改</li>
<li>容错性强，由于RDD中的元素会根据key来分区，并保存在多个节点上，还原时只会重新计算丢失的分区的数据，不会影响整个系统的使用</li>
<li>RDD中会保存他的继承信息，即关于它是如何从其他RDD中生成的信息</li>
<li>被重用的RDD会缓存在内存中，或溢出至磁盘作持久化存储</li>
<li>Spark会延迟计算RDD，这样RDD就能够转换管道化（pipeline）</li>
<li>有丰富的动作（action）如：count/reduce/collect/save等支持</li>
<li>惰性求值，即执行了多少次transformation操作，RDD都不会真正执行运算，而只有action操作执行时，运算才会触发</li>
</ol>




<h2 id="rdd的元数据">RDD的元数据</h2>




<p>每个RDD都包含了5部分的信息，他们包括数据分区的集合，能根据本地性快速访问数据的偏好位置（最佳位置），依赖关系，计算方法（函数），分区策略。</p>




<p>示例：</p>




<p><img src="https://i.loli.net/2017/11/10/5a04866bbb6c5.png" alt="rdd_meta.png" title=""></p>




<h2 id="rdd的操作">RDD的操作</h2>




<p>RDD中的操作主要分为两大类：</p>




<ul>
<li><strong>转换(transformation):</strong>现有的RDD通过转换来生成一个新的RDD，转换是延迟执行（惰性求值）的。</li>
<li><strong>动作(actions):</strong>在RDD上执行动作后，就会运行计算，然后返回结果给驱动程序或者写入文件系统，从而触发Job。</li>
</ul>




<p>常用transformation：</p>




<p><img src="https://i.loli.net/2017/11/10/5a0487f0527d5.png" alt="rdd_transformation.png" title=""></p>




<p>常用actions：</p>




<p><img src="https://i.loli.net/2017/11/10/5a0487f047dab.png" alt="rdd_actions.png" title=""></p>




<h3 id="持久化">持久化</h3>




<p>缓存的操作 <br>
使用<strong>persist</strong>和<strong>cache</strong>方法可以将任意RDD缓存在内存或磁盘文件中，缓存不仅可以加速RDD的读取速度同时兼备了容错性，可以通过构建他的transformation自动重构。</p>




<p><strong>缓存</strong>是Spark最重要的一个功能，就是在不同操作间，持久化（或缓存）一个数据集在内存中。当你持久化一个RDD，每一个结点都将把它的计算分块结果保存在内存中，并在对此数据集（或者衍生出的数据集）进行的其它动作中重用。这将使得后续的动作(actions)变得更加迅速（通常快10倍）。所以缓存是用Spark构建迭代算法的关键。</p>




<p>如果你需要删除被持久化的RDD，可以用unpersistRDD()来完成该工作。</p>




<p>此外，每一个RDD都可以用不同的保存级别进行保存，从而允许你持久化数据集在硬盘，或者在内存作为序列化的Java对象（节省空间），甚至于跨结点复制。这些等级选择，是通过将一个<strong>org.apache.spark.storage.StorageLevel</strong>对象传递给persist()方法进行确定。</p>




<p>cache()方法是使用默认存储级别的快捷方法，也就是StorageLevel.MEMORY_ONLY(将反序列化的对象存入内存）。</p>




<p>StorageLevel有五个属性，分别是：</p>




<ul>
<li>useDisk_是否使用磁盘</li>
<li>useMemory_是否使用内存</li>
<li>useOffHeap_是否使用堆外内存如：Tachyon</li>
<li>deserialized_是否进行反序列化</li>
<li>replication_备份数目。</li>
</ul>




<p><strong>存储级别的选择</strong> <br>
Spark的不同存储级别，旨在满足内存使用和CPU效率权衡上的不同需求。我们建议通过以下的步骤来进行选择：</p>




<ul>
<li>如果你的RDDs可以很好的与默认的存储级别(MEMORY_ONLY)契合，就不需要做任何修改了。这已经是CPU使用效率最高的选项，它使得RDDs的操作尽可能的快。</li>
<li>如果不行，试着使用MEMORY_ONLY_SER并且选择一个快速序列化的库使得对象在有比较高的空间使用率的情况下，依然可以较快被访问。</li>
<li>尽可能不要存储到硬盘上，除非计算数据集的函数，计算量特别大，或者它们过滤 <br>
了大量的数据。否则，重新计算一个分区的速度，和与从硬盘中读取基本差不多快。</li>
</ul>



</div>
  
  


      <footer>
      
      - <a href="/blog/2017/11/10/shen-ru-li-jie-spark-bian-cheng-mo-xing/">深入理解Spark 编程模型</a>
      <time datetime="2017-11-10T13:14:53+08:00" pubdate><span class='month'>Nov</span> <span class='day'>10</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/pyspark-and-spark/'>pyspark&spark</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/11/04/pythonzai-sparkshang-de-ji-qi-xue-xi-si-zhi-ke-shi-hua-gong-ju-de-jie-shao-yu-pysparkde-jie-he-shi-yong-shi-li/">Python在Spark上的机器学习(四)之可视化工具的介绍与PySpark的结合使用示例</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-11-04T23:20:17+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="python在spark上的机器学习四之可视化工具的介绍与pyspark的结合使用示例">Python在Spark上的机器学习(四)之可视化工具的介绍与PySpark的结合使用示例</h1></p>

<h2 id="前言">前言</h2>




<p>在Python和Java的生态圈中，有许多可用的可视化库，但是在这篇文章中，我们主要来介绍一下matplotlib 和 Bokeh的使用。</p>




<p>首先，这两个库都是<a href="https://www.anaconda.com/">Anaconda</a>预装的。如果你是通过Anaconda来搭建的Python的科学计算环境的话，直接就可以通过import导入来使用这两个库了。</p>




<p>但是如果还没安装和配置好环境的朋友，可以自行参考<a href="http://matplotlib.org/index.html">Matplotlib</a>和<a href="https://bokeh.pydata.org/en/latest/">Bokeh</a>的官方站点的教程来下载配置环境。</p>




<blockquote>
  <p>注：这一类对各系统平台支持良好的库，一般安装流程也就无非两条pip命令，如： <br>
  python -mpip install -U pip <br>
  python -mpip install -U matplotlib <br>
  pip install bokeh <br>
  或 <br>
  conda install bokeh <br>
  所以各位读者也没有必要担心配置麻烦。</p>
</blockquote>




<h2 id="有关matplotlib和bokeh的介绍">有关matplotlib和bokeh的介绍</h2>




<h3 id="matplotlib">Matplotlib</h3>




<p><strong>Matplotlib</strong>是一个Python 2D绘图库，可以跨平台生成各种通用格式和适用于交互式环境的高质量图表。 Matplotlib可直接用于Python脚本，IPython shell，Jupyter以及Web应用程序服务器之中。 <br>
<strong>Matplotlib</strong>简化了许多繁琐的绘图操作，使得原本简单的图表在绘制上更加简单，而复杂的图表绘制也更容易上手。只需几行代码即可生成许多好看的图表。如，直方图、功率谱、条形图、错误图，散点图等。</p>




<p>官方绘图预览：</p>




<p><img src="http://matplotlib.org/_images/sphx_glr_simple_plot_0011.png" alt="enter image description here" title=""> <br>
<img src="http://matplotlib.org/_images/sphx_glr_histogram_features_0011.png" alt="enter image description here" title=""></p>




<p><img src="http://matplotlib.org/_images/sphx_glr_barchart_demo_0011.png" alt="enter image description here" title=""> <br>
<img src="http://matplotlib.org/_images/sphx_glr_pie_features_0011.png" alt="enter image description here" title=""></p>




<h3 id="bokeh">Bokeh</h3>




<p><strong>Bokeh</strong> (Bokeh.js) 是一个 Python 交互式可视化库，支持现代化 Web 浏览器，提供非常完美的展示功能。Bokeh 的目标是使用 D3.js 样式提供优雅，简洁新颖的图形化风格，同时提供大型数据集的高性能交互功能。Boken 可以快速的创建交互式的绘图，仪表盘和数据应用。</p>




<p>鉴于Bokeh强调的更多是一种交互式的绘图体验，在这里我就不貼静态图了，不过下面我会附上一些官方demo的例子，让大家感受下Bokeh的强大之处。</p>




<p><a href="https://bokeh.pydata.org/en/latest/docs/gallery/stocks.html">趋势走向图</a></p>




<p><a href="https://bokeh.pydata.org/en/latest/docs/gallery/iris.html">散点图</a></p>




<p><a href="https://bokeh.pydata.org/en/latest/docs/gallery/texas.html">地域分布图</a></p>




<p><a href="https://bokeh.pydata.org/en/latest/docs/gallery/boxplot.html">箱型图</a></p>




<h2 id="结合pyspark进行可视化分析">结合PySpark进行可视化分析</h2>




<h3 id="模块加载">模块加载</h3>




<p>以下实验均在Jupyter环境下进行 <br>
<strong>matplotlib</strong></p>




<pre class="prettyprint"><code class="language-python hljs ">%matplotlib inline
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
plt.style.use(<span class="hljs-string">'ggplot'</span>)</code></pre>




<p><strong>bokeh</strong></p>




<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-keyword">import</span> bokeh.charts <span class="hljs-keyword">as</span> chrt
<span class="hljs-keyword">from</span> bokeh.io <span class="hljs-keyword">import</span> output_notebook
output_notebook()</code></pre>




<h3 id="频率分布分析">频率分布分析</h3>




<p>频率分布图是最为简单有效的观察数据的分布情况的方法之一。</p>




<h4 id="读取数据">读取数据</h4>




<p>本文用到的数据文件依旧是上文所提及的信用欺诈检测的数据集，具体下载地址：<a href="http://tomdrabas.com/data/LearningPySpark/ccFraud.csv.gz">这里</a></p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pyspark.sql.types</span> <span class="kn">as</span> <span class="nn">typ</span>
</span><span class='line'><span class="n">fraud</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">&#39;/home/ef/Desktop/learningPySpark-master/ccFraud.csv&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">header</span> <span class="o">=</span> <span class="n">fraud</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
</span><span class='line'><span class="n">fraud</span> <span class="o">=</span> <span class="n">fraud</span> \
</span><span class='line'><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span> <span class="o">!=</span> <span class="n">header</span><span class="p">)</span> \
</span><span class='line'><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">row</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;,&#39;</span><span class="p">)])</span>
</span><span class='line'><span class="n">fields</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'><span class="o">*</span><span class="p">[</span>
</span><span class='line'><span class="n">typ</span><span class="o">.</span><span class="n">StructField</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">typ</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span>
</span><span class='line'><span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">header</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;,&#39;</span><span class="p">)</span>
</span><span class='line'><span class="p">]</span>
</span><span class='line'><span class="p">]</span>
</span><span class='line'><span class="n">schema</span> <span class="o">=</span> <span class="n">typ</span><span class="o">.</span><span class="n">StructType</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span>
</span><span class='line'><span class="n">fraud_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">fraud</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
</span><span class='line'><span class="n">hists</span> <span class="o">=</span> <span class="n">fraud_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;balance&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span>
</span><span class='line'><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span>
</span><span class='line'><span class="p">)</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">fraud_df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出： <br>
  root <br>
   |– custID: integer (nullable = true) <br>
   |– gender: integer (nullable = true) <br>
   |– state: integer (nullable = true) <br>
   |– cardholder: integer (nullable = true) <br>
   |– balance: integer (nullable = true) <br>
   |– numTrans: integer (nullable = true) <br>
   |– numIntlTrans: integer (nullable = true) <br>
   |– creditLine: integer (nullable = true) <br>
   |– fraudRisk: integer (nullable = true)</p>
</blockquote>




<h4 id="绘制频率分布直方图">绘制频率分布直方图</h4>




<p><strong>matplotlib</strong></p>




<pre class="prettyprint"><code class="language-python hljs ">data = {
<span class="hljs-string">'bins'</span>: hists[<span class="hljs-number">0</span>][:-<span class="hljs-number">1</span>],
<span class="hljs-string">'freq'</span>: hists[<span class="hljs-number">1</span>]
}
plt.bar(data[<span class="hljs-string">'bins'</span>], data[<span class="hljs-string">'freq'</span>], width=<span class="hljs-number">2000</span>)
plt.title(<span class="hljs-string">'Histogram of \'balance\''</span>)
plt.show()</code></pre>




<blockquote>
  <p>输出: <br>
  <img src="https://ooo.0o0.ooo/2017/10/27/59f2fbe5dc612.png" alt="mat_hist.png" title=""></p>
</blockquote>




<p><strong>bokeh</strong></p>




<pre class="prettyprint"><code class="language-python hljs ">data = {
<span class="hljs-string">'bins'</span>: hists[<span class="hljs-number">0</span>][:-<span class="hljs-number">1</span>],
<span class="hljs-string">'freq'</span>: hists[<span class="hljs-number">1</span>]
}
b_hist = chrt.Bar(
data,
values=<span class="hljs-string">'freq'</span>, label=<span class="hljs-string">'bins'</span>,
title=<span class="hljs-string">'Histogram of \'balance\''</span>)
chrt.show(b_hist)</code></pre>




<blockquote>
  <p>输出: <br>
  <img src="https://ooo.0o0.ooo/2017/10/27/59f2fbe5e1f34.png" alt="bokeh_hist.png" title=""></p>
</blockquote>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/11/04/pythonzai-sparkshang-de-ji-qi-xue-xi-si-zhi-ke-shi-hua-gong-ju-de-jie-shao-yu-pysparkde-jie-he-shi-yong-shi-li/">Python在Spark上的机器学习(四)之可视化工具的介绍与PySpark的结合使用示例</a>
      <time datetime="2017-11-04T23:20:17+08:00" pubdate><span class='month'>Nov</span> <span class='day'>04</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/pyspark-and-spark/'>pyspark&spark</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/10/27/pythonzai-sparkshang-de-ji-qi-xue-xi-san-zhi-tong-ji-fen-xi/">Python在Spark上的机器学习(三)之统计分析</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-10-27T18:39:42+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="python在spark上的机器学习三之统计分析">Python在Spark上的机器学习(三)之统计分析</h1></p>

<h2 id="背景">背景</h2>




<p>通常来说，一个完整使用机器学习建模解决问题的过程包含一下步骤：</p>




<ul>
<li>数据获取</li>
<li>数据预处理</li>
<li>数据统计分析</li>
<li>算法建模</li>
<li>训练</li>
<li>预测/分类</li>
</ul>




<p>这就意味着，在我们进行一般的数学建模或者挑选机器学习训练算法之前，应该先对数据进行清洗以及简单的统计分析，以便了解数据中显著的特征或者规律（虽然现在的机器学习方法，很多情况下根本不需要了解数据的意义，仅仅是通过堆叠特征就能获得一个可行的结果，但这显然离一个优秀的结果还是有一段距离的）。为了得到更加鲁棒的模型，以及了解数据背后的含义，我们这篇文章就来讲讲如何在PySpark上进行简单的统计分析。</p>




<h3 id="概念介绍">概念介绍</h3>




<p><strong>描述性统计分析</strong> <br>
这是一个统计学的概念，描述性统计是以揭示数据分布特性的方式汇总并表达定量数据的方法。主要包括数据的频数分析、数据的集中趋势分析、数据离散程度分析、数据的分布、以及一些基本的统计图形。特征括并表示定量数据，揭示数据分布的特征。 <br>
描述性统计是一类统计方法的汇总，作用是提供了一种概括和表征数据的有效且相对简便的方法。通常用图示法来表述，易于看懂，能发现质量特性值（总体）的分布状况、趋势走向的一些规律，便于采取措施。用于汇总和表征数据，通常是对数据进一步定量分析的基础，或是对推断性统计方法的有效补充。</p>




<h3 id="数据读取">数据读取</h3>




<p>本文使用的是一个信用欺诈检测的一个数据集，具体下载地址：<a href="http://tomdrabas.com/data/LearningPySpark/ccFraud.csv.gz">这里</a></p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">PySpark.sql.types</span> <span class="kn">as</span> <span class="nn">typ</span>
</span><span class='line'><span class="n">fraud</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">&#39;data/ccFraud.csv&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">header</span> <span class="o">=</span> <span class="n">fraud</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
</span><span class='line'><span class="n">fraud</span> <span class="o">=</span> <span class="n">fraud</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span><span class="n">row</span><span class="o">!=</span><span class="n">header</span><span class="p">)</span>\
</span><span class='line'><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:[</span><span class="nb">int</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">row</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;,&#39;</span><span class="p">)])</span>
</span><span class='line'><span class="n">fields</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'>    <span class="o">*</span><span class="p">[</span>
</span><span class='line'>        <span class="n">typ</span><span class="o">.</span><span class="n">StructField</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">typ</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">(),</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">header</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;,&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="p">]</span>
</span><span class='line'><span class="p">]</span>
</span><span class='line'><span class="n">schema</span> <span class="o">=</span> <span class="n">typ</span><span class="o">.</span><span class="n">StructType</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span>
</span><span class='line'><span class="n">fraud_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">fraud</span><span class="p">,</span><span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">)</span>
</span><span class='line'><span class="n">fraud_df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</span><span class='line'><span class="n">fraud_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  root <br>
   |– custID: integer (nullable = true) <br>
   |– gender: integer (nullable = true) <br>
   |– state: integer (nullable = true) <br>
   |– cardholder: integer (nullable = true) <br>
   |– balance: integer (nullable = true) <br>
   |– numTrans: integer (nullable = true) <br>
   |– numIntlTrans: integer (nullable = true) <br>
   |– creditLine: integer (nullable = true) <br>
   |– fraudRisk: integer (nullable = true) <br>
  Out: <br>
  Row(custID=1, gender=1, state=35, cardholder=1, balance=3000, numTrans=4, numIntlTrans=14, creditLine=2, fraudRisk=0)</p>
</blockquote>




<p>在上面的代码中，我们读入了我们的数据集，以及创建了一个DataFrame，下面我们再进行一些简单的分析操作。</p>




<h3 id="简单统计分析">简单统计分析</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">fraud_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">&#39;gender&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c">#按照性别分类汇总</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="n">numerical</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;balance&#39;</span><span class="p">,</span> <span class="s">&#39;numTrans&#39;</span><span class="p">,</span> <span class="s">&#39;numIntlTrans&#39;</span><span class="p">]</span>
</span><span class='line'><span class="n">desc</span> <span class="o">=</span> <span class="n">fraud_df</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">numerical</span><span class="p">)</span>
</span><span class='line'><span class="c">##对balance，numTrans，numIntTrans进行描述性分析</span>
</span><span class='line'><span class="n">desc</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c"># 计算balance值分布的偏度</span>
</span><span class='line'><span class="n">fraud_df</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s">&#39;balance&#39;</span><span class="p">:</span> <span class="s">&#39;skewness&#39;</span><span class="p">})</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  +——+——-+ <br>
  |gender|  count| <br>
  +——+——-+ <br>
  |     1|6178231| <br>
  |     2|3821769| <br>
  +——+——-+ <br>
  +——-+—————–+——————+—————–+ <br>
  |summary|          balance|          numTrans|     numIntlTrans| <br>
  +——-+—————–+——————+—————–+ <br>
  |  count|         10000000|          10000000|         10000000| <br>
  |   mean|     4109.9199193|        28.9351871|        4.0471899| <br>
  | stddev|3996.847309737258|26.553781024523122|8.602970115863904| <br>
  |    min|                0|                 0|                0| <br>
  |    max|            41485|               100|               60| <br>
  +——-+—————–+——————+—————–+ <br>
  +——————+ <br>
  | skewness(balance)| <br>
  +——————+ <br>
  |1.1818315552993839| <br>
  +——————+</p>
</blockquote>




<p>上面我们使用了一些常用的统计分析函数，以及简单地了解了一下PySpark 聚合函数agg()的使用。通常地，常用的聚合函数还有avg() , count(), countDistinct() , max() 等。</p>




<h3 id="相关分析">相关分析</h3>




<p><strong>相关分析</strong>（correlation analysis），相关分析是研究现象之间是否存在某种依存关系，并对具体有依存关系的现象探讨其相关方向以及相关程度，是研究随机变量之间的相关关系的一种统计方法。通常两个变量之间存在的相关关系有：正相关、完全正相关、负相关、完全负相关、无相关。</p>




<p><strong>相关系数</strong>是最早由统计学家卡尔·皮尔逊设计的统计指标，是研究变量之间线性相关程度的量，一般用字母 r 表示。由于研究对象的不同，相关系数有多种定义方式，较为常用的是皮尔逊相关系数。简单来说，相关系数是衡量两个变量间相关关系的指标。</p>




<p>在PySpark中计算两个变量之间的相关系数是非常简单的，往往只需要一条代码：</p>




<blockquote>
  <p>fraud_df.corr(‘balance’, ‘numTrans’)#计算balance和numTrans的相关系数</p>
</blockquote>




<p>输出</p>




<blockquote>
  <p>Out：0.0004452314017265385</p>
</blockquote>




<p>我们还可以通过下面的方法来创建一个相关矩阵。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">n_numerical</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">numerical</span><span class="p">)</span>
</span><span class='line'><span class="n">corr</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_numerical</span><span class="p">):</span>
</span><span class='line'>    <span class="n">temp</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">i</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n_numerical</span><span class="p">):</span>
</span><span class='line'>        <span class="n">temp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraud_df</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">numerical</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">numerical</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
</span><span class='line'>    <span class="n">corr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果; <br>
  [[1.0, 0.0004452314017265387, 0.0002713991339817875], [None, 1.0, -0.00028057128198165555], [None, None, 1.0]]</p>
</blockquote>




<p>正如输出结果所示，这个信用欺诈检测的数据集中的特征之间不存在过大的相关关系，基本全部都为相互独立关系。因此，在选择特征代入机器学习算法训练时，可以采用全部的变量。正也是统计分析的用处，可以帮助我们了解变量之间的线性相关关系，有利于帮住我们选取训练的特征变量。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/10/27/pythonzai-sparkshang-de-ji-qi-xue-xi-san-zhi-tong-ji-fen-xi/">Python在Spark上的机器学习(三)之统计分析</a>
      <time datetime="2017-10-27T18:39:42+08:00" pubdate><span class='month'>Oct</span> <span class='day'>27</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/pyspark-and-spark/'>pyspark&spark</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/10/22/pythonzai-sparkshang-de-ji-qi-xue-xi-er-zhi-shu-ju-cao-zuo/">Python在Spark上的机器学习(二)之数据操作</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-10-22T16:18:47+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="python在spark上的机器学习二之数据操作">Python在Spark上的机器学习(二)之数据操作</h1></p>

<h2 id="pyspark">PySpark</h2>




<p>PySpark 是 Spark 为 Python 开发者提供的 API。 <br>
Spark是用Scala语言写成的，Scala把要编译的东西编译为Java虚拟机（JVM）的字节码（bytecode）。Spark的开源社区开发了一个叫PySpark的工具库。它允许使用者用Python处理RDD。这多亏了一个叫Py4J的库，它让Python可以使用JVM的对象（比如RDD）。  <br>
Pyspark Internals这篇<a href="https://cwiki.apache.org/confluence/display/SPARK/PySpark+Internals">wiki</a>里介绍了pyspark的实现机制，大体是下面这张图就可以表示：</p>




<p><img src="http://i.imgur.com/YlI8AqEl.png" alt="enter image description here" title=""></p>




<h2 id="resilient-distributed-datasets">Resilient Distributed Datasets</h2>




<p>说到Spark上的数据模式，一定不能少的就是Spark中的核心：RDD了。与许多专有的大数据处理平台不同，Spark建立在统一抽象的RDD之上，使得它可以以基本一致的方式应对不同的大数据处理场景，包括MapReduce，Streaming，SQL，Machine Learning以及Graph等。这即Matei Zaharia所谓的“设计一个通用的编程抽象（Unified Programming Abstraction）。这正是Spark让人着迷的地方。</p>




<p><strong>RDD 具体是什么呢？</strong> <br>
RDD，全称Resilient Distributed Datasets，又称弹性分布式数据集。是一个可容错的、并行的数据结构，可以让用户显示地将数据储存到磁盘和内存当中，并能控制数据的分区。</p>




<p>RDD本质上是一个内存数据集，在访问RDD时，指针只会指向与操作相关的部分。例如存在一个面向列的数据结构，其中一个实现为Int的数组，另一个实现为Float的数组。如果只需要访问Int字段，RDD的指针可以只访问Int数组，避免了对整个数据结构的扫描。</p>




<p>RDD将操作分为两类：transformation与action。无论执行了多少次transformation操作，RDD都不会真正执行运算，只有当action操作被执行时，运算才会触发。而在RDD的内部实现机制中，底层接口则是基于迭代器的，从而使得数据访问变得更高效，也避免了大量中间结果对内存的消耗。</p>




<h2 id="使用pyspark">使用Pyspark</h2>




<p>在按照系列的上一个教程搭建好环境后，在终端中直接输入pyspark就可以运行Python与Spark的交互式的shell了。</p>




<p>那么，下面我们就以一些简单的例子来使用pyspark。</p>




<h3 id="创建rdd">创建RDD</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span>
</span><span class='line'>    <span class="p">[(</span><span class="s">&#39;Amber&#39;</span><span class="p">,</span> <span class="mi">22</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;Alfred&#39;</span><span class="p">,</span> <span class="mi">23</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;Skye&#39;</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;Albert&#39;</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
</span><span class='line'>     <span class="p">(</span><span class="s">&#39;Amber&#39;</span><span class="p">,</span> <span class="mi">9</span><span class="p">)])</span>
</span><span class='line'><span class="n">data</span>
</span></code></pre></td></tr></table></div></figure>




<p>输出：</p>




<blockquote>
  <p>ParallelCollectionRDD[3] at parallelize at PythonRDD.scala:475</p>
</blockquote>




<h3 id="rdd对象转换成python对象">RDD对象转换成Python对象</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">data_heterogenous</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([(</span><span class="s">&#39;Ferrari&#39;</span><span class="p">,</span> <span class="s">&#39;fast&#39;</span><span class="p">),</span> <span class="p">{</span><span class="s">&#39;Porsche&#39;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">},</span> <span class="p">[</span><span class="s">&#39;Spain&#39;</span><span class="p">,</span><span class="s">&#39;visited&#39;</span><span class="p">,</span> <span class="mi">4504</span><span class="p">]])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span><span class='line'><span class="n">data_heterogenous</span>
</span></code></pre></td></tr></table></div></figure>


<p>输出：</p>




<blockquote>
  <p>[(‘Ferrari’, ‘fast’), {‘Porsche’: 100000}, [‘Spain’, ‘visited’, 4504]]</p>
</blockquote>




<h3 id="读取文件及统计词频">读取文件及统计词频</h3>




<p>首先word.txt文件内容如下：</p>




<blockquote>
  <p>The dynamic lifestyle <br>
  people lead nowadays <br>
  causes many reactions <br>
   in our bodies and <br>
   the one that is the <br>
   most frequent of all <br>
   is the headache. However so good</p>
</blockquote>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">add</span>
</span><span class='line'><span class="n">lines</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">&#39;word.txt&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">counts</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39; &#39;</span><span class="p">))</span>\
</span><span class='line'><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>\
</span><span class='line'><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="n">add</span><span class="p">)</span>
</span><span class='line'><span class="n">output</span> <span class="o">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span><span class='line'><span class="k">for</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span> <span class="ow">in</span> <span class="n">output</span><span class="p">:</span>
</span><span class='line'>    <span class="k">print</span><span class="p">(</span><span class="s">&quot;</span><span class="si">%s</span><span class="s">: </span><span class="si">%i</span><span class="s">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">count</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<p>输出：</p>




<blockquote>
  <p>[(”, 4), (‘good’, 1), (‘in’, 1), (‘is’, 2), (‘However’, 1), (‘of’, 1), (‘causes’, 1), (‘lifestyle’, 1), (‘The’, 1), (‘headache.’, 1), (‘reactions’, 1), (‘most’, 1), (‘frequent’, 1), (‘that’, 1), (‘all’, 1), (‘our’, 1), (‘dynamic’, 1), (‘nowadays’, 1), (‘so’, 1), (‘the’, 3), (‘people’, 1), (‘bodies’, 1), (‘many’, 1), (‘one’, 1), (‘and’, 1), (‘lead’, 1)] <br>
  …</p>
</blockquote>




<h2 id="dataframe">DataFrame</h2>




<p>DataFrameDataFrame是Spark推荐的统一结构化数据接口，是一个不可变的分布式数据集合，它结构与关系数据库中的表类似。</p>




<p>类似于Python Pandas DataFrame或R DataFrame，它能够让用户轻松处理结构化数据。</p>




<p>DataFrame还允许用户通过Spark SQL数据库或者采用一些函数式的方法查询及操作结构数据，下面我们就通过一些例子来了解和使用DataFrame。</p>




<h3 id="创建dataframes">创建DataFrames</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">stringJSONRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">((</span><span class="s">&quot;&quot;&quot;</span>
</span><span class='line'><span class="s">{ &quot;id&quot;: &quot;123&quot;,</span>
</span><span class='line'><span class="s">&quot;name&quot;: &quot;Katie&quot;,</span>
</span><span class='line'><span class="s">&quot;age&quot;: 19,</span>
</span><span class='line'><span class="s">&quot;eyeColor&quot;: &quot;brown&quot;</span>
</span><span class='line'><span class="s">}&quot;&quot;&quot;</span><span class="p">,</span>
</span><span class='line'><span class="sd">&quot;&quot;&quot;{</span>
</span><span class='line'><span class="sd">&quot;id&quot;: &quot;234&quot;,</span>
</span><span class='line'><span class="sd">&quot;name&quot;: &quot;Michael&quot;,</span>
</span><span class='line'><span class="sd">&quot;age&quot;: 22,</span>
</span><span class='line'><span class="sd">&quot;eyeColor&quot;: &quot;green&quot;</span>
</span><span class='line'><span class="sd">}&quot;&quot;&quot;</span><span class="p">,</span>
</span><span class='line'><span class="sd">&quot;&quot;&quot;{</span>
</span><span class='line'><span class="sd">&quot;id&quot;: &quot;345&quot;,</span>
</span><span class='line'><span class="sd">&quot;name&quot;: &quot;Simone&quot;,</span>
</span><span class='line'><span class="sd">&quot;age&quot;: 23,</span>
</span><span class='line'><span class="sd">&quot;eyeColor&quot;: &quot;blue&quot;</span>
</span><span class='line'><span class="sd">}&quot;&quot;&quot;</span><span class="p">)</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'><span class="n">swimmersJSON</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="n">stringJSONRDD</span><span class="p">)</span>
</span><span class='line'><span class="n">swimmersJSON</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="n">swimmersJSON</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s">&quot;swimmersJSON&quot;</span><span class="p">)</span> <span class="c">#这里创建了临时表</span>
</span></code></pre></td></tr></table></div></figure>




<p>输出：</p>




<blockquote>
  <p>+—+——–+—+——-+ <br>
  |age|eyeColor| id|   name| <br>
  +—+——–+—+——-+ <br>
  | 19|   brown|123|  Katie| <br>
  | 22|   green|234|Michael| <br>
  | 23|    blue|345| Simone| <br>
  +—+——–+—+——-+</p>
</blockquote>




<h3 id="dataframe的简单内容及类型查询">DataFrame的简单内容及类型查询</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s">&quot;select * from swimmersJSON&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span><span class='line'><span class="n">swimmersJSON</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span> <span class="c">#显示表数据的类型</span>
</span></code></pre></td></tr></table></div></figure>




<p>输出：</p>




<blockquote>
  <p>[Row(age=19, eyeColor=’brown’, id=’123’, name=’Katie’), <br>
   Row(age=22, eyeColor=’green’, id=’234’, name=’Michael’), <br>
   Row(age=23, eyeColor=’blue’, id=’345’, name=’Simone’)] <br>
   root <br>
   |– age: long (nullable = true) <br>
   |– eyeColor: string (nullable = true) <br>
   |– id: string (nullable = true) <br>
   |– name: string (nullable = true)</p>
</blockquote>




<h3 id="指定数据储存及处理的类型">指定数据储存及处理的类型</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># Import types</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>
</span><span class='line'><span class="c"># Generate comma delimited data</span>
</span><span class='line'><span class="n">stringCSVRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span>
</span><span class='line'><span class="p">(</span><span class="mi">123</span><span class="p">,</span> <span class="s">&#39;Katie&#39;</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="s">&#39;brown&#39;</span><span class="p">),</span>
</span><span class='line'><span class="p">(</span><span class="mi">234</span><span class="p">,</span> <span class="s">&#39;Michael&#39;</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="s">&#39;green&#39;</span><span class="p">),</span>
</span><span class='line'><span class="p">(</span><span class="mi">345</span><span class="p">,</span> <span class="s">&#39;Simone&#39;</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="s">&#39;blue&#39;</span><span class="p">)</span>
</span><span class='line'><span class="p">])</span>
</span><span class='line'><span class="c"># Specify schema</span>
</span><span class='line'><span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
</span><span class='line'><span class="n">StructField</span><span class="p">(</span><span class="s">&quot;id&quot;</span><span class="p">,</span> <span class="n">LongType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
</span><span class='line'><span class="n">StructField</span><span class="p">(</span><span class="s">&quot;name&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
</span><span class='line'><span class="n">StructField</span><span class="p">(</span><span class="s">&quot;age&quot;</span><span class="p">,</span> <span class="n">LongType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
</span><span class='line'><span class="n">StructField</span><span class="p">(</span><span class="s">&quot;eyeColor&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span>
</span><span class='line'><span class="p">])</span>
</span><span class='line'><span class="c"># Apply the schema to the RDD and Create DataFrame</span>
</span><span class='line'><span class="n">swimmers</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">stringCSVRDD</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
</span><span class='line'><span class="c"># Creates a temporary view using the DataFrame</span>
</span><span class='line'><span class="n">swimmers</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s">&quot;swimmers&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">swimmers</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<p>输出：</p>




<blockquote>
  <p>root <br>
   |– id: long (nullable = true) <br>
   |– name: string (nullable = true) <br>
   |– age: long (nullable = true) <br>
   |– eyeColor: string (nullable = true)</p>
</blockquote>




<p><strong>明明可以自动匹配储存类型，为什么我们还要手动指定类型呢？</strong> <br>
因为，在自动匹配类型的情况下，有时会将ID，Age等我们未来将要用来计算的数据以String的方式存储，这样就不利于我们对这些数据进行加减等运算，所以手动指定储存类型还是很有必要的。</p>




<h3 id="使用sql语句查询及操作数据">使用SQL语句查询及操作数据</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s">&quot;select count(1) from swimmers&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s">&quot;select id, age from swimmers where age = 22&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span>
</span><span class='line'><span class="s">&quot;select name, eyeColor from swimmers where eyeColor like &#39;b%&#39;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<p>输出：</p>




<blockquote>
  <p>+——–+ <br>
  |count(1)| <br>
  +——–+ <br>
  |       3| <br>
  +——–+</p>
  
  <p>+—+—+ <br>
  | id|age| <br>
  +—+—+ <br>
  |234| 22| <br>
  +—+—+</p>
  
  <p>+——+——–+ <br>
  |  name|eyeColor| <br>
  +——+——–+ <br>
  | Katie|   brown| <br>
  |Simone|    blue| <br>
  +——+——–+</p>
</blockquote>




<h2 id="小结">小结</h2>




<p>在这篇文章中我们可以看出，通过Pyspark结合RDD与DataFrames让我们可以用Python用上Spark平台上的分布式优势，也能够进一步加速和优化我们平时的数据操作。通过Spark导出的抽象层的API我们无需学过过于复杂和繁多的语法就能操作RDD上的数据。这篇文章的内容主要是为了后面用在用Python在Spark进行数据建模和机器学习所铺路，但受限于文章篇幅，还有十分多的函数和API无提及。所以有兴趣的读者可以阅读下<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark DataFrame的官方文档</a>深入了解一下。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/10/22/pythonzai-sparkshang-de-ji-qi-xue-xi-er-zhi-shu-ju-cao-zuo/"> Python在Spark上的机器学习(二)之数据操作</a>
      <time datetime="2017-10-22T16:18:47+08:00" pubdate><span class='month'>Oct</span> <span class='day'>22</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/pyspark-and-spark/'>pyspark&spark</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/10/16/pythonzai-sparkshang-de-ji-qi-xue-xi-%5B%3F%5D-zhi-huan-jing-da-jian/">Python在Spark上的机器学习(一)之环境搭建</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-10-16T14:07:29+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="python在spark上的机器学习一之环境搭建">Python在Spark上的机器学习(一)之环境搭建</h1></p>

<p>前面已经介绍了不少机器学习的算法了，那么机器学习又该如何结合大数据一起使用么？</p>




<h2 id="常言道工欲善其事必先利其器">常言道：工欲善其事，必先利其器</h2>




<p>既然来结合大数据与机器学习，我们就不得不提Spark了。</p>




<p>首先，<a href="https://spark.apache.org/docs/latest/index.html">Apache Spark</a> 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。</p>




<p>Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。</p>




<p>讲了这么多Spark的优点，那么现在我们就先开始来搭建一个Spark 集群环境吧！</p>




<h3 id="安装基础环境">安装基础环境</h3>




<p><strong>1. Java1.8环境搭建</strong>（下载JDK1.8的）：</p>




<blockquote>
  <p>下载页面： <br>
  <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p>
</blockquote>




<p>安装过程可以参考<a href="http://www.linuxidc.com/Linux/2016-05/131348.htm">Linux公社给出的教程</a></p>




<p><strong>Ubuntu用户：</strong> <br>
Ubuntu用户可以通过添加PPA源再通过Apt来进行安装</p>




<blockquote>
  <p><span>$</span> sudo add-apt-repository ppa:webupd8team/java <br>
  <span>$</span> sudo apt-get update <br>
  <span>$</span> sudo apt-get install oracle-java8-installer</p>
</blockquote>




<p><strong>2. Scala环境搭建</strong></p>




<p>下载scala安装包：</p>




<pre class="prettyprint"><code class=" hljs avrasm">wget -O <span class="hljs-string">"scala-2.12.3.deb"</span> 
<span class="hljs-label">https:</span>//downloads<span class="hljs-preprocessor">.lightbend</span><span class="hljs-preprocessor">.com</span>/scala/<span class="hljs-number">2.12</span><span class="hljs-number">.3</span>/scala-<span class="hljs-number">2.12</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.deb</span>
或者
wget -O <span class="hljs-string">"scala-2.12.3.rpm"</span> <span class="hljs-string">"https://downloads.lightbend.com/scala/2.12.3/scala-2.12.3.rpm"</span>
</code></pre>




<p>安装deb/rpm包：</p>




<pre class="prettyprint"><code class=" hljs avrasm">rpm -ivh scala-<span class="hljs-number">2.12</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.rpm</span>
dpkg -i scala-<span class="hljs-number">2.12</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.deb</span></code></pre>




<p>增加SCALA_HOME</p>




<blockquote>
  <p>$ vim /etc/profile</p>
</blockquote>




<p>增加如下内容;</p>




<blockquote>
  <p>export SCALA_HOME=/usr/share/scala</p>
</blockquote>




<p>刷新配置</p>




<blockquote>
  <p>$ source /etc/profile</p>
</blockquote>




<h3 id="安装hadoop">安装Hadoop</h3>




<p><strong>1.下载二进制包：</strong> <br>
wget <a href="http://www-eu.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz">http://www-eu.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz</a></p>




<p><strong>2.解压并移动至相应目录：</strong></p>




<p>我的习惯是将软件放置/opt目录下：</p>




<blockquote>
  <p>tar -xvf hadoop-2.7.3.tar.gz <br>
  mv hadoop-2.7.3 /opt</p>
</blockquote>




<p><strong>3.修改相应的配置文件：</strong></p>




<blockquote>
  <p><strong>（1）</strong> $ vim /etc/profile</p>
</blockquote>




<p>增加如下内容：</p>




<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment">#hadoop enviroment </span>
<span class="hljs-keyword">export</span> HADOOP_HOME=/opt/hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">3</span>/
<span class="hljs-keyword">export</span> PATH=<span class="hljs-string">"<span class="hljs-variable">$HADOOP_HOME</span>/bin:<span class="hljs-variable">$HADOOP_HOME</span>/sbin:<span class="hljs-variable">$PATH</span>"</span>
<span class="hljs-keyword">export</span> HADOOP_CONF_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/etc/hadoop
<span class="hljs-keyword">export</span> YARN_CONF_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/etc/hadoop</code></pre>




<blockquote>
  <p><strong>（2）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh</p>
</blockquote>




<p>修改JAVA_HOME 如下：</p>




<blockquote>
  <p>export JAVA_HOME=&lt;你的Java安装目录&gt;</p>
</blockquote>




<p>-</p>




<blockquote>
  <p><strong>（3）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/core-site.xml</p>
</blockquote>




<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://master:9000<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
        <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>io.file.buffer.size<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>131072<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
       <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/opt/hadoop-2.7.3/tmp<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
        <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>




<blockquote>
  <p><strong>（4）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml</p>
</blockquote>




<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:50090<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>2<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>file:/opt/hadoop-2.7.3/hdfs/name<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>file:/opt/hadoop-2.7.3/hdfs/data<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>




<blockquote>
  <p><strong>（5）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/mapred-site.xml</p>
</blockquote>




<p>复制template，生成xml：</p>




<blockquote>
  <p>cp mapred-site.xml.template mapred-site.xml</p>
</blockquote>




<p>内容：</p>




<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
 <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:10020<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:19888<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>




<p><strong>（6）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/yarn-site.xml</p>




<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-comment">&lt;!-- Site specific YARN configuration properties --&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
           <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
           <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8032<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8030<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
      <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8031<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8033<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8088<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>




<p>至此master节点的hadoop搭建完毕</p>




<p>再启动之前我们需要</p>




<p>格式化一下namenode</p>




<blockquote>
  <p>$ hadoop namenode -format</p>
</blockquote>




<h3 id="安装spark">安装Spark</h3>




<p><strong>下载文件：</strong></p>




<pre class="prettyprint"><code class=" hljs mathematica">wget -<span class="hljs-keyword">O</span> <span class="hljs-string">"spark-2.1.0-bin-hadoop2.7.tgz"</span> <span class="hljs-string">"http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz"</span></code></pre>




<p><strong>解压并移动至相应的文件夹：</strong></p>




<blockquote>
  <p>tar -xvf spark-2.1.0-bin-hadoop2.7.tgz <br>
  mv spark-2.1.0-bin-hadoop2.7 /opt</p>
</blockquote>




<p><strong>修改相应的配置文件：</strong></p>




<blockquote>
  <p><strong>（1）</strong> <span>$</span> vim /etc/profie</p>
</blockquote>




<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment">#Spark enviroment</span>
<span class="hljs-keyword">export</span> SPARK_HOME=/opt/spark-<span class="hljs-number">2.1</span>.<span class="hljs-number">0</span>-bin-hadoop2.<span class="hljs-number">7</span>/
<span class="hljs-keyword">export</span> PATH=<span class="hljs-string">"<span class="hljs-variable">$SPARK_HOME</span>/bin:<span class="hljs-variable">$PATH</span>"</span></code></pre>




<blockquote>
  <p><strong>（2）</strong> <span>$</span> vim $SPARK_HOME/conf/spark-env.sh</p>
</blockquote>




<p>-</p>




<blockquote>
  <p>cp spark-env.sh.template spark-env.sh</p>
</blockquote>




<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment">#配置内容如下：</span>
<span class="hljs-keyword">export</span> SCALA_HOME=/usr/share/scala
<span class="hljs-keyword">export</span> JAVA_HOME=&lt;你的Java安装目录&gt;
<span class="hljs-keyword">export</span> SPARK_MASTER_IP=master
<span class="hljs-keyword">export</span> SPARK_WORKER_MEMORY=<span class="hljs-number">1</span>g
<span class="hljs-keyword">export</span> HADOOP_CONF_DIR=/opt/hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">3</span>/etc/hadoop</code></pre>




<p>至此，我们大部分环境基本安装完毕！</p>




<h2 id="测试spark">测试Spark</h2>




<p>为了避免麻烦这里我们使用spark-shell以及本地的文件（非hdfs），做一个简单的worcount的测试。</p>




<pre class="prettyprint"><code class=" hljs livecodeserver">val <span class="hljs-built_in">file</span>=sc.textFile(<span class="hljs-string">"/home/ef/Desktop/Notes/wordcount_test"</span>)
val rdd = <span class="hljs-built_in">file</span>.flatMap(<span class="hljs-built_in">line</span> =&gt; <span class="hljs-built_in">line</span>.<span class="hljs-built_in">split</span>(<span class="hljs-string">" "</span>)).map(<span class="hljs-built_in">word</span> =&gt; (<span class="hljs-built_in">word</span>,<span class="hljs-number">1</span>)).reduceByKey(_+_)
rdd.collect()
rdd.foreach(println)</code></pre>




<p><strong>展示图：</strong> <br>
<img src="https://i.loli.net/2017/10/10/59dc80d01e9ff.png" alt="spark-shell.png" title=""></p>




<h2 id="小结">小结</h2>




<p>到此，我们在Spark上进行机器学习训练的环境，就搭建完毕了，下章我们再开始讲Spark中的数据结构与Python中的区别，以及结合Pyspark来进行数据处理。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/10/16/pythonzai-sparkshang-de-ji-qi-xue-xi-%5B%3F%5D-zhi-huan-jing-da-jian/">Python在Spark上的机器学习(一)之环境搭建</a>
      <time datetime="2017-10-16T14:07:29+08:00" pubdate><span class='month'>Oct</span> <span class='day'>16</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/pyspark-and-spark/'>pyspark&spark</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/10/11/svmzhi-chi-xiang-liang-ji/">SVM支持向量机</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-10-11T16:38:50+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="svmsupport-vector-machines-支持向量机">SVM(Support Vector Machines)-支持向量机</h1></p>

<p>曾经很多人都认为SVM是现在的最好的分类器，即：在不加以修改的前提之下，就能够在数据上进行训练并能够对训练集之外的数据点做出很好的分类决策。</p>




<h2 id="基于最大间隔分割数据">基于最大间隔分割数据</h2>




<p><strong>支持向量机：</strong> <br>
优点：泛化错误率低，计算开销不大，结果容易解释 <br>
缺点：对参数调节和核函数的选择策略敏感，原始分类器不加修改仅适用于处理二类问题。 <br>
<img src="http://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_0011.png" alt="enter image description here" title=""></p>




<p>在上图中，我们可以看出：我们可以很容易在图中画出一条直线将两组数据点分开。在这种情况下，这组数据被称为<strong>线性可分(linearly separable)</strong>数据，而将数据集分割开来的直线我们称为<strong>分隔超平面(separating hyperplane)</strong>。在上图例子中，由于数据点都在二维平面上，所有此时分隔超平面就只是一条直线而已。但是，如果所给的数据为三维的，那么此时用来分隔数据的就是一个平面。依此类推，如果给出一个N（N&gt;3）维数据集，那么则要用一个N-1维的对象来对数据进行分隔，该对象亦被称为<strong>超平面(hyperplane)</strong>。</p>




<p>我们希望通过这样的方式来构建分类器。即如果数据点离决策边界越远，那么其最后的预测效果就越可信。那么我们继续看回上面的图片，我们可以看到有三条直线（一条实线，两条虚线）它们分别都能将数据分隔开，但是其中哪一条才是最理想的呢？通常，我们可以做过这样的方法来确定一个最佳分隔平面，即：我们先找到离分隔平面最近的点，确保它们离分隔平面的距离尽可能远。</p>




<p>这里我们又要先引入一些新的概念： <br>
首先是，点到分隔面的距离被称为<strong>间隔(margin)</strong> <br>
<strong>支持向量(support vector)：</strong>就是离分割平面最近的那些点。</p>




<p>接下来，就是最大化支持向量都分隔面的距离，并需要找到此问题的优化求解方法。</p>




<h2 id="寻找最大间隔">寻找最大间隔</h2>




<p><strong>Maximum Marginal（最大间隔）</strong>是SVM的一个理论基础之一。选择使得间隔最大的函数作为分隔平面是十分容易解释的。从概率的角度上而言，就是使得置信度最小的点置信度最大;从现实意义上而言，两个个体的类别差异越大，我们自然也能够更为准确地分类。</p>




<p><img src="https://i.loli.net/2017/10/11/59ddd657a3c93.png" alt="svm.png" title=""></p>




<p>上图就是一个对之前所提及的类别间隙的一个描述。其中中间的黑色实线为<strong>分隔边界（Classifier Boundary）</strong>是我们算法中要求解的<strong>f(x)</strong>，红色和蓝色的线(plus plane 与 minus plane)就是支持变量所在的平面，而红色，蓝色之间的间隙就是我们要最大化的分类间的间隙。</p>




<p>首先，我们可以知道其两个支持向量的所在平面可以表达成如下形式：</p>




<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a677ed33ca0c840aa9295405fc095c8aefa73e48" alt="enter image description here" title=""></p>




<p>和</p>




<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6c3dbeeb7d5af27a2551ec07ce172ddbce62fc58" alt="enter image description here" title=""></p>




<p>然后，这两个超平面的距离可以表达成：<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ac553c94aec996dffa3369adcf285319178a474f" alt="enter image description here" title=""></p>




<p>因此，为了最大化两个平面的距离，我们只要最小化<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b6f27a892f3053ef0bfe273f88f18351a1a18ac" alt="" title="">即可。</p>




<p><strong>综上所述</strong>，我们可以将整个原理表示为：</p>




<blockquote>
  <p>Minimize<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b6f27a892f3053ef0bfe273f88f18351a1a18ac" alt="" title="">  <br>
  subject to<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7181cf8e723b24ad6d85b73b9513dcaac0d31023" alt="" title=""> <br>
  for <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/520ffef648f7b26db5bae564be860346630635fc" alt="enter image description here" title=""></p>
</blockquote>




<p>当支持变量确定的时候，整个分割函数也就确定了下来。除此之外，支持向量的出现还可以让向量后方的样本点不用再参与计算，大大降低了算法的计算复杂度。</p>




<p>再者，有关距离计算的优化。<script type="math/tex" id="MathJax-Element-41">||\vec w||</script>的意思是<script type="math/tex" id="MathJax-Element-42">\vec w</script>的二范数，由之前我们得到的最大间隔<script type="math/tex" id="MathJax-Element-43">M=2/||\vec w||</script>，最大化这个式子等价于最小化<script type="math/tex" id="MathJax-Element-44">|||\vec w||</script>，另外由于<script type="math/tex" id="MathJax-Element-45">||\vec w||</script>是一个单调函数，我们可以对其进行平方，和加上系数。数学经验丰富的朋友可能一眼就看出来，这样做是为了方便求导。</p>




<p>最后我们的式子可以写成：</p>




<p><img src="https://i.loli.net/2017/10/11/59ddd726bc801.png" alt="svmalg.png" title=""></p>




<p><strong>s.t的意思是subject to</strong>，也就是在后面这个限制条件下的意思，这个词在svm的论文里面非常容易见到。这其实是一个<strong>带约束的二次规划(quadratic programming, QP)问题</strong>，是一个<strong>凸问题</strong>，凸问题就是指的不会有局部最优解，可以想象一个漏斗，不管我们开始的时候将一个小球放在漏斗的什么位置，这个小球最终一定可以掉出漏斗，也就是得到全局最优解。s.t.后面的限制条件可以看做是一个凸多面体，我们要做的就是在这个凸多面体中找到最优解。</p>




<h2 id="优化求解">优化求解</h2>




<p>这个优化问题可以用<a href="https://en.wikipedia.org/wiki/Lagrange_multiplier">拉格朗日乘子法</a>去解，使用了<a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">KKT条件</a>的理论，这里直接作出这个式子的拉格朗日目标函数： <br>
<img src="https://i.loli.net/2017/10/11/59ddd726bb94a.png" alt="Lagrange.png" title=""></p>




<p>由于求解这个式子的过程需要<a href="https://en.wikipedia.org/wiki/Quadratic_programming#Lagrangian_duality">拉格朗日对偶性</a>的相关知识，以及较深入的数学背景知识，在这篇文章中暂且不谈，以后博客再另外写一篇有关具体推导的文章。</p>




<p>在此，我先贴出在该问题在论文中的关键推导步骤：</p>




<p><img src="https://i.loli.net/2017/10/11/59ddd726dd5a4.png" alt="formulation.png" title=""></p>




<p><img src="https://i.loli.net/2017/10/11/59ddd726d9bc8.png" alt="dual.png" title=""></p>




<p>上图就是我们需要最终优化的式子了。整篇文章到这里，我们终于得到了SVM线性可分问题的优化式子。</p>




<h2 id="svm的使用">SVM的使用</h2>




<p>由于支持向量机算法的实现涉及过多的数学背景，在本中暂不使用原生程序代码实现，而是选择调用Python sklearn 库现有的SVM算法进行使用的举例。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
</span><span class='line'><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
</span><span class='line'><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
</span><span class='line'><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
</span><span class='line'><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span class='line'><span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">pred</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, <br>
    decision_function_shape=None, degree=3, gamma=’auto’, kernel=’rbf’, <br>
    max_iter=-1, probability=False, random_state=None, shrinking=True, <br>
    tol=0.001, verbose=False) <br>
  0.986666666667</p>
</blockquote>




<p>本例使用的是<strong>sklearn</strong>库自带的<strong>iris</strong>数据集使用SVM算法进行训练，然后再进行回测。首先，我们可以看到在不做任意处理的前提下，SVM模型的预估效果也是相当不错的，其准确率高达98%（其结果主要因为使用的数据集优秀导致的，直接运用于工程上时不会有这么高的准确率）。</p>




<p>当然，上面例子中的算法模型的实现方式是十分简陋的。如果真正要使用SVM进行严格地建模，测试集与训练集的划分问题，数据的归一化处理问题等。都是我们需要考虑的元素。但由于本文主要为了介绍与探讨SVM算法，其他细节问题就不一一处理，详细方法可以参考我写的其他文章。</p>




<h2 id="svm的其他实现">SVM的其他实现</h2>




<p>除了Python的sklearn库外，SVM在其它语言及平台也有实现。其中： <br>
最流行的有</p>




<blockquote>
  <p><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM：</a><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">https://www.csie.ntu.edu.tw/~cjlin/libsvm/</a> <br>
  这是经典的svm库支持多种语言调用</p>
</blockquote>




<p>再者，在R语言中也有SVM算法的实现：</p>




<blockquote>
  <p><a href="https://cran.r-project.org/web/packages/e1071/index.html">e1071：</a> <br>
  <a href="https://cran.r-project.org/web/packages/e1071/index.html">https://cran.r-project.org/web/packages/e1071/index.html</a></p>
</blockquote>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/10/11/svmzhi-chi-xiang-liang-ji/">SVM支持向量机</a>
      <time datetime="2017-10-11T16:38:50+08:00" pubdate><span class='month'>Oct</span> <span class='day'>11</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/10/06/k-meansju-lei-jian-jie/">K-means聚类简介</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- 








  



<time datetime="2017-10-06T14:28:25+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


  <div class="entry-content"><p>﻿<h1 id="k-means聚类简介">K-means聚类简介</h1></p>

<p>前面介绍了不少监督学习的各类算法，那么这次我们就来认识和了解一下无监督学习。首先，K-means聚类算法就是一种无监督学习的算法。这就意味着他可以通过没有分类标记的数据学习出训练数据本身的分组信息。（其实他的本质就是自动的将属性/特征类似的数据归到统一类别）而其最后分成的组数则由参数K来决定。</p>




<h2 id="算法基本步骤">算法基本步骤</h2>




<ol>
<li>随机初始化K个簇心。用作标识各组数据。</li>
<li>根据各个数据的特征/属性，将他们聚类到距离最接近的一个簇，并打上分类标识。</li>
<li>根据加入的数据重新计算每个簇的质心（均值，Means）</li>
<li>重复2，3步，直至最后所有数据被划分成k个簇。</li>
</ol>




<p>从以后的步骤我们也可以充分地看出，再聚类完毕之前数据是没有分组和标识的，而是通过聚类来查找和分析被划分在一起的数据。</p>




<p>同时，每个簇的质心是定义组的特征的代表，我们往往可以通过一个簇的质心看出该分组的特征以及属性。从而判断出这个簇代表了一个怎么样的组。</p>




<h2 id="应用领域">应用领域</h2>




<ul>
<li>网站，App的用户群体聚类</li>
<li>信用卡诈骗监测（这个是利用了聚类算法的反原理，寻找离群值）</li>
<li>文章自动归类</li>
<li>图像归类</li>
<li>人群健康状态监测（同信用卡诈骗检测同原理）</li>
</ul>




<p>此外，我们还可以通过监控数据点根据时间的变化而造成的组间切换现象找到状态变化的方法。</p>




<h2 id="算法主要原理">算法主要原理</h2>




<p>（1）在数据划分方面，我们主要依赖的思路是：<strong>欧氏距离</strong>。即，每个簇的质心定义了一种聚类，然后每个点根据其到每个簇的质心的欧几里德距离的平方的大小，将其分配到最近的簇中。我们假设<script type="math/tex" id="MathJax-Element-1">c_i</script>是簇集合C中质心i，那么我们可以将其聚类的过程表达成下列形式：</p>




<p><script type="math/tex" id="MathJax-Element-2">argmin_{c_i \in C} dist(c_i,x)^2</script></p>




<p>（2）<strong>质心的更新</strong>，在这一步骤中，各个簇的质心将要被重新计算，通过加入新的数据再重新计算包括i新数据在内的的整个簇的均值以此作为新的质心。该过程可以表达为一下形式：</p>




<p><script type="math/tex" id="MathJax-Element-3">c_i=\frac{1}{|S_i|}\sum_{x_i \in S_i }x_i</script></p>




<p>在多次迭代之后，该算法可以保证收敛于一个结果，虽然有可能只是一个局部的最优解而已。为了使得最后结果更加稳定和可靠，我们也可以通过多次运行算法然后再在多个结果中取得一个均衡（为什么说多次计算可以得到更好的结果呢？ 因为每次随机初始化的质心都是不同的，这样使得每次的运行结果都不尽相同，为了得到一个更加稳定的结果和更好的鲁棒性，多次运行往往是一个简单但却有效的方法。）</p>




<h2 id="有关k值的选择">有关K值的选择</h2>




<p>在K-means聚类算法中，K值的选择往往是一个较为难以抉择的问题。最后的情况是，在你应用这个算法之前，已经知道数据应该分为多少个类别合适，或者将这种方法应用在一个半监督学习的场合，使得最后的分类结果有据可依。</p>




<p>那么，在一般我们不太清楚分类的情况之下，我们能做的就是通过为K值制定一个范围，然后在这个范围之上，我们尝试运行我们的分类器，然后根据分类效果来评判我们的k的取值。</p>




<p>另外一方面，聚类算法通常会不断降低各个样本点到质心之间的距离，随着k值的增加，“距离”更是一直下降。但是，当k值增大到一定程度时，虽然“距离”仍在下降，但下降的速率已经变得十分缓慢了。我们常常称这个点的k值为<strong>肘点</strong>。往往到达肘点的k值已经能够很好地将各个类别之间的差异信息给描述出来，所以我们可以在不清楚数据具体分类信息的情况下，选择肘点值来作为我们的k值。</p>




<p><img src="https://www.datascience.com/hs-fs/hubfs/Blog/introduction-to-k-means-clustering-elbow-point-example.png?t=1507257936532&amp;width=760&amp;height=411&amp;name=introduction-to-k-means-clustering-elbow-point-example.png" alt="enter image description here" title=""></p>




<h2 id="example">Example</h2>




<p>在这里我们通过Python的Sklearn库来看一下K-means的应用实例</p>




<p><a href="https://raw.githubusercontent.com/datascienceinc/learn-data-science/master/Introduction-to-K-means-Clustering/Data/data_1024.csv">Delivery Fleet Data 数据下载</a></p>




<h3 id="数据读取">数据读取</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">&quot;data_1024.csv&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&quot;Distance_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&quot;Speeding_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Delivery Fleet Data&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote>
  <p>输出结果 <br>
    Driver_ID   Distance_Feature    Speeding_Feature <br>
  0   3423311935  71.24   28.0 <br>
  1   3423313212  52.53   25.0 <br>
  2   3423313724  64.54   27.0 <br>
  3   3423311373  55.69   22.0 <br>
  4   3423310999  54.58   25.0 <br>
  <img src="https://i.loli.net/2017/10/06/59d71bde43c28.png" alt="kmeans.png" title=""></p>
</blockquote>




<h3 id="算法使用">算法使用</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</span><span class='line'><span class="n">X_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">,</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">]]</span>
</span><span class='line'><span class="n">kmeas</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="o">/</span><span class="mf">255.</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">kmeas</span><span class="o">.</span><span class="n">labels_</span><span class="p">]</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&quot;Distance_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&quot;Speeding_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Delivery Fleet Data&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="n">kmeas</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="o">/</span><span class="mf">255.</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">kmeas</span><span class="o">.</span><span class="n">labels_</span><span class="p">]</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&quot;Distance_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&quot;Speeding_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Delivery Fleet Data&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  <img src="https://i.loli.net/2017/10/06/59d720b726068.png" alt="sk-kmeans.png" title=""></p>
</blockquote>




<p>上面的结果展示了，K分别等于2和4时对数据的聚类的结果，由于这个算法使用还算简单，在这里我也不做赘述了。那么有关K-means的简介到这里也就结束了，谢谢大家的阅读。</p>

</div>
  
  


      <footer>
      
      - <a href="/blog/2017/10/06/k-meansju-lei-jian-jie/">K-means聚类简介</a>
      <time datetime="2017-10-06T14:28:25+08:00" pubdate><span class='month'>Oct</span> <span class='day'>06</span> <span class='year'>2017</span></time>
      
      <span class="categories">posted in <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a></span>
      
      </footer>
    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/3">&larr; Older</a>
    
    <a href="/archives">Blog Archives</a>
    
    <a class="next" href="/index.html">Newer &rarr;</a>
    
  </div><!-- /div.pagination -->
</div><!-- /div.blog-index -->

      </div><!-- /div#content -->
    </div><!-- /div#main -->
  </div><!-- /div.container -->
  <footer><div id="footer-widgets-wrapper">
  <div id="footer-first" class="footer-widget">
    <h3>About Me</h3>
    <section class="about-me">
      
        <img class="icon-image" src="https://avatars0.githubusercontent.com/u/13914416?s=240" alt="icon_image">
      
      <div>
        <ul>
          
            <li>GitHub: <a href="https://github.com/EdmondFrank">@EdmondFrank</a></li>
          
          
            <li>Twitter: <a href="https://twitter.com/EdmondFrank4">@EdmondFrank4</a></li>
          
            <li>Blog: <a href="https://edmondfrank.github.io">https://edmondfrank.github.io</a></li>
        </ul>
        <p>
          この町、冗談と気まぐれと偶然でてきっているらしい。
        </p>
      </div>
    </section>
  </div><!-- /div#footer-second -->

  <div id="footer-second" class="footer-widget">
    <h3>Recent Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="https://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "https://edmondfrank.github.io";
        Hatena.BookmarkWidget.title = "Recent Posts";
        Hatena.BookmarkWidget.sort  = "hot";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-second -->

  <div id="footer-third" class="footer-widget">
    <h3>Popular Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="https://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "https://edmondfrank.github.io";
        Hatena.BookmarkWidget.title = "Popular Posts";
        Hatena.BookmarkWidget.sort  = "count";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-third -->
</div><!-- /div#footer-widgets-wrapper -->

<div id="credit" role="contentinfo">
  <p>
    Copyright &copy; 2018 - <a href="https://github.com/EdmondFrank/">EdmondFrank</a> -
    <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  </p>
</div>

</footer>
  










  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
