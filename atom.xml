<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[EdmondFrank's 时光足迹]]></title>
  <link href="https://edmondfrank.github.io/atom.xml" rel="self"/>
  <link href="https://edmondfrank.github.io/"/>
  <updated>2017-10-16T14:09:57+08:00</updated>
  <id>https://edmondfrank.github.io/</id>
  <author>
    <name><![CDATA[EdmondFrank]]></name>
    <email><![CDATA[EdmomdFrank@yahoo.co.jp]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Python在Spark上的机器学习(一)之环境搭建]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/10/16/pythonzai-sparkshang-de-ji-qi-xue-xi-%5B%3F%5D-zhi-huan-jing-da-jian/"/>
    <updated>2017-10-16T14:07:29+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/10/16/pythonzai-sparkshang-de-ji-qi-xue-xi-[?]-zhi-huan-jing-da-jian</id>
    <content type="html"><![CDATA[<p>﻿<h1 id="python在spark上的机器学习一之环境搭建">Python在Spark上的机器学习(一)之环境搭建</h1></p>

<p>前面已经介绍了不少机器学习的算法了，那么机器学习又该如何结合大数据一起使用么？</p>




<h2 id="常言道工欲善其事必先利其器">常言道：工欲善其事，必先利其器</h2>




<p>既然来结合大数据与机器学习，我们就不得不提Spark了。</p>




<p>首先，<a href="https://spark.apache.org/docs/latest/index.html">Apache Spark</a> 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。</p>




<p>Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。</p>




<p>讲了这么多Spark的优点，那么现在我们就先开始来搭建一个Spark 集群环境吧！</p>




<h3 id="安装基础环境">安装基础环境</h3>




<p><strong>1. Java1.8环境搭建</strong>（下载JDK1.8的）：</p>




<blockquote>
  <p>下载页面： <br>
  <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p>
</blockquote>




<p>安装过程可以参考<a href="http://www.linuxidc.com/Linux/2016-05/131348.htm">Linux公社给出的教程</a></p>




<p><strong>Ubuntu用户：</strong> <br>
Ubuntu用户可以通过添加PPA源再通过Apt来进行安装</p>




<blockquote>
  <p><span>$</span> sudo add-apt-repository ppa:webupd8team/java <br>
  <span>$</span> sudo apt-get update <br>
  <span>$</span> sudo apt-get install oracle-java8-installer</p>
</blockquote>




<p><strong>2. Scala环境搭建</strong></p>




<p>下载scala安装包：</p>




<pre class="prettyprint"><code class=" hljs avrasm">wget -O <span class="hljs-string">"scala-2.12.3.deb"</span> 
<span class="hljs-label">https:</span>//downloads<span class="hljs-preprocessor">.lightbend</span><span class="hljs-preprocessor">.com</span>/scala/<span class="hljs-number">2.12</span><span class="hljs-number">.3</span>/scala-<span class="hljs-number">2.12</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.deb</span>
或者
wget -O <span class="hljs-string">"scala-2.12.3.rpm"</span> <span class="hljs-string">"https://downloads.lightbend.com/scala/2.12.3/scala-2.12.3.rpm"</span>
</code></pre>




<p>安装deb/rpm包：</p>




<pre class="prettyprint"><code class=" hljs avrasm">rpm -ivh scala-<span class="hljs-number">2.12</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.rpm</span>
dpkg -i scala-<span class="hljs-number">2.12</span><span class="hljs-number">.3</span><span class="hljs-preprocessor">.deb</span></code></pre>




<p>增加SCALA_HOME</p>




<blockquote>
  <p>$ vim /etc/profile</p>
</blockquote>




<p>增加如下内容;</p>




<blockquote>
  <p>export SCALA_HOME=/usr/share/scala</p>
</blockquote>




<p>刷新配置</p>




<blockquote>
  <p>$ source /etc/profile</p>
</blockquote>




<h3 id="安装hadoop">安装Hadoop</h3>




<p><strong>1.下载二进制包：</strong> <br>
wget <a href="http://www-eu.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz">http://www-eu.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz</a></p>




<p><strong>2.解压并移动至相应目录：</strong></p>




<p>我的习惯是将软件放置/opt目录下：</p>




<blockquote>
  <p>tar -xvf hadoop-2.7.3.tar.gz <br>
  mv hadoop-2.7.3 /opt</p>
</blockquote>




<p><strong>3.修改相应的配置文件：</strong></p>




<blockquote>
  <p><strong>（1）</strong> $ vim /etc/profile</p>
</blockquote>




<p>增加如下内容：</p>




<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment">#hadoop enviroment </span>
<span class="hljs-keyword">export</span> HADOOP_HOME=/opt/hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">3</span>/
<span class="hljs-keyword">export</span> PATH=<span class="hljs-string">"<span class="hljs-variable">$HADOOP_HOME</span>/bin:<span class="hljs-variable">$HADOOP_HOME</span>/sbin:<span class="hljs-variable">$PATH</span>"</span>
<span class="hljs-keyword">export</span> HADOOP_CONF_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/etc/hadoop
<span class="hljs-keyword">export</span> YARN_CONF_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/etc/hadoop</code></pre>




<blockquote>
  <p><strong>（2）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh</p>
</blockquote>




<p>修改JAVA_HOME 如下：</p>




<blockquote>
  <p>export JAVA_HOME=&lt;你的Java安装目录&gt;</p>
</blockquote>




<p>-</p>




<blockquote>
  <p><strong>（3）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/core-site.xml</p>
</blockquote>




<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://master:9000<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
        <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>io.file.buffer.size<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>131072<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
       <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>/opt/hadoop-2.7.3/tmp<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
        <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>




<blockquote>
  <p><strong>（4）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml</p>
</blockquote>




<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:50090<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>2<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>file:/opt/hadoop-2.7.3/hdfs/name<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>file:/opt/hadoop-2.7.3/hdfs/data<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>




<blockquote>
  <p><strong>（5）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/mapred-site.xml</p>
</blockquote>




<p>复制template，生成xml：</p>




<blockquote>
  <p>cp mapred-site.xml.template mapred-site.xml</p>
</blockquote>




<p>内容：</p>




<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>
 <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:10020<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:19888<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span></code></pre>




<p><strong>（6）</strong> <span>$</span> vim $HADOOP_HOME/etc/hadoop/yarn-site.xml</p>




<pre class="prettyprint"><code class=" hljs xml"><span class="hljs-comment">&lt;!-- Site specific YARN configuration properties --&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
           <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
           <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8032<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8030<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
      <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8031<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8033<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>
     <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>
         <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>master:8088<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>
     <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span></code></pre>




<p>至此master节点的hadoop搭建完毕</p>




<p>再启动之前我们需要</p>




<p>格式化一下namenode</p>




<blockquote>
  <p>$ hadoop namenode -format</p>
</blockquote>




<h3 id="安装spark">安装Spark</h3>




<p><strong>下载文件：</strong></p>




<pre class="prettyprint"><code class=" hljs mathematica">wget -<span class="hljs-keyword">O</span> <span class="hljs-string">"spark-2.1.0-bin-hadoop2.7.tgz"</span> <span class="hljs-string">"http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz"</span></code></pre>




<p><strong>解压并移动至相应的文件夹：</strong></p>




<blockquote>
  <p>tar -xvf spark-2.1.0-bin-hadoop2.7.tgz <br>
  mv spark-2.1.0-bin-hadoop2.7 /opt</p>
</blockquote>




<p><strong>修改相应的配置文件：</strong></p>




<blockquote>
  <p><strong>（1）</strong> <span>$</span> vim /etc/profie</p>
</blockquote>




<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment">#Spark enviroment</span>
<span class="hljs-keyword">export</span> SPARK_HOME=/opt/spark-<span class="hljs-number">2.1</span>.<span class="hljs-number">0</span>-bin-hadoop2.<span class="hljs-number">7</span>/
<span class="hljs-keyword">export</span> PATH=<span class="hljs-string">"<span class="hljs-variable">$SPARK_HOME</span>/bin:<span class="hljs-variable">$PATH</span>"</span></code></pre>




<blockquote>
  <p><strong>（2）</strong> <span>$</span> vim $SPARK_HOME/conf/spark-env.sh</p>
</blockquote>




<p>-</p>




<blockquote>
  <p>cp spark-env.sh.template spark-env.sh</p>
</blockquote>




<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment">#配置内容如下：</span>
<span class="hljs-keyword">export</span> SCALA_HOME=/usr/share/scala
<span class="hljs-keyword">export</span> JAVA_HOME=&lt;你的Java安装目录&gt;
<span class="hljs-keyword">export</span> SPARK_MASTER_IP=master
<span class="hljs-keyword">export</span> SPARK_WORKER_MEMORY=<span class="hljs-number">1</span>g
<span class="hljs-keyword">export</span> HADOOP_CONF_DIR=/opt/hadoop-<span class="hljs-number">2.7</span>.<span class="hljs-number">3</span>/etc/hadoop</code></pre>




<p>至此，我们大部分环境基本安装完毕！</p>




<h2 id="测试spark">测试Spark</h2>




<p>为了避免麻烦这里我们使用spark-shell以及本地的文件（非hdfs），做一个简单的worcount的测试。</p>




<pre class="prettyprint"><code class=" hljs livecodeserver">val <span class="hljs-built_in">file</span>=sc.textFile(<span class="hljs-string">"/home/ef/Desktop/Notes/wordcount_test"</span>)
val rdd = <span class="hljs-built_in">file</span>.flatMap(<span class="hljs-built_in">line</span> =&gt; <span class="hljs-built_in">line</span>.<span class="hljs-built_in">split</span>(<span class="hljs-string">" "</span>)).map(<span class="hljs-built_in">word</span> =&gt; (<span class="hljs-built_in">word</span>,<span class="hljs-number">1</span>)).reduceByKey(_+_)
rdd.collect()
rdd.foreach(println)</code></pre>




<p><strong>展示图：</strong> <br>
<img src="https://i.loli.net/2017/10/10/59dc80d01e9ff.png" alt="spark-shell.png" title=""></p>




<h2 id="小结">小结</h2>




<p>到此，我们在Spark上进行机器学习训练的环境，就搭建完毕了，下章我们再开始讲Spark中的数据结构与Python中的区别，以及结合Pyspark来进行数据处理。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SVM支持向量机]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/10/11/svmzhi-chi-xiang-liang-ji/"/>
    <updated>2017-10-11T16:38:50+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/10/11/svmzhi-chi-xiang-liang-ji</id>
    <content type="html"><![CDATA[<p>﻿<h1 id="svmsupport-vector-machines-支持向量机">SVM(Support Vector Machines)-支持向量机</h1></p>

<p>曾经很多人都认为SVM是现在的最好的分类器，即：在不加以修改的前提之下，就能够在数据上进行训练并能够对训练集之外的数据点做出很好的分类决策。</p>




<h2 id="基于最大间隔分割数据">基于最大间隔分割数据</h2>




<p><strong>支持向量机：</strong> <br>
优点：泛化错误率低，计算开销不大，结果容易解释 <br>
缺点：对参数调节和核函数的选择策略敏感，原始分类器不加修改仅适用于处理二类问题。 <br>
<img src="http://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_0011.png" alt="enter image description here" title=""></p>




<p>在上图中，我们可以看出：我们可以很容易在图中画出一条直线将两组数据点分开。在这种情况下，这组数据被称为<strong>线性可分(linearly separable)</strong>数据，而将数据集分割开来的直线我们称为<strong>分隔超平面(separating hyperplane)</strong>。在上图例子中，由于数据点都在二维平面上，所有此时分隔超平面就只是一条直线而已。但是，如果所给的数据为三维的，那么此时用来分隔数据的就是一个平面。依此类推，如果给出一个N（N&gt;3）维数据集，那么则要用一个N-1维的对象来对数据进行分隔，该对象亦被称为<strong>超平面(hyperplane)</strong>。</p>




<p>我们希望通过这样的方式来构建分类器。即如果数据点离决策边界越远，那么其最后的预测效果就越可信。那么我们继续看回上面的图片，我们可以看到有三条直线（一条实线，两条虚线）它们分别都能将数据分隔开，但是其中哪一条才是最理想的呢？通常，我们可以做过这样的方法来确定一个最佳分隔平面，即：我们先找到离分隔平面最近的点，确保它们离分隔平面的距离尽可能远。</p>




<p>这里我们又要先引入一些新的概念： <br>
首先是，点到分隔面的距离被称为<strong>间隔(margin)</strong> <br>
<strong>支持向量(support vector)：</strong>就是离分割平面最近的那些点。</p>




<p>接下来，就是最大化支持向量都分隔面的距离，并需要找到此问题的优化求解方法。</p>




<h2 id="寻找最大间隔">寻找最大间隔</h2>




<p><strong>Maximum Marginal（最大间隔）</strong>是SVM的一个理论基础之一。选择使得间隔最大的函数作为分隔平面是十分容易解释的。从概率的角度上而言，就是使得置信度最小的点置信度最大;从现实意义上而言，两个个体的类别差异越大，我们自然也能够更为准确地分类。</p>




<p><img src="https://i.loli.net/2017/10/11/59ddd657a3c93.png" alt="svm.png" title=""></p>




<p>上图就是一个对之前所提及的类别间隙的一个描述。其中中间的黑色实线为<strong>分隔边界（Classifier Boundary）</strong>是我们算法中要求解的<strong>f(x)</strong>，红色和蓝色的线(plus plane 与 minus plane)就是支持变量所在的平面，而红色，蓝色之间的间隙就是我们要最大化的分类间的间隙。</p>




<p>首先，我们可以知道其两个支持向量的所在平面可以表达成如下形式：</p>




<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a677ed33ca0c840aa9295405fc095c8aefa73e48" alt="enter image description here" title=""></p>




<p>和</p>




<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6c3dbeeb7d5af27a2551ec07ce172ddbce62fc58" alt="enter image description here" title=""></p>




<p>然后，这两个超平面的距离可以表达成：<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ac553c94aec996dffa3369adcf285319178a474f" alt="enter image description here" title=""></p>




<p>因此，为了最大化两个平面的距离，我们只要最小化<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b6f27a892f3053ef0bfe273f88f18351a1a18ac" alt="" title="">即可。</p>




<p><strong>综上所述</strong>，我们可以将整个原理表示为：</p>




<blockquote>
  <p>Minimize<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b6f27a892f3053ef0bfe273f88f18351a1a18ac" alt="" title="">  <br>
  subject to<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7181cf8e723b24ad6d85b73b9513dcaac0d31023" alt="" title=""> <br>
  for <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/520ffef648f7b26db5bae564be860346630635fc" alt="enter image description here" title=""></p>
</blockquote>




<p>当支持变量确定的时候，整个分割函数也就确定了下来。除此之外，支持向量的出现还可以让向量后方的样本点不用再参与计算，大大降低了算法的计算复杂度。</p>




<p>再者，有关距离计算的优化。<script type="math/tex" id="MathJax-Element-41">||\vec w||</script>的意思是<script type="math/tex" id="MathJax-Element-42">\vec w</script>的二范数，由之前我们得到的最大间隔<script type="math/tex" id="MathJax-Element-43">M=2/||\vec w||</script>，最大化这个式子等价于最小化<script type="math/tex" id="MathJax-Element-44">|||\vec w||</script>，另外由于<script type="math/tex" id="MathJax-Element-45">||\vec w||</script>是一个单调函数，我们可以对其进行平方，和加上系数。数学经验丰富的朋友可能一眼就看出来，这样做是为了方便求导。</p>




<p>最后我们的式子可以写成：</p>




<p><img src="https://i.loli.net/2017/10/11/59ddd726bc801.png" alt="svmalg.png" title=""></p>




<p><strong>s.t的意思是subject to</strong>，也就是在后面这个限制条件下的意思，这个词在svm的论文里面非常容易见到。这其实是一个<strong>带约束的二次规划(quadratic programming, QP)问题</strong>，是一个<strong>凸问题</strong>，凸问题就是指的不会有局部最优解，可以想象一个漏斗，不管我们开始的时候将一个小球放在漏斗的什么位置，这个小球最终一定可以掉出漏斗，也就是得到全局最优解。s.t.后面的限制条件可以看做是一个凸多面体，我们要做的就是在这个凸多面体中找到最优解。</p>




<h2 id="优化求解">优化求解</h2>




<p>这个优化问题可以用<a href="https://en.wikipedia.org/wiki/Lagrange_multiplier">拉格朗日乘子法</a>去解，使用了<a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">KKT条件</a>的理论，这里直接作出这个式子的拉格朗日目标函数： <br>
<img src="https://i.loli.net/2017/10/11/59ddd726bb94a.png" alt="Lagrange.png" title=""></p>




<p>由于求解这个式子的过程需要<a href="https://en.wikipedia.org/wiki/Quadratic_programming#Lagrangian_duality">拉格朗日对偶性</a>的相关知识，以及较深入的数学背景知识，在这篇文章中暂且不谈，以后博客再另外写一篇有关具体推导的文章。</p>




<p>在此，我先贴出在该问题在论文中的关键推导步骤：</p>




<p><img src="https://i.loli.net/2017/10/11/59ddd726dd5a4.png" alt="formulation.png" title=""></p>




<p><img src="https://i.loli.net/2017/10/11/59ddd726d9bc8.png" alt="dual.png" title=""></p>




<p>上图就是我们需要最终优化的式子了。整篇文章到这里，我们终于得到了SVM线性可分问题的优化式子。</p>




<h2 id="svm的使用">SVM的使用</h2>




<p>由于支持向量机算法的实现涉及过多的数学背景，在本中暂不使用原生程序代码实现，而是选择调用Python sklearn 库现有的SVM算法进行使用的举例。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
</span><span class='line'><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
</span><span class='line'><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
</span><span class='line'><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
</span><span class='line'><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span class='line'><span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">pred</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, <br>
    decision_function_shape=None, degree=3, gamma=’auto’, kernel=’rbf’, <br>
    max_iter=-1, probability=False, random_state=None, shrinking=True, <br>
    tol=0.001, verbose=False) <br>
  0.986666666667</p>
</blockquote>




<p>本例使用的是<strong>sklearn</strong>库自带的<strong>iris</strong>数据集使用SVM算法进行训练，然后再进行回测。首先，我们可以看到在不做任意处理的前提下，SVM模型的预估效果也是相当不错的，其准确率高达98%（其结果主要因为使用的数据集优秀导致的，直接运用于工程上时不会有这么高的准确率）。</p>




<p>当然，上面例子中的算法模型的实现方式是十分简陋的。如果真正要使用SVM进行严格地建模，测试集与训练集的划分问题，数据的归一化处理问题等。都是我们需要考虑的元素。但由于本文主要为了介绍与探讨SVM算法，其他细节问题就不一一处理，详细方法可以参考我写的其他文章。</p>




<h2 id="svm的其他实现">SVM的其他实现</h2>




<p>除了Python的sklearn库外，SVM在其它语言及平台也有实现。其中： <br>
最流行的有</p>




<blockquote>
  <p><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM：</a><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">https://www.csie.ntu.edu.tw/~cjlin/libsvm/</a> <br>
  这是经典的svm库支持多种语言调用</p>
</blockquote>




<p>再者，在R语言中也有SVM算法的实现：</p>




<blockquote>
  <p><a href="https://cran.r-project.org/web/packages/e1071/index.html">e1071：</a> <br>
  <a href="https://cran.r-project.org/web/packages/e1071/index.html">https://cran.r-project.org/web/packages/e1071/index.html</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K-means聚类简介]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/10/06/k-meansju-lei-jian-jie/"/>
    <updated>2017-10-06T14:28:25+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/10/06/k-meansju-lei-jian-jie</id>
    <content type="html"><![CDATA[<p>﻿<h1 id="k-means聚类简介">K-means聚类简介</h1></p>

<p>前面介绍了不少监督学习的各类算法，那么这次我们就来认识和了解一下无监督学习。首先，K-means聚类算法就是一种无监督学习的算法。这就意味着他可以通过没有分类标记的数据学习出训练数据本身的分组信息。（其实他的本质就是自动的将属性/特征类似的数据归到统一类别）而其最后分成的组数则由参数K来决定。</p>




<h2 id="算法基本步骤">算法基本步骤</h2>




<ol>
<li>随机初始化K个簇心。用作标识各组数据。</li>
<li>根据各个数据的特征/属性，将他们聚类到距离最接近的一个簇，并打上分类标识。</li>
<li>根据加入的数据重新计算每个簇的质心（均值，Means）</li>
<li>重复2，3步，直至最后所有数据被划分成k个簇。</li>
</ol>




<p>从以后的步骤我们也可以充分地看出，再聚类完毕之前数据是没有分组和标识的，而是通过聚类来查找和分析被划分在一起的数据。</p>




<p>同时，每个簇的质心是定义组的特征的代表，我们往往可以通过一个簇的质心看出该分组的特征以及属性。从而判断出这个簇代表了一个怎么样的组。</p>




<h2 id="应用领域">应用领域</h2>




<ul>
<li>网站，App的用户群体聚类</li>
<li>信用卡诈骗监测（这个是利用了聚类算法的反原理，寻找离群值）</li>
<li>文章自动归类</li>
<li>图像归类</li>
<li>人群健康状态监测（同信用卡诈骗检测同原理）</li>
</ul>




<p>此外，我们还可以通过监控数据点根据时间的变化而造成的组间切换现象找到状态变化的方法。</p>




<h2 id="算法主要原理">算法主要原理</h2>




<p>（1）在数据划分方面，我们主要依赖的思路是：<strong>欧氏距离</strong>。即，每个簇的质心定义了一种聚类，然后每个点根据其到每个簇的质心的欧几里德距离的平方的大小，将其分配到最近的簇中。我们假设<script type="math/tex" id="MathJax-Element-1">c_i</script>是簇集合C中质心i，那么我们可以将其聚类的过程表达成下列形式：</p>




<p><script type="math/tex" id="MathJax-Element-2">argmin_{c_i \in C} dist(c_i,x)^2</script></p>




<p>（2）<strong>质心的更新</strong>，在这一步骤中，各个簇的质心将要被重新计算，通过加入新的数据再重新计算包括i新数据在内的的整个簇的均值以此作为新的质心。该过程可以表达为一下形式：</p>




<p><script type="math/tex" id="MathJax-Element-3">c_i=\frac{1}{|S_i|}\sum_{x_i \in S_i }x_i</script></p>




<p>在多次迭代之后，该算法可以保证收敛于一个结果，虽然有可能只是一个局部的最优解而已。为了使得最后结果更加稳定和可靠，我们也可以通过多次运行算法然后再在多个结果中取得一个均衡（为什么说多次计算可以得到更好的结果呢？ 因为每次随机初始化的质心都是不同的，这样使得每次的运行结果都不尽相同，为了得到一个更加稳定的结果和更好的鲁棒性，多次运行往往是一个简单但却有效的方法。）</p>




<h2 id="有关k值的选择">有关K值的选择</h2>




<p>在K-means聚类算法中，K值的选择往往是一个较为难以抉择的问题。最后的情况是，在你应用这个算法之前，已经知道数据应该分为多少个类别合适，或者将这种方法应用在一个半监督学习的场合，使得最后的分类结果有据可依。</p>




<p>那么，在一般我们不太清楚分类的情况之下，我们能做的就是通过为K值制定一个范围，然后在这个范围之上，我们尝试运行我们的分类器，然后根据分类效果来评判我们的k的取值。</p>




<p>另外一方面，聚类算法通常会不断降低各个样本点到质心之间的距离，随着k值的增加，“距离”更是一直下降。但是，当k值增大到一定程度时，虽然“距离”仍在下降，但下降的速率已经变得十分缓慢了。我们常常称这个点的k值为<strong>肘点</strong>。往往到达肘点的k值已经能够很好地将各个类别之间的差异信息给描述出来，所以我们可以在不清楚数据具体分类信息的情况下，选择肘点值来作为我们的k值。</p>




<p><img src="https://www.datascience.com/hs-fs/hubfs/Blog/introduction-to-k-means-clustering-elbow-point-example.png?t=1507257936532&amp;width=760&amp;height=411&amp;name=introduction-to-k-means-clustering-elbow-point-example.png" alt="enter image description here" title=""></p>




<h2 id="example">Example</h2>




<p>在这里我们通过Python的Sklearn库来看一下K-means的应用实例</p>




<p><a href="https://raw.githubusercontent.com/datascienceinc/learn-data-science/master/Introduction-to-K-means-Clustering/Data/data_1024.csv">Delivery Fleet Data 数据下载</a></p>




<h3 id="数据读取">数据读取</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">&quot;data_1024.csv&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&quot;Distance_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&quot;Speeding_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Delivery Fleet Data&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote>
  <p>输出结果 <br>
    Driver_ID   Distance_Feature    Speeding_Feature <br>
  0   3423311935  71.24   28.0 <br>
  1   3423313212  52.53   25.0 <br>
  2   3423313724  64.54   27.0 <br>
  3   3423311373  55.69   22.0 <br>
  4   3423310999  54.58   25.0 <br>
  <img src="https://i.loli.net/2017/10/06/59d71bde43c28.png" alt="kmeans.png" title=""></p>
</blockquote>




<h3 id="算法使用">算法使用</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</span><span class='line'><span class="n">X_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">,</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">]]</span>
</span><span class='line'><span class="n">kmeas</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="o">/</span><span class="mf">255.</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">kmeas</span><span class="o">.</span><span class="n">labels_</span><span class="p">]</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&quot;Distance_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&quot;Speeding_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Delivery Fleet Data&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="n">kmeas</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="o">/</span><span class="mf">255.</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">kmeas</span><span class="o">.</span><span class="n">labels_</span><span class="p">]</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Distance_Feature&#39;</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Speeding_Feature&#39;</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&quot;Distance_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&quot;Speeding_Feature&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Delivery Fleet Data&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  <img src="https://i.loli.net/2017/10/06/59d720b726068.png" alt="sk-kmeans.png" title=""></p>
</blockquote>




<p>上面的结果展示了，K分别等于2和4时对数据的聚类的结果，由于这个算法使用还算简单，在这里我也不做赘述了。那么有关K-means的简介到这里也就结束了，谢谢大家的阅读。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[机器学习之梯度下降]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/09/30/ji-qi-xue-xi-zhi-ti-du-xia-jiang/"/>
    <updated>2017-09-30T20:19:04+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/09/30/ji-qi-xue-xi-zhi-ti-du-xia-jiang</id>
    <content type="html"><![CDATA[<h1 id="机器学习之梯度下降">机器学习之梯度下降</h1>




<h2 id="梯度下降gradient-descent">梯度下降(gradient descent)</h2>




<p>是线性回归的一种(Linear Regression)，在<a href="https://www.bilibili.com/video/av9912938/?from=search&amp;seid=3888228796805461518">Andrew Ng的machine learning</a>前期课程中有着详细的讲解，首先给出一个关于课程中经典的例子:预测房屋的价格。</p>




<table>
<thead>
<tr>
  <th>面积(feet2)</th>
  <th>房间个数</th>
  <th>价格（1000$）</th>
</tr>
</thead>
<tbody><tr>
  <td>2104</td>
  <td>3</td>
  <td>400</td>
</tr>
<tr>
  <td>1600</td>
  <td>3</td>
  <td>330</td>
</tr>
<tr>
  <td>2400</td>
  <td>3</td>
  <td>369</td>
</tr>
<tr>
  <td>1416</td>
  <td>2</td>
  <td>232</td>
</tr>
<tr>
  <td>3000</td>
  <td>4</td>
  <td>540</td>
</tr>
</tbody></table>




<p>在上面的表格中，房间的个数以及房屋的面积都是输入变量而，价格就是我们要预测输出的值。其中，面积和房屋个数分别表示一个特征，我们在这将他们一起用X来表示。价格用Y来表示。同时表格的每一行表示成一个样本，具体表示为：<script type="math/tex" id="MathJax-Element-1">f: X_1=[24104,3] \to Y_1=400</script>。</p>




<p>那么我们具体的任务就可以概括成给定一个训练集合，学习出一个函数<script type="math/tex" id="MathJax-Element-2">f</script>，使得<script type="math/tex" id="MathJax-Element-3">f(x)</script>能够符合结果Y，或者说能够使得<script type="math/tex" id="MathJax-Element-4">f(x)</script>与Y的之间的误差最小。</p>




<p>我们可以用以下的式子来表达上述的关系：</p>




<p><script type="math/tex" id="MathJax-Element-5">f(x) = \theta_1 x_1 + \theta_2 x_2 + \beta</script></p>




<p>其中，<script type="math/tex" id="MathJax-Element-6">\theta 表示X映射成Y的权重，而x表示为各组特征。</script> <br>
我们再分别用<script type="math/tex" id="MathJax-Element-7">x^{j},y^{j}来表示第J个样本</script>。这样我们就可以写出代价函数：</p>




<p><script type="math/tex" id="MathJax-Element-8">J(\theta) = \frac {1}{2}\sum ^m_{i=0}(f_\theta(x^{i})-y^{(i)})^2</script></p>




<p>然后我们要使得计算的结果无限接近真实值y的话，我们就要令得我们的代价函数（俗称的误差）最小化。要使得<script type="math/tex" id="MathJax-Element-9">J(\theta)</script>最小，即对<script type="math/tex" id="MathJax-Element-10">J(\theta)</script>进行求导操作，并使得其结果为0。</p>




<p><script type="math/tex" id="MathJax-Element-11">\theta_j = \theta_j - \frac{\partial J(\theta)}{\partial \theta_j}</script></p>




<p>当只有单个特征时，上式中的j表示系数（权重）的编号，右边的值赋给左边的变量后完成一次迭代过程。</p>




<p>而多个特征时，其迭代过程如下： <br>
<img src="https://i.loli.net/2017/09/23/59c5f7bb6ccee.png" alt="gd.png" title=""></p>




<p>上式就是<strong>批梯度下降算法(batch gradient descent)</strong>，当上式收敛时则退出迭代，何为收敛，即前后两次迭代的值不再发生变化了。一般情况下，会设置一个具体的参数，当前后两次迭代差值小于该参数时候结束迭代。注意以下几点：</p>




<p>(1) <strong>a 即学习率（learning rate</strong>），决定的下降步伐，如果太小，则找到函数最小值的速度就很慢，如果太大，则可能会出现无法逼近最小值的现象；</p>




<p>(2) 初始点不同，获得的最小值也不同，因此梯度下降求得的只是局部最小值；</p>




<p>(3) 越接近最小值时，下降速度越慢；</p>




<p>(4) 计算批梯度下降算法时候，计算每一个θ值都需要遍历计算所有样本，当数据量的时候这是比较费时的计算。</p>




<p>批梯度下降算法的步骤可以归纳为以下几步：</p>




<p>(1)先确定向下一步的步伐大小，我们称为Learning rate ；</p>




<p>(2)任意给定一个初始值：θ向量，一般为0向量</p>




<p>(3)确定一个向下的方向，并向下走预先规定的步伐，并更新θ向量</p>




<p>(4)当下降的高度小于某个定义的值，则停止下降；</p>




<h2 id="随机梯度下降算法">随机梯度下降算法</h2>




<p>因为每次计算梯度都需要遍历所有的样本点。这是因为梯度是J(θ)的导数，而J(θ)是需要考虑所有样本的误差和 ，这个方法问题就是，扩展性问题，当样本点很大的时候，基本就没法算了。</p>




<p>所以接下来又提出了<strong>随机梯度下降算法(stochastic gradient descent )</strong>。随机梯度下降算法，每次迭代只是考虑让该样本点的J(θ)趋向最小，而不管其他的样本点，这样算法会很快，但是收敛的过程会比较曲折，整体效果上，大多数时候它只能接近局部最优解，而无法真正达到局部最优解。所以适合用于较大训练集的例子。</p>




<p>其具体流程用公式表达如下：</p>




<p><img src="https://i.loli.net/2017/09/23/59c5f947573e4.png" alt="sgd.png" title=""></p>




<h2 id="代码实现">代码实现</h2>




<h3 id="批梯度下降算法">批梯度下降算法</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#Training data set</span>
</span><span class='line'><span class="c">#each element in x represents (x0,x1,x2)</span>
</span><span class='line'><span class="n">x</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">4.</span><span class="p">,</span><span class="mi">4</span><span class="p">)]</span>
</span><span class='line'><span class="c">#y[i] is the output of y = theta0 * x[0] + theta1 * x[1] +theta2 * x[2]</span>
</span><span class='line'><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">95.364</span><span class="p">,</span><span class="mf">97.217205</span><span class="p">,</span><span class="mf">75.195834</span><span class="p">,</span><span class="mf">60.105519</span><span class="p">,</span><span class="mf">49.342380</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.000001</span>
</span><span class='line'><span class="c">#learning rate</span>
</span><span class='line'><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.001</span>
</span><span class='line'><span class="n">diff</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="n">error1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">error0</span> <span class="o">=</span><span class="mi">0</span>
</span><span class='line'><span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">#init the parameters to zero</span>
</span><span class='line'><span class="n">theta0</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">theta1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">theta2</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">sum0</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">sum1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">sum2</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#calculate the parameters</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span><span class='line'>        <span class="c">#begin batch gradient descent</span>
</span><span class='line'>        <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="p">(</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">theta1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span>
</span><span class='line'>        <span class="n">sum0</span> <span class="o">=</span> <span class="n">sum0</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>        <span class="n">sum1</span> <span class="o">=</span> <span class="n">sum1</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</span><span class='line'>        <span class="n">sum2</span> <span class="o">=</span> <span class="n">sum2</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
</span><span class='line'>        <span class="c">#end  batch gradient descent</span>
</span><span class='line'>    <span class="n">theta0</span> <span class="o">=</span> <span class="n">sum0</span><span class="p">;</span>
</span><span class='line'>    <span class="n">theta1</span> <span class="o">=</span> <span class="n">sum1</span><span class="p">;</span>
</span><span class='line'>    <span class="n">theta2</span> <span class="o">=</span> <span class="n">sum2</span><span class="p">;</span>
</span><span class='line'>    <span class="c">#calculate the cost function</span>
</span><span class='line'>    <span class="n">error1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">lp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
</span><span class='line'>        <span class="n">error1</span> <span class="o">+=</span> <span class="p">(</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="p">(</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">theta1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span> <span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">error1</span><span class="o">-</span><span class="n">error0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
</span><span class='line'>        <span class="k">break</span>
</span><span class='line'>    <span class="k">else</span><span class="p">:</span>
</span><span class='line'>        <span class="n">error0</span> <span class="o">=</span> <span class="n">error1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">print</span><span class="p">(</span><span class="s">&#39; theta0 : </span><span class="si">%f</span><span class="s">, theta1 : </span><span class="si">%f</span><span class="s">, theta2 : </span><span class="si">%f</span><span class="s">, error1 : </span><span class="si">%f</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">,</span><span class="n">error1</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;Done: theta0 : </span><span class="si">%f</span><span class="s">, theta1 : </span><span class="si">%f</span><span class="s">, theta2 : </span><span class="si">%f</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
   theta0 : 0.377225, theta1 : 0.625295, theta2 : 1.120912, error1 : 4405.869965 <br>
   theta0 : 0.729497, theta1 : 1.193311, theta2 : 2.164098, error1 : 3094.652486 <br>
   theta0 : 1.058680, theta1 : 1.708424, theta2 : 3.135362, error1 : 2089.261446 <br>
   theta0 : 1.366497, theta1 : 2.174683, theta2 : 4.040070, error1 : 1335.974025 <br>
   theta0 : 1.654541, theta1 : 2.595831, theta2 : 4.883186, error1 : 789.589683 <br>
   theta0 : 1.924288, theta1 : 2.975327, theta2 : 5.669299, error1 : 412.137681 <br>
   theta0 : 2.177098, theta1 : 3.316371, theta2 : 6.402654, error1 : 171.776368 <br>
   theta0 : 2.414234, theta1 : 3.621921, theta2 : 7.087177, error1 : 41.856096 <br>
   theta0 : 2.636861, theta1 : 3.894714, theta2 : 7.726499, error1 : 0.121739 <br>
   theta0 : 2.846057, theta1 : 4.137277, theta2 : 8.323976, error1 : 28.034282 <br>
   theta0 : 3.042819, theta1 : 4.351950, theta2 : 8.882714, error1 : 110.193963 <br>
   …… <br>
    theta0 : 98.101057, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473679 <br>
   theta0 : 98.101058, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473678 <br>
   theta0 : 98.101058, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473677 <br>
   theta0 : 98.101059, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473676 <br>
   theta0 : 98.101059, theta1 : -13.028753, theta2 : 1.133773, error1 : 3.473675 <br>
   theta0 : 98.101060, theta1 : -13.028753, theta2 : 1.133772, error1 : 3.473674 <br>
   theta0 : 98.101061, theta1 : -13.028753, theta2 : 1.133772, error1 : 3.473673 <br>
  Done: theta0 : 98.101061, theta1 : -13.028753, theta2 : 1.133772</p>
</blockquote>




<p>由上面的输出结果可以知道，梯度下降算法会在迭代一定次数后收敛于一个较少的损失值（即error）然而这并不是最优解而只是一个局部最小值（因为我们也可以从结果看到 theta0 : 2.636861, theta1 : 3.894714, theta2 : 7.726499, error1 : 0.121739，这项数据的最终error反而优于我们的最终解）。</p>




<h3 id="随机梯度下降算法-1">随机梯度下降算法</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#Training data set</span>
</span><span class='line'><span class="c">#each element in x represents (x0,x1,x2)</span>
</span><span class='line'><span class="n">x</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">4.</span><span class="p">,</span><span class="mi">4</span><span class="p">)]</span>
</span><span class='line'><span class="c">#y[i] is the output of y = theta0 * x[0] + theta1 * x[1] +theta2 * x[2]</span>
</span><span class='line'><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">95.364</span><span class="p">,</span><span class="mf">97.217205</span><span class="p">,</span><span class="mf">75.195834</span><span class="p">,</span><span class="mf">60.105519</span><span class="p">,</span><span class="mf">49.342380</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.0001</span>
</span><span class='line'><span class="c">#learning rate</span>
</span><span class='line'><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
</span><span class='line'><span class="n">diff</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="n">error1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">error0</span> <span class="o">=</span><span class="mi">0</span>
</span><span class='line'><span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c">#init the parameters to zero</span>
</span><span class='line'><span class="n">theta0</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">theta1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'><span class="n">theta2</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>
</span><span class='line'><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#calculate the parameters</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="p">(</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">theta1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">theta0</span> <span class="o">=</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>        <span class="n">theta1</span> <span class="o">=</span> <span class="n">theta1</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</span><span class='line'>        <span class="n">theta2</span> <span class="o">=</span> <span class="n">theta2</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">diff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#calculate the cost function</span>
</span><span class='line'>    <span class="n">error1</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">lp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
</span><span class='line'>        <span class="n">error1</span> <span class="o">+=</span> <span class="p">(</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="p">(</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">theta1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span> <span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">error1</span><span class="o">-</span><span class="n">error0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
</span><span class='line'>        <span class="k">break</span>
</span><span class='line'>    <span class="k">else</span><span class="p">:</span>
</span><span class='line'>        <span class="n">error0</span> <span class="o">=</span> <span class="n">error1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">print</span> <span class="p">(</span><span class="s">&#39; theta0 : </span><span class="si">%f</span><span class="s">, theta1 : </span><span class="si">%f</span><span class="s">, theta2 : </span><span class="si">%f</span><span class="s">, error1 : </span><span class="si">%f</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">,</span><span class="n">error1</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;Done: theta0 : </span><span class="si">%f</span><span class="s">, theta1 : </span><span class="si">%f</span><span class="s">, theta2 : </span><span class="si">%f</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
   theta0 : 2.782632, theta1 : 3.207850, theta2 : 7.998823, error1 : 7.508687 <br>
   theta0 : 4.254302, theta1 : 3.809652, theta2 : 11.972218, error1 : 813.550287 <br>
   theta0 : 5.154766, theta1 : 3.351648, theta2 : 14.188535, error1 : 1686.507256 <br>
   theta0 : 5.800348, theta1 : 2.489862, theta2 : 15.617995, error1 : 2086.492788 <br>
   theta0 : 6.326710, theta1 : 1.500854, theta2 : 16.676947, error1 : 2204.562407 <br>
   theta0 : 6.792409, theta1 : 0.499552, theta2 : 17.545335, error1 : 2194.779569 <br>
   theta0 : 7.223066, theta1 : -0.467855, theta2 : 18.302105, error1 : 2134.182794 <br>
   theta0 : 7.630213, theta1 : -1.384304, theta2 : 18.982980, error1 : 2056.719790 <br>
   …… <br>
    theta0 : 97.986505, theta1 : -13.221170, theta2 : 1.257223, error1 : 1.553680 <br>
   theta0 : 97.986620, theta1 : -13.221169, theta2 : 1.257186, error1 : 1.553579 <br>
   theta0 : 97.986735, theta1 : -13.221167, theta2 : 1.257150, error1 : 1.553479 <br>
   theta0 : 97.986849, theta1 : -13.221166, theta2 : 1.257113, error1 : 1.553379 <br>
   theta0 : 97.986963, theta1 : -13.221165, theta2 : 1.257077, error1 : 1.553278 <br>
  Done: theta0 : 97.987078, theta1 : -13.221163, theta2 : 1.257041</p>
</blockquote>




<p>通过上述批梯度下降和随机梯度下降算法代码的对比，不难发现两者的区别： <br>
随机梯度下降算法在迭代的时候，每迭代一个新的样本，就会更新一次所有的theta参数。 <br>
因此当样本数量很大时候，批梯度得做完所有样本的计算才能更新一次theta，从而花费的时间远大于随机梯度下降。但是随机梯度下降过早的结束了迭代，使得它获取的值只是接近局部最优解，而并非像批梯度下降算法那样就是局部最优解。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python 实现推荐系统]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/09/24/python-shi-xian-tui-jian-xi-tong/"/>
    <updated>2017-09-24T10:51:37+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/09/24/python-shi-xian-tui-jian-xi-tong</id>
    <content type="html"><![CDATA[<h1 id="python-实现推荐系统">Python 实现推荐系统</h1>




<h2 id="引言">引言</h2>




<p>最早的推荐系统应该是亚马逊为了提升长尾货物的用户抵达率而发明的。已经有数据证明，长尾商品的销售额以及利润总和与热门商品是基本持平的。亚马逊网站上在线销售的商品何止百万，但首页能够展示的商品数量又极其有限，给用户推荐他们可能喜欢的商品就成了一件非常重要的事情。当然，商品搜索也是一块大蛋糕，亚马逊的商品搜索早已经开始侵蚀谷歌的核心业务了。</p>




<p>从这些例子之中，我们可以看到我们能够使用许多不同的方式来搜集兴趣偏好。有时候，这些数据可能来自人们购买的商品，以及这些商品关联的评价信息。我们可以利用一组算法从中挖掘，建立几个有意思的推荐系统。</p>




<h2 id="推荐系统的简介">推荐系统的简介</h2>




<p>两种最普遍的推荐系统的类型是基于内容的推荐系统和协同过滤推荐系统（CF）。协同过滤基于用户对产品的态度产生推荐，基于内容的推荐系统基于物品属性的相似性进行推荐。CF可以分为基于内存的协同过滤和基于模型的协同过滤。</p>




<h3 id="基于内容推荐">基于内容推荐</h3>




<p><strong>基于内容的推荐（Content-based Recommendation）</strong>，它是建立在项目的内容信息上作出推荐的，而不需要依据用户对项目的评价意见，更多地需要用机器学习的方法从关于内容的特征描述的事例中得到用户的兴趣资料。在基于内容的推荐系统中，项目或对象是通过相关的特征的属性来定义，系统基于用户评价对象的特征，学习用户的兴趣，考察用户资料与待预测项目的相匹配程度。用户的资料模型取决于所用学习方法，常用的有决策树、神经网络和基于向量的表示方法等。</p>




<h4 id="基于内容推荐方法的优点是">基于内容推荐方法的优点是：</h4>




<ul>
<li>不需要其它用户的数据，没有冷开始问题和稀疏问题。</li>
<li>能为具有特殊兴趣爱好的用户进行推荐。</li>
<li>能推荐新的或不是很流行的项目，没有新项目问题。</li>
<li>通过列出推荐项目的内容特征，可以解释为什么推荐那些项目。</li>
<li>已有比较好的技术，如关于分类学习方面的技术已相当成熟。</li>
</ul>




<h4 id="缺点是">缺点是:</h4>




<p>要求内容能容易抽取成有意义的特征，要求特征内容有良好的结构性，并且用户的口味必须能够用内容特征形式来表达，不能显式地得到其它用户的判断情况。</p>




<h3 id="协同过滤推荐">协同过滤推荐</h3>




<p><strong>协同过滤推荐（Collaborative Filtering Recommendation）</strong>，是推荐系统中应用最早和最为成功的技术之一。它一般采用最近邻技术，利用用户的历史喜好信息计算用户之间的距离，然后利用目标用户的最近邻居用户对商品评价的加权评价值来预测目标用户对特定商品的喜好程度，系统从而根据这一喜好程度来对目标用户进行推荐。协同过滤最大优点是对推荐对象没有特殊的要求，能处理非结构化的复杂对象，如音乐、电影。</p>




<p>协同过滤是基于这样的假设：为一用户找到他真正感兴趣的内容的好方法是首先找到与此用户有相似兴趣的其他用户，然后将他们感兴趣的内容推荐给此用 户。其基本思想非常易于理解，在日常生活中，我们往往会利用好朋友的推荐来进行一些选择。协同过滤正是把这一思想运用到电子商务推荐系统中来，基于其他用 户对某一内容的评价来向目标用户进行推荐。</p>




<p>基于协同过滤的推荐系统可以说是从用户的角度来进行相应推荐的，而且是自动的即用户获得的推荐是系统从购买模式或浏览行为等隐式获得的，不需要用户努力地找到适合自己兴趣的推荐信息，如填写一些调查表格等。</p>




<p>和基于内容的过滤方法相比，</p>




<h4 id="协同过滤具有如下的优点">协同过滤具有如下的优点：</h4>




<ul>
<li>能够过滤难以进行机器自动内容分析的信息，如艺术品，音乐等。</li>
<li>共享其他人的经验，避免了内容分析的不完全和不精确，并且能够基于一些复杂的，难以表述的概念（如信息质量、个人品味）进行过滤。</li>
<li>有推荐新信息的能力。可以发现内容上完全不相似的信息，用户对推荐信息的内容事先是预料不到的。这也是协同过滤和基于内容的过滤一个较大的差别，基于内容的过滤推荐很多都是用户本来就熟悉的内容，而协同过滤可以发现用户潜在的但自己尚未发现的兴趣偏好。</li>
<li>能够有效的使用其他相似用户的反馈信息，较少用户的反馈量，加快个性化学习的速度。</li>
</ul>




<h4 id="缺点是-1">缺点是：</h4>




<p>最典型的问题有， <br>
稀疏问题（Sparsity） <br>
可扩展问题（Scalability） <br>
冷启动问题</p>




<h2 id="实例应用">实例应用</h2>




<p>我们下面通过使用MovieLens数据集（这是一个有关电影评分的经典数据集， 其中Movielens-100k和movielens-1M有用户对电影的打分，电影的title、genre、IMDB链接、用户的gender、age、occupation、zip code。movielens-10M中还有用户对电影使用的tag信息。）</p>




<p>数据集的<a href="http://files.grouplens.org/datasets/movielens/ml-100k.zip">下载地址</a></p>




<h3 id="数据读取">数据读取</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;user_id&#39;</span><span class="p">,</span><span class="s">&#39;item_id&#39;</span><span class="p">,</span><span class="s">&#39;rating&#39;</span><span class="p">,</span><span class="s">&#39;timestamp&#39;</span><span class="p">]</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">&#39;/home/ef/Desktop/ml-100k/u.data&#39;</span><span class="p">,</span>
</span><span class='line'>                <span class="n">sep</span><span class="o">=</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">,</span><span class="n">names</span><span class="o">=</span><span class="n">header</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</span><span class='line'><span class="n">n_users</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">user_id</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="n">n_items</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">item_id</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Number of users = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_users</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39; | Number of movies = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_items</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
     user_id  item_id  rating  timestamp <br>
  0      196      242       3  881250949 <br>
  1      186      302       3  891717742 <br>
  2       22      377       1  878887116 <br>
  3      244       51       2  880606923 <br>
  4      166      346       1  886397596 <br>
  Number of users = 943 | Number of movies = 1682</p>
</blockquote>




<h3 id="数据划分">数据划分</h3>




<p>使用scikit-learn库来划分数据集</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span> <span class="k">as</span> <span class="n">cv</span>
</span><span class='line'><span class="n">X_train</span><span class="p">,</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<h3 id="基于内存的协同过滤">基于内存的协同过滤</h3>




<p>基于内存的协同过滤方法可以分为两个部分：</p>




<ul>
<li>用户－产品协同过滤，即：基于用户的协同过滤推荐</li>
<li>产品－产品协同过滤，即：基于物品的协同过滤推荐</li>
</ul>




<p>基于用户的协同过滤推荐，将选取一个特定的用户，基于打分的相似性发现类似于该用户的用户，并推荐那些相似用户喜欢的产品。基于物品的协同过滤推荐会选取一个产品，发现喜欢该产品的用户，并找到这些相似用户还喜欢的其它产品。</p>




<p>基于用户的协同过滤推荐：“喜欢这东西的人也喜欢……” <br>
基于物品的协同过滤推荐：“像你一样的人也喜欢（买个该商品的还买了）……”</p>




<p>在这两种情况下，从整个数据集构建一个用户产品矩阵。</p>




<h4 id="用户产品矩阵的例子">用户产品矩阵的例子：</h4>




<p>计算相似性，并创建一个相似性矩阵。 <br>
通常用于推荐系统中的距离矩阵是余弦相似性，其中，打分被看成n维空间中的向量，而相似性是基于这些向量之间的角度进行计算的。用户a和b的余弦相似性可以用下面的公式进行计算：</p>




<p><script type="math/tex" id="MathJax-Element-1">Similar_u^{cos}(U_a,U_b)=\frac{U_a*U_b}{||U_a|| * ||U_b||} = \frac {\sum x_{a,m}x_{b,m}}{\sqrt {\sum x^2_{a,m}\sum x^2_{b,m} }}</script></p>




<p>同时，物品a和b的相似读也可以写成以上形式。</p>




<p>创建用户产品矩阵，针对测试数据和训练数据，创建两个矩阵：</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span> <span class="k">as</span> <span class="n">cv</span>
</span><span class='line'><span class="n">X_train</span><span class="p">,</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">train_data_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_users</span><span class="p">,</span><span class="n">n_items</span><span class="p">))</span>
</span><span class='line'><span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
</span><span class='line'>    <span class="n">train_data_matrix</span><span class="p">[</span><span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">line</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</span><span class='line'><span class="n">test_data_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_users</span><span class="p">,</span> <span class="n">n_items</span><span class="p">))</span>
</span><span class='line'><span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">x_test</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
</span><span class='line'>    <span class="n">test_data_matrix</span><span class="p">[</span><span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">line</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="c">## 通过余弦相似度计算用户和物品的相似度</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
</span><span class='line'><span class="n">user_similarity</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">train_data_matrix</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="s">&quot;cosine&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">item_similarity</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">train_data_matrix</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="s">&quot;cosine&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<h4 id="评估">评估</h4>




<p>这里采用均方根误差(RMSE)来度量预测评分的准确性,可以使用sklearn的mean_square_error(MSE)函数，其中RMSE仅仅是MSE的平方根。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
</span><span class='line'><span class="k">def</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">):</span>
</span><span class='line'>    <span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</span><span class='line'>    <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">ground_truth</span><span class="p">[</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;User based CF RMSE: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">user_prediction</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;Item based CF RMSe: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">item_prediction</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;User based CF RMSE: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">user_prediction</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&#39;Item based CF RMSe: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">item_prediction</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
  User based CF RMSE: 3.087357412872858 <br>
  Item based CF RMSe: 3.437038163412728</p>
</blockquote>




<p>但从结果来看，算法的推荐效果还算理想。</p>




<h3 id="基于模型的协同过滤">基于模型的协同过滤</h3>




<p>基于模型的协同过滤是基于<strong>矩阵分解(MF)的</strong>，矩阵分解广泛应用于推荐系统中，它比基于内存的CF有更好的扩展性和稀疏性。MF的目标是从已知的评分中学习用户的潜在喜好和产品的潜在属性，随后通过用户和产品的潜在特征的点积来预测未知的评分。 <br>
这是一个典型的机器学习的问题，可以将已有的用户喜好信息作为训练样本，训练出一个预测用户喜好的模型，这样以后用户在进入系统，可以基于此模型计算推荐。这种方法的问题在于如何将用户实时或者近期的喜好信息反馈给训练好的模型，从而提高推荐的准确度。</p>




<h4 id="svd">SVD</h4>




<p>SVD即：<strong>奇异值分解（Singular value decomposition）</strong>奇异值分解是线性代数中一种重要的矩阵分解，在信号处理、统计学等领域有重要应用。奇异值分解在某些方面与对称矩阵或Hermite矩阵基于特征向量的对角化类似。然而这两种矩阵分解尽管有其相关性，但还是有明显的不同。对称阵特征向量分解的基础是谱分析，而奇异值分解则是谱分析理论在任意矩阵上的推广。</p>




<p>在矩阵M的奇异值分解中</p>




<p><script type="math/tex" id="MathJax-Element-2">M=UΣV^T</script> </p>




<ul>
<li><strong>U的列(columns)</strong>组成一套对M的正交”输入”或”分析”的基向量。这些向量是MM*的特征向量。</li>
<li><strong>V的列(columns)</strong>组成一套对M的正交”输出”的基向量。这些向量是M*M的特征向量。</li>
<li><strong>Σ对角线上的元素</strong>是奇异值，可视为是在输入与输出间进行的标量的”膨胀控制”。这些是M*M及MM*的奇异值，并与U和V的列向量相对应。</li>
</ul>




<p>那么矩阵M就可以分解成U，Σ，V。 <br>
U矩阵表示对应于隐藏特性空间中的用户的特性矩阵，而V矩阵表示对应于隐藏特性空间中的产品的特性矩阵。</p>




<p>现在，我们可以通过U，Σ和<script type="math/tex" id="MathJax-Element-3">V^T</script>的点积进行预测了。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># 计算矩阵的稀疏度</span>
</span><span class='line'><span class="n">sparsity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">n_users</span><span class="o">*</span><span class="n">n_items</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;The sparsity level of MovieLen100K is &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sparsity</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39;%&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="kn">as</span> <span class="nn">sp</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scipy.sparse.linalg</span> <span class="kn">import</span> <span class="n">svds</span>
</span><span class='line'><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vt</span> <span class="o">=</span> <span class="n">svds</span><span class="p">(</span><span class="n">train_data_matrix</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
</span><span class='line'><span class="n">s_diag_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</span><span class='line'><span class="n">x_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">s_diag_matrix</span><span class="p">),</span><span class="n">vt</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;User-based CF MSE: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">test_data_matrix</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果： <br>
  The sparsity level of MovieLen100K is 93.7% <br>
  User-based CF MSE: 2.63901831155016</p>
</blockquote>




<p>最后，我们可以发现，采用SVD分解矩阵的基于模型的协同过滤方法在推荐的表现上更胜一筹。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apriori与关联分析]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/09/19/aprioriyu-guan-lian-fen-xi/"/>
    <updated>2017-09-19T13:33:11+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/09/19/aprioriyu-guan-lian-fen-xi</id>
    <content type="html"><![CDATA[<h1 id="关联分析">关联分析</h1>




<h2 id="相关概念">相关概念</h2>




<p>作为经典的机器学习算法来说，关联分析并不算复杂。简单来说，从大规模数据集中寻找物品间的隐含关系被称作<strong>关联分析(association analysis)</strong>或者<strong>关联规则学习(association rule learning)</strong>。而其中关联分析的关键就是在众多的物品组成的<strong>项集(itemset)</strong>中找到那些经常一起出现的物品集合，也就是我们所谓的<strong>频繁项集</strong>。由于寻找物品的不同组合是一项非常耗时的任务，所需的计算代价也非常的高，这样显然用蛮力的搜索方法是不可取的。为了解决这样的问题，我们需要用到<strong>Apriori算法</strong>来解决。</p>




<h4 id="有关关联分析的一些应用">有关关联分析的一些应用</h4>




<ol>
<li>购物篮分析，这是关联分析最经典的一项应用。我们耳熟能详的<a href="http://www.jianshu.com/p/a22890153f93"><em>尿布与啤酒</em></a>就是来源于此（虽然这个故事的真实性有待考据，但这并不影响它成为一个营销界的小故事）。</li>
<li>公众热点发现</li>
<li>新闻及流行趋势挖掘</li>
<li>搜索引擎推荐</li>
<li>发现毒蘑菇的相似特征（该例子取自《机器学习实战》一书）</li>
</ol>




<h2 id="apriori算法">Apriori算法</h2>




<p>优点：易编码实现 <br>
缺点：在大数据集上计算效果较慢</p>




<p>既然关联分析是一种在大规模数据集中寻找有趣的关系的任务。这些关系可以有两种形式：一种就是我们上面所说的<strong>频繁项集(frequent itemsets)</strong>;另外一种则是<strong>关联规则(association rules)</strong>。关联规则，其暗示了两种物品之间可能存在很强的关系。</p>




<p>那么我们该如何定义有趣的关系呢？以及，频繁项集中的频繁有怎么划定呢？虽然，许多概念都可以说明这些问题，但是最重要及最通用的莫过于其<strong>支持度</strong>和<strong>可信度</strong>。</p>




<p><strong>支持度(support)：</strong>一个项集的支持度被定义为数据集包含该项集的记录比例。</p>




<blockquote>
  <p>举个例子: <br>
<img src="https://i.loli.net/2017/09/30/59ce75c2b9080.jpg" alt="apriori.jpg" title="apriori.jpg" /><br>
  如上图所示，因为5项记录中有4条包含了{豆奶}，所以其支持度为4/5;依此类推，{豆奶，尿布}的支持读为3/5。</p>
</blockquote>




<p><strong>可信度或置信度(confidence)：</strong>这个概念是针对一条{尿布} -&gt; {葡萄酒}这样的关联规则来定义的。</p>




<blockquote>
  <p><script type="math/tex" id="MathJax-Element-1">置信度({尿布} -> {葡萄酒} )= 支持度({尿布,葡萄酒}) / 支持度({尿布})</script></p>
</blockquote>




<p>支持度和可信度是用来量化关联分析是否成功的方法。</p>




<h4 id="apriori原理">Apriori原理</h4>




<p>如果计算一个集合中的频繁项集的支持度，首先需要遍历全部可能的项集，比如针对一个包含了4个产品的集合，那么购买该集合产品的可能集合数目为2^4-1=15，而针对包含N项的集合，就需要遍历2^N-1。显然，这样的计算量很大。为了降低所需计算时间，就需要我们所谓的Apriori原理。</p>




<p><strong>其基本思路：</strong>如果某个项集是频繁的，那么它的所有子集也是频繁的。该定理的逆反定理为：如果某一个项集是非频繁的，那么它的所有超集（包含该集合的集合）也是非频繁的。Apriori原理的出现，可以在得知某些项集是非频繁之后，不需要计算该集合的超集，有效地避免项集数目的指数增长，从而在合理时间内计算出频繁项集。</p>




<h4 id="算法基本流程">算法基本流程</h4>




<p>当集合中项的个数大于0时： <br>
    创建一个长度为k的候选项集列表 <br>
    检查数据以确认每个项集都是频繁的 <br>
    保留频繁项集，并构建k+1项组成的候选集列表</p>




<h4 id="代码实现">代码实现</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">load_dataset</span><span class="p">():</span>
</span><span class='line'>    <span class="s">&quot;Load the sample dataset.&quot;</span>
</span><span class='line'>    <span class="k">return</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
</span><span class='line'><span class="k">def</span> <span class="nf">createC1</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Create a list of candidate item sets of size one.&quot;</span>
</span><span class='line'>    <span class="n">c1</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">transaction</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">transaction</span><span class="p">:</span>
</span><span class='line'>            <span class="k">if</span> <span class="ow">not</span> <span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="ow">in</span> <span class="n">c1</span><span class="p">:</span>
</span><span class='line'>                <span class="n">c1</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">item</span><span class="p">])</span>
</span><span class='line'>    <span class="n">c1</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</span><span class='line'>    <span class="c">#frozenset because it will be a ket of a dictionary.</span>
</span><span class='line'>    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">,</span> <span class="n">c1</span><span class="p">))</span>
</span><span class='line'><span class="k">def</span> <span class="nf">scanD</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">min_support</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Returns all candidates that meets a minimum support level&quot;</span>
</span><span class='line'>    <span class="n">sscnt</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">tid</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
</span><span class='line'>        <span class="c">#print(tid)</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">can</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">can</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">tid</span><span class="p">):</span>
</span><span class='line'>                <span class="n">sscnt</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">can</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span class='line'>                <span class="n">sscnt</span><span class="p">[</span><span class="n">can</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">num_items</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
</span><span class='line'>    <span class="n">retlist</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="n">support_data</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">sscnt</span><span class="p">:</span>
</span><span class='line'>        <span class="n">support</span> <span class="o">=</span> <span class="n">sscnt</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="n">num_items</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">support</span> <span class="o">&gt;=</span> <span class="n">min_support</span><span class="p">:</span>
</span><span class='line'>            <span class="n">retlist</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
</span><span class='line'>        <span class="n">support_data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">support</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">retlist</span><span class="p">,</span> <span class="n">support_data</span>
</span><span class='line'><span class="k">def</span> <span class="nf">aprioriGen</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Generate the joint transactions from candidate sets&quot;</span>
</span><span class='line'>    <span class="n">retList</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="n">lenLk</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">)</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">lenLk</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">lenLk</span><span class="p">):</span>
</span><span class='line'>            <span class="n">L1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">[</span><span class="n">i</span><span class="p">])[:</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span>
</span><span class='line'>            <span class="n">L2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">[</span><span class="n">j</span><span class="p">])[:</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span>
</span><span class='line'>            <span class="n">L1</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</span><span class='line'>            <span class="n">L2</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">L1</span> <span class="o">==</span> <span class="n">L2</span><span class="p">:</span>
</span><span class='line'>                <span class="n">retList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">freq_sets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">|</span> <span class="n">freq_sets</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">retList</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">apriori</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">minsupport</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Generate a list of candidate item sets&quot;</span>
</span><span class='line'>    <span class="n">C1</span> <span class="o">=</span> <span class="n">createC1</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</span><span class='line'>    <span class="n">D</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">set</span><span class="p">,</span> <span class="n">dataset</span><span class="p">))</span>
</span><span class='line'>    <span class="n">L1</span><span class="p">,</span> <span class="n">support_data</span> <span class="o">=</span> <span class="n">scanD</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">minsupport</span><span class="p">)</span>
</span><span class='line'>    <span class="n">L</span> <span class="o">=</span> <span class="p">[</span><span class="n">L1</span><span class="p">]</span>
</span><span class='line'>    <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span>
</span><span class='line'>    <span class="k">while</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">L</span><span class="p">[</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
</span><span class='line'>        <span class="n">Ck</span> <span class="o">=</span> <span class="n">aprioriGen</span><span class="p">(</span><span class="n">L</span><span class="p">[</span><span class="n">k</span> <span class="o">-</span> <span class="mi">2</span><span class="p">],</span> <span class="n">k</span><span class="p">)</span>
</span><span class='line'>        <span class="n">Lk</span><span class="p">,</span> <span class="n">supK</span> <span class="o">=</span> <span class="n">scanD</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">Ck</span><span class="p">,</span> <span class="n">minsupport</span><span class="p">)</span>
</span><span class='line'>        <span class="n">support_data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">supK</span><span class="p">)</span>
</span><span class='line'>        <span class="n">L</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Lk</span><span class="p">)</span>
</span><span class='line'>        <span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">L</span><span class="p">,</span> <span class="n">support_data</span>
</span></code></pre></td></tr></table></div></figure>


<h4 id="挖掘关联规则">挖掘关联规则</h4>




<p>上面，我们实现了用apriori算法找出了频繁项集。现在我们来尝试找出关联规则。那么什么是关联规则呢？我们可以举这样一个例子：假设我们有一个频繁项集是：{豆奶，莴苣}。那么则意味着一个人如果他已经购买了豆奶，那么他也有很大的几率会购买莴苣;但反过来却不一定成立：则如果一个人购买了莴苣，但还是不能说明他有很大几率会接着购买豆奶。</p>




<p>既然，在上面的例子中我们已经用支持度作为一种参考单位去量化一个集合的频繁关系，在这里我们同理也可以通过另一个概念来度量关联规则。没错，它就是我们已经在上面提过的<strong>可信度</strong>。根据可信度的计算法则和定义可知：</p>




<blockquote>
  <p><script type="math/tex" id="MathJax-Element-2">置信度({尿布} -> {葡萄酒} )= 支持度({尿布,葡萄酒}) / 支持度({尿布})</script></p>
</blockquote>




<p>这也是我们上面已经提及过的问题。加上，在上面的例子之中我们已经得到了所有的频繁项集的支持度，那么为了求出各关联规则的可信度也就是剩下一个除法的问题而已。</p>




<h4 id="如何从频繁项集中生成关联规则">如何从频繁项集中生成关联规则</h4>




<p>一般对于一个频繁项集而言，如果我们直接生成关联规则的话，往往会有很多条。例如：我们对一个频繁项集{0，1，2，3}直接生成关联规则的话结果就如下图所示一样： <br>
<img src="https://i.loli.net/2017/09/30/59ce75dc70dd2.png" alt="assrule.png" title="assrule.png" /><br>
从上图我们就可以看出仅仅含4项的频繁项集就会生成出如此多的关联规则，那么如果频繁项集中含有10，20，甚至100个元素那么生成的候选关联规则的数据是相当庞大。</p>




<p>在此，我们可以参考apriori算法中挖掘频繁项集的思路。在发现频繁项集时我们通过最低支持度的方法来忽略掉一些项集支持度的计算;同理，在这里我们将这个思想应用在关联规则的生成之上，即：如果一条规则的不满足最低可信度的要求，那么其子集自然也不能满足最低可信度的要求。对于这部分规则的可信度计算我们可以直接忽略。如上图中的阴影部分。我们假设规则{0，1，2} -&gt; 3不能满足最低可信度，那么，他的子集{1，2}-&gt;{0，3}，{0，2}-&gt;{1，3}等将不能满足最低可信度。</p>




<h4 id="代码实现-1">代码实现</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">generateRules</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">min_confidence</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;Create the association rules</span>
</span><span class='line'><span class="sd">    L: list of frequent item sets</span>
</span><span class='line'><span class="sd">    support_data: support data for those itemsets</span>
</span><span class='line'><span class="sd">    min_confidence: minimum confidence threshold</span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">rules</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">L</span><span class="p">)):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">freqSet</span> <span class="ow">in</span> <span class="n">L</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
</span><span class='line'>            <span class="n">H1</span> <span class="o">=</span> <span class="p">[</span><span class="nb">frozenset</span><span class="p">([</span><span class="n">item</span><span class="p">])</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">freqSet</span><span class="p">]</span>
</span><span class='line'>            <span class="k">print</span><span class="p">(</span><span class="s">&quot;freqSet&quot;</span><span class="p">,</span> <span class="n">freqSet</span><span class="p">,</span> <span class="s">&#39;H1&#39;</span><span class="p">,</span> <span class="n">H1</span><span class="p">)</span>
</span><span class='line'>            <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
</span><span class='line'>                <span class="n">rules_from_conseq</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">H1</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="p">)</span>
</span><span class='line'>            <span class="k">else</span><span class="p">:</span>
</span><span class='line'>                <span class="n">calc_confidence</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">H1</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">rules</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">calc_confidence</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Evaluate the rule generated&quot;</span>
</span><span class='line'>    <span class="n">pruned_H</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">conseq</span> <span class="ow">in</span> <span class="n">H</span><span class="p">:</span>
</span><span class='line'>        <span class="n">conf</span> <span class="o">=</span> <span class="n">support_data</span><span class="p">[</span><span class="n">freqSet</span><span class="p">]</span> <span class="o">/</span> <span class="n">support_data</span><span class="p">[</span><span class="n">freqSet</span> <span class="o">-</span> <span class="n">conseq</span><span class="p">]</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">conf</span> <span class="o">&gt;=</span> <span class="n">min_confidence</span><span class="p">:</span>
</span><span class='line'>            <span class="k">print</span><span class="p">(</span><span class="n">freqSet</span> <span class="o">-</span> <span class="n">conseq</span><span class="p">,</span> <span class="s">&#39;---&gt;&#39;</span><span class="p">,</span> <span class="n">conseq</span><span class="p">,</span> <span class="s">&#39;conf:&#39;</span><span class="p">,</span> <span class="n">conf</span><span class="p">)</span>
</span><span class='line'>            <span class="n">rules</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">freqSet</span> <span class="o">-</span> <span class="n">conseq</span><span class="p">,</span> <span class="n">conseq</span><span class="p">,</span> <span class="n">conf</span><span class="p">))</span>
</span><span class='line'>            <span class="n">pruned_H</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conseq</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">pruned_H</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">rules_from_conseq</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
</span><span class='line'>    <span class="s">&quot;Generate a set of candidate rules&quot;</span>
</span><span class='line'>    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">H</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">freqSet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
</span><span class='line'>        <span class="n">Hmp1</span> <span class="o">=</span> <span class="n">aprioriGen</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>        <span class="n">Hmp1</span> <span class="o">=</span> <span class="n">calc_confidence</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">Hmp1</span><span class="p">,</span>  <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="p">)</span>
</span><span class='line'>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Hmp1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span class='line'>            <span class="n">rules_from_conseq</span><span class="p">(</span><span class="n">freqSet</span><span class="p">,</span> <span class="n">Hmp1</span><span class="p">,</span> <span class="n">support_data</span><span class="p">,</span> <span class="n">rules</span><span class="p">,</span> <span class="n">min_confidence</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>运行测试</p>
</blockquote>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">()</span>
</span><span class='line'><span class="n">L</span><span class="p">,</span><span class="n">support_data</span> <span class="o">=</span> <span class="n">apriori</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</span><span class='line'><span class="n">generateRules</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">support_data</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  freqSet frozenset({3, 5}) H1 [frozenset({3}), frozenset({5})] <br>
  freqSet frozenset({1, 3}) H1 [frozenset({1}), frozenset({3})] <br>
  frozenset({1}) —&gt; frozenset({3}) conf: 1.0 <br>
  freqSet frozenset({2, 5}) H1 [frozenset({2}), frozenset({5})] <br>
  frozenset({5}) —&gt; frozenset({2}) conf: 1.0 <br>
  frozenset({2}) —&gt; frozenset({5}) conf: 1.0 <br>
  freqSet frozenset({2, 3}) H1 [frozenset({2}), frozenset({3})] <br>
  freqSet frozenset({2, 3, 5}) H1 [frozenset({2}), frozenset({3}), frozenset({5})] <br>
  Out[6]: <br>
  [(frozenset({1}), frozenset({3}), 1.0), <br>
   (frozenset({5}), frozenset({2}), 1.0), <br>
   (frozenset({2}), frozenset({5}), 1.0)]</p>
</blockquote>




<p>从输出结果可以看出，其中{1} —&gt; {3}，{5} —&gt; {2}，{2} —&gt; {5}这三条关联规则的可信度居然达到了1.0，而且{2}，{5}还存在一个相互关联的关系。除此之外，我们还可以发现：虽然{1} —&gt; {3}这条关联的可信度达到了1.0，但是{3} —&gt; {1}却不足0.7（因为我们的最低可信度标准为0.7，没有输出显示的规则，则意味着它们的可信度低于0.7)。为了可以看见输出更多的规则，我们可以降低下最低可信度的标准，再来执行一遍代码。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">()</span>
</span><span class='line'><span class="n">L</span><span class="p">,</span><span class="n">support_data</span> <span class="o">=</span> <span class="n">apriori</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</span><span class='line'><span class="n">generateRules</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">support_data</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  freqSet frozenset({3, 5}) H1 [frozenset({3}), frozenset({5})] <br>
  frozenset({5}) —&gt; frozenset({3}) conf: 0.6666666666666666 <br>
  frozenset({3}) —&gt; frozenset({5}) conf: 0.6666666666666666 <br>
  freqSet frozenset({1, 3}) H1 [frozenset({1}), frozenset({3})] <br>
  frozenset({3}) —&gt; frozenset({1}) conf: 0.6666666666666666 <br>
  frozenset({1}) —&gt; frozenset({3}) conf: 1.0 <br>
  freqSet frozenset({2, 5}) H1 [frozenset({2}), frozenset({5})] <br>
  frozenset({5}) —&gt; frozenset({2}) conf: 1.0 <br>
  frozenset({2}) —&gt; frozenset({5}) conf: 1.0 <br>
  freqSet frozenset({2, 3}) H1 [frozenset({2}), frozenset({3})] <br>
  frozenset({3}) —&gt; frozenset({2}) conf: 0.6666666666666666 <br>
  frozenset({2}) —&gt; frozenset({3}) conf: 0.6666666666666666 <br>
  freqSet frozenset({2, 3, 5}) H1 [frozenset({2}), frozenset({3}), frozenset({5})] <br>
  frozenset({5}) —&gt; frozenset({2, 3}) conf: 0.6666666666666666 <br>
  frozenset({3}) —&gt; frozenset({2, 5}) conf: 0.6666666666666666 <br>
  frozenset({2}) —&gt; frozenset({3, 5}) conf: 0.6666666666666666 <br>
  Out[7]: <br>
  [(frozenset({5}), frozenset({3}), 0.6666666666666666), <br>
   (frozenset({3}), frozenset({5}), 0.6666666666666666), <br>
   (frozenset({3}), frozenset({1}), 0.6666666666666666), <br>
   (frozenset({1}), frozenset({3}), 1.0), <br>
   (frozenset({5}), frozenset({2}), 1.0), <br>
   (frozenset({2}), frozenset({5}), 1.0), <br>
   (frozenset({3}), frozenset({2}), 0.6666666666666666), <br>
   (frozenset({2}), frozenset({3}), 0.6666666666666666), <br>
   (frozenset({5}), frozenset({2, 3}), 0.6666666666666666), <br>
   (frozenset({3}), frozenset({2, 5}), 0.6666666666666666), <br>
   (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)]</p>
</blockquote>




<p>这次我们就可以在输出中看见{3} —&gt; {1}了，它的可信度为0.6666666666666666。</p>




<p>到此，有关关联分析的apriori算法就告一段落了。后续还会有有关关联分析FP-growth算法的文章讲解。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Geek的写作方式——LaTeX 入门]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/09/14/geekde-xie-zuo-fang-shi-latex-ru-men/"/>
    <updated>2017-09-14T21:25:58+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/09/14/geekde-xie-zuo-fang-shi-latex-ru-men</id>
    <content type="html"><![CDATA[<h1 id="geek的写作方式latex-入门">Geek的写作方式——LaTeX 入门</h1>




<h2 id="有关latex的简介">有关LaTex的简介</h2>




<p>说道LaTex首先要提到<strong>TeX （文本排版系统）</strong>  <br>
TeX是由著名的计算机科学家Donald E. Knuth（高德纳）发明的排版系统，利用TeX可以很容易地生成高质量的dvi文件，打印输出。利用dvips,dvipdfmx,pdfLaTeX等程序生成pdf，ps，文件，LaTeX2html生成html文件。它在学术界十分流行，特别是数学、物理学和计算机科学界。TeX被普遍认为是一个很好的排版工具，特别是在处理复杂的数学公式时。</p>




<p>而LaTeX使用TeX作为它的格式化引擎。 <br>
Leslie Lamport开发的LaTeX是当今世界上最流行和使用最为广泛的TeX宏集。它构筑在Plain TeX的基础之上，并加进了很多的功能以使得使用者可以更为方便的利用TeX的强大功能。使用LaTeX基本上不需要使用者自己设计命令和宏等，因为LaTeX已经替你做好了。因此，即使使用者并不是很了解TeX，也可以在短短的时间内生成高质量的文档。对于生成复杂的数学公式，LaTeX表现的更为出色。</p>




<h2 id="latex的应用">LaTex的应用</h2>




<ol>
<li>使用 (La)TeX进行简单的中英混排；</li>
<li>简单的文章组织结构；</li>
<li>使用 (La)TeX 进行数学公式的排版；</li>
<li>在 (La)TeX 的文档中插入图片/表格；</li>
<li>最常见的带有 TeX 的单词的含义；</li>
</ol>




<h4 id="简单的规则">简单的规则</h4>




<p>为了实现强大的排版能力，LaTex背后定义了一些非常严谨的语法和规则。 <br>
（1）空格：Latex中空格不起作用。 <br>
（2）换行：用控制命令“\”,或“ \newline”. <br>
（3）分段：用控制命令“\par” 或空出一行。 <br>
（4）换页：用控制命令“\newpage”或“\clearpage” <br>
（5）特殊控制字符：#，$, %, &amp;, - ,{, }, ^, ~ <br>
要想输出这些控制符用下列命令：</p>




<blockquote>
  <p>\# <span>\</span>$   \%  \&amp;  \-  \{  \}    \^{}  \~{}    其中 \blackslash 表示“ \”。</p>
</blockquote>




<p>在讲具体如何使用LaTex之前，先给大家推荐一下LaTex在线编辑器方便大家做测试。</p>




<p><a href="http://gongshi.baidu.com/latex.html">kityformula：WEB mathematical formulas projects</a> ，同时项目的Github地址在「<a href="https://github.com/fex-team/kityformula">这里</a>」</p>




<h3 id="尝试第一次中英文排版">尝试第一次中英文排版</h3>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">[</span>UTF8<span class="hljs-special">]</span><span class="hljs-special">{</span>article<span class="hljs-special">}</span>
<span class="hljs-comment">%这里是导言区</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
Blahblahblah... 
你好，世界。etc.
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<p>此处的第一行 \documentclass{article} 中包含了一个控制序列（或称命令/标记）。所谓控制序列，是以反斜杠\开头，以第一个空格或非字母 的字符结束的一串文字，他们并不被输出，但是他们会影响输出文档的效果。这里的控制序列是 documentclass，它后面紧跟着的 {article} 代表这个控制序列有一个必要的参数，该参数的值为 article。这个控制序列的作用，是调用名为 “article” 的文档类。</p>




<p>方括号[]包括的可选参数，这里表示采用UTF-8编码。</p>




<p><strong>请注意，(La)TeX 对控制序列的大小写是敏感的。</strong></p>




<p>此处的第二行以 % 开头。在 TeX 风格的文档中，从 “%” 开始，到该行末尾的所有字符，都会被 TeX 系统无视，只作为供人类阅读的注释。除非在 “%” 前加上反斜杠来取消这一特性。</p>




<h3 id="组织你的文章">组织你的文章</h3>




<h4 id="作者标题日期">作者、标题、日期</h4>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">{</span>article<span class="hljs-special">}</span>
<span class="hljs-command">\title</span><span class="hljs-special">{</span>Cartesian closed categories and the price of eggs<span class="hljs-special">}</span>
<span class="hljs-command">\author</span><span class="hljs-special">{</span>Jane Doe<span class="hljs-special">}</span>
<span class="hljs-command">\date</span><span class="hljs-special">{</span>September 1994<span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
   <span class="hljs-command">\maketitle</span>
   Hello world!
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<h4 id="章节和段落">章节和段落</h4>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">[</span>UTF8<span class="hljs-special">]</span><span class="hljs-special">{</span>ctexart<span class="hljs-special">}</span>
<span class="hljs-command">\title</span><span class="hljs-special">{</span>hello，world!<span class="hljs-special">}</span>
<span class="hljs-command">\author</span><span class="hljs-special">{</span>Liam<span class="hljs-special">}</span>
<span class="hljs-command">\date</span><span class="hljs-special">{</span><span class="hljs-command">\today</span><span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
<span class="hljs-command">\maketitle</span>
<span class="hljs-command">\section</span><span class="hljs-special">{</span>你好，世界<span class="hljs-special">}</span>
Welcome to 中国.
<span class="hljs-command">\subsection</span><span class="hljs-special">{</span>Hello China<span class="hljs-special">}</span>
北京是capital of China.
<span class="hljs-command">\subsubsection</span><span class="hljs-special">{</span>Hello BeiJing<span class="hljs-special">}</span>
<span class="hljs-command">\paragraph</span><span class="hljs-special">{</span>Tian'anmen Square<span class="hljs-special">}</span>
is in the center of Beijing
<span class="hljs-command">\subparagraph</span><span class="hljs-special">{</span>Chairman Mao<span class="hljs-special">}</span>
is in the center of 天安门广场。
<span class="hljs-command">\subsection</span><span class="hljs-special">{</span>Hello 广东<span class="hljs-special">}</span>
<span class="hljs-command">\paragraph</span><span class="hljs-special">{</span>中山大学<span class="hljs-special">}</span> is one of the best university in 广东。
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<p>在文档类 article/ctexart 中，定义了五个控制序列来调整行文组织结构。他们分别是</p>




<ul>
<li>\section{·}</li>
<li>\subsection{·}</li>
<li>\subsubsection{·}</li>
<li>\paragraph{·}</li>
<li>\subparagraph{·}</li>
</ul>




<h4 id="插入目录">插入目录</h4>




<p>在上一节的文档中，找到 \maketitle，在它的下面插入控制序列 \tableofcontents</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">[</span>UTF8<span class="hljs-special">]</span><span class="hljs-special">{</span>ctexart<span class="hljs-special">}</span>
<span class="hljs-command">\title</span><span class="hljs-special">{</span>hello，world!<span class="hljs-special">}</span>
<span class="hljs-command">\author</span><span class="hljs-special">{</span>Liam<span class="hljs-special">}</span>
<span class="hljs-command">\date</span><span class="hljs-special">{</span><span class="hljs-command">\today</span><span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
<span class="hljs-command">\maketitle</span>
<span class="hljs-command">\tableofcontents</span>
<span class="hljs-command">\section</span><span class="hljs-special">{</span>你好，世界<span class="hljs-special">}</span>
Welcome to 中国.
<span class="hljs-command">\subsection</span><span class="hljs-special">{</span>Hello China<span class="hljs-special">}</span>
北京是capital of China.
<span class="hljs-command">\subsubsection</span><span class="hljs-special">{</span>Hello BeiJing<span class="hljs-special">}</span>
<span class="hljs-command">\paragraph</span><span class="hljs-special">{</span>Tian'anmen Square<span class="hljs-special">}</span>
is in the center of Beijing
<span class="hljs-command">\subparagraph</span><span class="hljs-special">{</span>Chairman Mao<span class="hljs-special">}</span>
is in the center of 天安门广场。
<span class="hljs-command">\subsection</span><span class="hljs-special">{</span>Hello 广东<span class="hljs-special">}</span>
<span class="hljs-command">\paragraph</span><span class="hljs-special">{</span>中山大学<span class="hljs-special">}</span> is one of the best university in 广东。
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<h3 id="数学公式排版">数学公式排版</h3>




<p>数学公式排版功能是LaTeX 最为强大的部分。</p>




<h4 id="数学模式">数学模式</h4>




<p>LaTeX 的数学模式有两种：<strong>行内模式 (inline)</strong> 和<strong>行间模式 (display)</strong>。前者在正文的行文中，插入数学公式；后者独立排列单独成行，并自动居中。</p>




<p>在行文中，使用 <script type="math/tex" id="MathJax-Element-77"> ... </script> 可以插入行内公式，使用 [ … ] 可以插入行间公式，如果需要对行间公式进行编号，则可以使用 equation 环境： <br>
<strong>eg：</strong></p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\begin</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span>
...
<span class="hljs-command">\end</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span></code></pre>




<h4 id="上下标">上下标</h4>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">{</span>article<span class="hljs-special">}</span>
<span class="hljs-command">\usepackage</span><span class="hljs-special">{</span>amsmath<span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
Einstein 's <span class="hljs-formula">$E=mc^2$</span>.

<span class="hljs-command">\[</span> E=mc^2. <span class="hljs-command">\]</span>

<span class="hljs-command">\begin</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span>
E=mc^2.
<span class="hljs-command">\end</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span>
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex; mode=display" id="MathJax-Element-149">\begin{equation}
E=mc^2 \\
2H_2+O_2==2H_2O
\end{equation}</script></p>




<p>在数学模式中，需要表示上标，可以使用 ^ 来实现（下标则是 _）。它默认只作用于之后的一个字符，如果想对连续的几个字符起作用，请将这些字符用花括号 {} 括起来。</p>




<h4 id="根式与分式">根式与分式</h4>




<p>根式用 \sqrt{·} 来表示，分式用 \frac{·}{·} 来表示（第一个参数为分子，第二个为分母）。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\documentclass</span><span class="hljs-special">{</span>article<span class="hljs-special">}</span>
<span class="hljs-command">\usepackage</span><span class="hljs-special">{</span>amsmath<span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span>
<span class="hljs-command">\sqrt</span><span class="hljs-special">{</span>x<span class="hljs-special">}</span><span class="hljs-formula">$, $</span><span class="hljs-command">\frac</span><span class="hljs-special">{</span>1<span class="hljs-special">}</span><span class="hljs-special">{</span>2<span class="hljs-special">}</span><span class="hljs-formula">$.
<span class="hljs-command">\[</span> <span class="hljs-command">\sqrt</span><span class="hljs-special">{</span>x<span class="hljs-special">}</span>, <span class="hljs-command">\]</span>
<span class="hljs-command">\[</span> <span class="hljs-command">\frac</span><span class="hljs-special">{</span>1<span class="hljs-special">}</span><span class="hljs-special">{</span>2<span class="hljs-special">}</span>. <span class="hljs-command">\]</span>
<span class="hljs-command">\end</span><span class="hljs-special">{</span>document<span class="hljs-special">}</span></span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-151">\sqrt{x} \\ \frac{1}{2}</script></p>




<h4 id="运算符号">运算符号</h4>




<p>一些小的运算符，可以在数学模式下直接输入；另一些需要用控制序列生成。 <br>
[ \pm\; \times \; \div\; \cdot\; \cap\; \cup\; <br>
\geq\; \leq\; \neq\; \approx \; \equiv ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-400">[ \pm\; \times \; \div\; \cdot\; \cap\; \cup\;  
\geq\; \leq\; \neq\; \approx \; \equiv ]</script></p>




<p>连加、连乘、极限、积分等大型运算符分别用 \sum, \prod, \lim, \int生成。他们的上下标在行内公式中被压缩，以适应行高。我们可以用 \limits 和 \nolimits 来强制显式地指定是否压缩这些上下标。 <br>
 \sum_{i=1}^n i <br>
 \prod_{i=1}^n  <br>
 \sum\limits <em>{i=1}^n i\quad \prod\limits </em>{i=1}^n  <br>
[ \lim_{x\to0}x^2 \quad \int_a^b x^2 dx ] <br>
[ \lim\nolimits _{x\to0}x^2\quad \int\nolimits_a^b x^2 dx ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-401">\sum_{i=1}^n i</script>  <br>
<script type="math/tex" id="MathJax-Element-402">\prod_{i=1}^n</script> <br>
<script type="math/tex" id="MathJax-Element-403">\sum\limits _{i=1}^n i\quad \prod\limits _{i=1}^n</script> <br>
<script type="math/tex" id="MathJax-Element-404">[ \lim_{x\to0}x^2 \quad \int_a^b x^2 dx ]</script> <br>
<script type="math/tex" id="MathJax-Element-405">[ \lim\nolimits _{x\to0}x^2\quad \int\nolimits_a^b x^2 dx ]</script></p>




<p>多重积分可以使用 \iint, \iiint, \iiiint, \idotsint 等命令输入。 <br>
[ \iint\quad \iiint\quad \iiiint\quad \idotsint ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-406">[ \iint\quad \iiint\quad \iiiint\quad \idotsint ]</script></p>




<h4 id="定界符括号等">定界符（括号等）</h4>




<p>各种括号用 (), [], {}, \langle\rangle 等命令表示； <br>
注意花括号通常用来输入命令和环境的参数，所以在数学公式中它们前面要加 \。</p>




<p>[ \Biggl(\biggl(\Bigl(\bigl((x)\bigr)\Bigr)\biggr)\Biggr) ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-413"> \Biggl(\biggl(\Bigl(\bigl((x)\bigr)\Bigr)\biggr)\Biggr) </script></p>




<h4 id="省略号">省略号</h4>




<p>省略号用 \dots, \cdots, \vdots, \ddots 等命令表示。\dots 和 \cdots 的纵向位置不同，前者一般用于有下标的序列。 <br>
[ x_1,x_2,\dots ,x_n\quad 1,2,\cdots ,n\quad <br>
\vdots\quad \ddots ]</p>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-418">  
[ x_1,x_2,\dots ,x_n\quad 1,2,\cdots ,n\quad  
\vdots\quad \ddots ]</script></p>




<h4 id="矩阵">矩阵</h4>




<p>pmatrix, bmatrix, Bmatrix, vmatrix, Vmatrix 等环境可以在矩阵两边加上各种分隔符。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\[</span> <span class="hljs-command">\begin</span><span class="hljs-special">{</span>pmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>pmatrix<span class="hljs-special">}</span> <span class="hljs-command">\quad</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>bmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>bmatrix<span class="hljs-special">}</span> <span class="hljs-command">\quad</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>Bmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>Bmatrix<span class="hljs-special">}</span> <span class="hljs-command">\quad</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>vmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>vmatrix<span class="hljs-special">}</span> <span class="hljs-command">\quad</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>Vmatrix<span class="hljs-special">}</span> a<span class="hljs-special">&amp;</span>b<span class="hljs-command">\\</span>c<span class="hljs-special">&amp;</span>d <span class="hljs-command">\end</span><span class="hljs-special">{</span>Vmatrix<span class="hljs-special">}</span> <span class="hljs-command">\]</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex; mode=display" id="MathJax-Element-649">\begin{pmatrix} a&b\\c&d \end{pmatrix}</script>  <br>
<script type="math/tex; mode=display" id="MathJax-Element-650">\begin{bmatrix} a&b\\c&d \end{bmatrix}</script>  <br>
<script type="math/tex; mode=display" id="MathJax-Element-651">\begin{Bmatrix} a&b\\c&d \end{Bmatrix}</script>  <br>
<script type="math/tex; mode=display" id="MathJax-Element-652">\begin{vmatrix} a&b\\c&d \end{vmatrix}</script>  <br>
<script type="math/tex; mode=display" id="MathJax-Element-653">\begin{Vmatrix} a&b\\c&d \end{Vmatrix}</script></p>




<p>而使用 smallmatrix 环境，可以生成行内公式的小矩阵。</p>




<p><code>( \begin{smallmatrix} a&amp;b\\c&amp;d \end{smallmatrix} )</code> </p>




<p><strong>示例如下：</strong> <br>
this is a little matrix <script type="math/tex" id="MathJax-Element-654"> ( \begin{smallmatrix} a&b\\c&d \end{smallmatrix} ) </script>.</p>




<h4 id="公式组">公式组</h4>




<p>无需对齐的公式组可以使用 gather 环境，需要对齐的公式组可以使用 align 环境。他们都带有编号，如果不需要编号可以使用带星花的版本。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\begin</span><span class="hljs-special">{</span>gather<span class="hljs-special">}</span>
a = b+c+d <span class="hljs-command">\\</span>
x = y+z
<span class="hljs-command">\end</span><span class="hljs-special">{</span>gather<span class="hljs-special">}</span>
<span class="hljs-command">\begin</span><span class="hljs-special">{</span>align<span class="hljs-special">}</span>
a <span class="hljs-special">&amp;</span>= b+c+d <span class="hljs-command">\\</span>
x <span class="hljs-special">&amp;</span>= y+z
<span class="hljs-command">\end</span><span class="hljs-special">{</span>align<span class="hljs-special">}</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex; mode=display" id="MathJax-Element-673">\begin{gather}
a = b+c+d \\
x = y+z
\end{gather}</script> <br>
<script type="math/tex; mode=display" id="MathJax-Element-674">\begin{align}
a &= b+c+d \\
x &= y+z
\end{align}</script></p>




<h4 id="分段函数">分段函数</h4>




<p>分段函数可以用cases次环境来实现，它必须包含在数学环境之内。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\begin</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span> y=<span class="hljs-command">\begin</span><span class="hljs-special">{</span>cases<span class="hljs-special">}</span>
-x,<span class="hljs-command">\quad</span> x<span class="hljs-command">\leq</span> 0 <span class="hljs-command">\\</span>
x,<span class="hljs-command">\quad</span> x&gt;0
<span class="hljs-command">\end</span><span class="hljs-special">{</span>cases<span class="hljs-special">}</span>
<span class="hljs-command">\end</span><span class="hljs-special">{</span>equation<span class="hljs-special">}</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex; mode=display" id="MathJax-Element-730">\begin{equation} y=\begin{cases}
-x,\quad x\leq 0 \\
x,\quad x>0
\end{cases}
\end{equation}</script></p>




<h3 id="插入图表">插入图表</h3>




<p>在LaTeX文档中插入图片都是通过使用一些latex图形处理宏命令来实现的, 有很多宏命令都支持在在LaTeX文档中插入eps格式的图形文件, 主要有: <br>
（1）用includegraphics宏命令(graphicx包)  <br>
（2）用psfig宏命令 <br>
（3）用epsfig宏命令  <br>
（4）用epsf宏命令 <br>
由于插入图片较为麻烦，且不如Markdown语法方便，这里就略过了。有兴趣的朋友可以自行查询下命令的使用方法。</p>




<h4 id="表格">表格</h4>




<p>tabular 环境提供了最简单的表格功能。它用 \hline 命令表示横线，在列格式中用 | 表示竖线；用 &amp; 来分列，用 \\ 来换行；每列可以采用居左、居中、居右等横向对齐方式，分别用 l、c、r 来表示。</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\begin</span><span class="hljs-special">{</span>tabular<span class="hljs-special">}</span><span class="hljs-special">{</span>|l|c|r|<span class="hljs-special">}</span>
 <span class="hljs-command">\hline</span>
OS<span class="hljs-special">&amp;</span> Release<span class="hljs-special">&amp;</span> Editor<span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
Windows <span class="hljs-special">&amp;</span> MikTeX <span class="hljs-special">&amp;</span> TexMakerX <span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
Unix/Linux <span class="hljs-special">&amp;</span> teTeX <span class="hljs-special">&amp;</span> Kile <span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
Mac OS <span class="hljs-special">&amp;</span> MacTeX <span class="hljs-special">&amp;</span> TeXShop <span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
通用<span class="hljs-special">&amp;</span> TeX Live <span class="hljs-special">&amp;</span> TeXworks <span class="hljs-command">\\</span>
 <span class="hljs-command">\hline</span>
<span class="hljs-command">\end</span><span class="hljs-special">{</span>tabular<span class="hljs-special">}</span></code></pre>




<p><strong>示例如下：</strong></p>




<table>
<thead>
<tr>
  <th align="center">OS</th>
  <th>Release</th>
  <th>Editor</th>
</tr>
</thead>
<tbody><tr>
  <td align="center">Windows</td>
  <td>MikTeX</td>
  <td>TexMakerX</td>
</tr>
<tr>
  <td align="center">Unix/Linux</td>
  <td>teTeX</td>
  <td>Kile</td>
</tr>
<tr>
  <td align="center">Mac OS</td>
  <td>MacTeX</td>
  <td>TeXShop</td>
</tr>
<tr>
  <td align="center">通用</td>
  <td>TeX LIve</td>
  <td>TeXworks</td>
</tr>
</tbody></table>




<h3 id="其他">其他</h3>




<p>到目前为止，常用的(La)Tex常用的功能已经介绍的基本差不多了。 <br>
当然，除此之外，(La)Tex还有一些版面设置，以及常用字母符号输入等功能。 <br>
例如我们常用的希腊字母</p>




<pre class="prettyprint"><code class="language-tex hljs "><span class="hljs-command">\alpha</span> <span class="hljs-command">\beta</span> <span class="hljs-command">\gamma</span> <span class="hljs-command">\theta</span><span class="hljs-command">\omega</span> <span class="hljs-command">\mu</span> <span class="hljs-command">\pi</span> <span class="hljs-command">\dots</span></code></pre>




<p><strong>示例如下：</strong> <br>
<script type="math/tex" id="MathJax-Element-844">\alpha \beta \gamma \theta\omega \mu \pi \dots</script></p>




<p>到此文章基本结束了，但依旧还有十分多的功能（不常用）没有在此文提及。有兴趣的朋友可以自行查询<a href="http://texdoc.net/texmf-dist/doc/latex/latex2e-help-texinfo/latex2e.pdf">LaTex相关手册</a>。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何在Python中实现决策树算法]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/09/09/ru-he-zai-pythonzhong-shi-xian-jue-ce-shu-suan-fa/"/>
    <updated>2017-09-09T15:33:50+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/09/09/ru-he-zai-pythonzhong-shi-xian-jue-ce-shu-suan-fa</id>
    <content type="html"><![CDATA[<h1 id="如何在python中实现决策树算法">如何在Python中实现决策树算法</h1>




<p>决策树算法是一种简单的预测算法，但正是因为它模型的简单性，常作为一些高级的组合算法的基础，例如<strong>bagging，random forests ，gradient boosting</strong> 等等。再者，由于决策树的最终模型和预估行为具有较强的业务相关与可解析性，使得它十分受从业者与领域专家的欢迎，在各行各业中也有十分多的应用。</p>




<h4 id="决策树的优缺点">决策树的优缺点</h4>




<p>优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据</p>




<p>缺点：可能会产生过拟合问题</p>




<h2 id="决策树的构建">决策树的构建</h2>




<p>在构建决策树之前，我们首先要明确的第一个问题就是：在当前的数据集上哪个特征在划分数据分类时起决定性作用。而其中划分数据集的最大原则就是：<strong><em>将无序的数据变得更加有序。</em></strong></p>




<p>在选择如何去划分数据集的时候，我们可以采用各种不同的方法。但是每种方法都有各自的优缺点。组织杂乱无章的数据的一种方法就是使用信息论度量信息。</p>




<p>在划分数据集之前之后信息发生的变化称为<strong>信息增益</strong>，而获得信息增益最高的特征就是我们用于划分数据的最好选择。</p>




<p>在评测哪种数据划分方式是最好的数据划分之前，我们必须学习如何计算信息增益，而为了能够计算和理解信息增益，我们又必须先了解一个概念，即：集合信息的度量方式，其被称为<strong>香农熵</strong>或简称<strong>熵</strong>。这个名字来源于信息论之父<a href="https://baike.baidu.com/item/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E8%89%BE%E5%B0%94%E4%BC%8D%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C/10588593?fr=aladdin&amp;fromid=1146248&amp;fromtitle=%E9%A6%99%E5%86%9C">克劳德×香农</a></p>




<p>熵：被定义为信息的<strong>期望值</strong>，如果一个事件发生的概率是<script type="math/tex" id="MathJax-Element-1">p(x)</script>,则其信息熵为:</p>




<blockquote>
  <p><script type="math/tex" id="MathJax-Element-2">H(X)=-\sum _{i=i}^n p(x_i) \log  \left (p (x_i)\right)</script></p>
  
  <p>Eg:<img src="http://www.saedsayad.com/images/Entropy_3.png" alt="enter image description here" title=""></p>
</blockquote>




<p>其中n是分类的数目。</p>




<p>可以这样验证一下：如果这件事发生的概率是1，其信息熵<script type="math/tex" id="MathJax-Element-3">H</script>则等于0，因为你知道他一定会发生，丝毫不会觉得惊喜;但是如果这件事的概率趋向于无穷小，比如国足夺得世界杯冠军，那么他的信息熵就会趋向于无穷大。就像你心中听完上一条信息之后，心中可能就有数十万只草泥马奔过一样。</p>




<h4 id="使用python计算信息的熵">使用Python计算信息的熵</h4>




<p>下面我们将以《机器学习实战》一书中给出的例子为基础进一步探讨本文所讲内容。</p>




<blockquote>
  <p><strong>海洋生物数据表</strong></p>
  
  <table>
<thead>
<tr>
  <th>index</th>
  <th>不浮出水面是否可以生存</th>
  <th>是否有脚蹼</th>
  <th>是否属于鱼类</th>
</tr>
</thead>
<tbody><tr>
  <td>0</td>
  <td>是</td>
  <td>是</td>
  <td>是</td>
</tr>
<tr>
  <td>1</td>
  <td>是</td>
  <td>是</td>
  <td>是</td>
</tr>
<tr>
  <td>2</td>
  <td>是</td>
  <td>否</td>
  <td>否</td>
</tr>
<tr>
  <td>3</td>
  <td>否</td>
  <td>是</td>
  <td>否</td>
</tr>
<tr>
  <td>4</td>
  <td>否</td>
  <td>是</td>
  <td>否</td>
</tr>
</tbody></table>

</blockquote>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#coding:utf-8</span>
</span><span class='line'><span class="c"># 代码功能：计算香农熵，本代码来源于书籍《机器学习实战》</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">log</span> <span class="c">#我们要用到对数函数，所以我们需要引入math模块中定义好的log函数（对数函数）</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">calcShannonEnt</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span><span class="c">#传入数据集</span>
</span><span class='line'><span class="c"># 在这里dataSet是一个链表形式的的数据集</span>
</span><span class='line'>    <span class="n">countDataSet</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span> <span class="c"># 我们计算出这个数据集中的数据个数，在这里我们的值是5个数据集</span>
</span><span class='line'>    <span class="n">labelCounts</span><span class="o">=</span><span class="p">{}</span> <span class="c"># 构建字典，用键值对的关系我们表示出 我们数据集中的类别还有对应的关系</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">featVec</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">:</span> <span class="c">#通过for循环，我们每次取出一个数据集，如featVec=[1,1,&#39;yes&#39;]</span>
</span><span class='line'>        <span class="n">currentLabel</span><span class="o">=</span><span class="n">featVec</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c"># 取出最后一列 也就是类别的那一类，比如说‘yes’或者是‘no’</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">currentLabel</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">labelCounts</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>            <span class="n">labelCounts</span><span class="p">[</span><span class="n">currentLabel</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="n">labelCounts</span><span class="p">[</span><span class="n">currentLabel</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">shannonEnt</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c"># 计算香农熵， 根据公式</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">labelCounts</span><span class="p">:</span>
</span><span class='line'>        <span class="n">prob</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">labelCounts</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="o">/</span><span class="n">countDataSet</span>
</span><span class='line'>        <span class="n">shannonEnt</span> <span class="o">-=</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">shannonEnt</span>
</span><span class='line'><span class="k">def</span> <span class="nf">createDataSet</span><span class="p">():</span>
</span><span class='line'>    <span class="n">dataSet</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;yes&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;yes&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="s">&#39;no&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;no&#39;</span><span class="p">],</span>
</span><span class='line'>              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;no&#39;</span><span class="p">]]</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;no surfacing&#39;</span><span class="p">,</span><span class="s">&#39;flippers&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">dataSet</span><span class="p">,</span> <span class="n">labels</span>
</span><span class='line'>
</span><span class='line'><span class="n">myDat</span><span class="p">,</span><span class="n">labels</span> <span class="o">=</span> <span class="n">createDataSet</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span class='line'><span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果: <br>
  [[1, 1, ‘yes’], [1, 1, ‘yes’], [1, 0, ‘no’], [0, 1, ‘no’], [0, 1, ‘no’]] <br>
  [‘no surfacing’, ‘flippers’] <br>
  0.9709505944546686</p>
</blockquote>




<p>其中，香农熵越高，则代表混合的数据越多，这点我们可以通过在数据集中添加更多的分类来验证。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">myDat</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="s">&#39;maybe&#39;</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span><span class='line'><span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果: <br>
  [[1, 1, ‘maybe’], [1, 1, ‘yes’], [1, 0, ‘no’], [0, 1, ‘no’], [0, 1, ‘no’]] <br>
  1.3709505944546687</p>
</blockquote>




<h4 id="划分数据集">划分数据集</h4>




<p>分类算法除了需要测量信息熵之外，还需要划分数据集，度量划分数据集的熵，以便判断当前是否正确地划分了数据集。</p>




<p>那么，我们如何确定目前划分数据的方法是否就是最优的划分方法呢？答案就是：<strong>信息增益</strong>。我们仅需选择使得划分后数据集信息增益最大的特征作为分类的最佳特征即可。</p>




<p>首先假设我们选取了第一个特征<strong>“是否需要浮出水面生存”</strong>的第一种可能<strong>“是”</strong>来划分数据集，我们得到划分之后的数据集就是：</p>




<blockquote>
  <p>[[1, 1, ‘maybe’], [1, 1, ‘yes’], [1, 0, ‘no’]</p>
</blockquote>




<p><strong>“否”</strong>的话，得到的划分集则是：</p>




<blockquote>
  <p>[[0, 1, ‘no’], [0, 1, ‘no’]]</p>
</blockquote>




<p>其他特征的划分方式也以此类推。</p>




<p>知道如何划分数据集之后，让我们来构建我们下一步的数据划分代码。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># 代码功能：划分数据集</span>
</span><span class='line'><span class="k">def</span> <span class="nf">splitDataSet</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">axis</span><span class="p">,</span><span class="n">value</span><span class="p">):</span> <span class="c">#传入三个参数第一个参数是我们的数据集，是一个链表形式的数据集；第二个参数是我们的要依据某个特征来划分数据集</span>
</span><span class='line'>    <span class="n">retDataSet</span> <span class="o">=</span> <span class="p">[]</span> <span class="c">#由于参数的链表dataSet我们拿到的是它的地址，也就是引用，直接在链表上操作会改变它的数值，所以我们新建一格链表来做操作</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">featVec</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">:</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">featVec</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="p">:</span> <span class="c">#如果某个特征和我们指定的特征值相等</span>
</span><span class='line'>        <span class="c">#除去这个特征然后创建一个子特征</span>
</span><span class='line'>            <span class="n">reduceFeatVec</span> <span class="o">=</span> <span class="n">featVec</span><span class="p">[:</span><span class="n">axis</span><span class="p">]</span>
</span><span class='line'>            <span class="n">reduceFeatVec</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">featVec</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
</span><span class='line'>            <span class="c">#将满足条件的样本并且经过切割后的样本都加入到我们新建立的样本中</span>
</span><span class='line'>            <span class="n">retDataSet</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduceFeatVec</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">retDataSet</span>
</span></code></pre></td></tr></table></div></figure>




<p>下面来测试下我们的代码</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">splitDataSet</span><span class="p">(</span><span class="n">myDat</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>[Out] [[1, ‘maybe’], [1, ‘yes’], [0, ‘no’]]</p>
</blockquote>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">splitDataSet</span><span class="p">(</span><span class="n">myDat</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>[Out]  [[1, ‘no’], [1, ‘no’]]</p>
</blockquote>




<p>知道怎么划分数据集之后，我们接下来要做的就是遍历整个数据集的特征值，然后循环计算熵，找出最好的分类特征了。</p>




<h4 id="选择最好的数据划分方式">选择最好的数据划分方式</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">chooseBestFeatureToSplit</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span>
</span><span class='line'>    <span class="n">numFeatures</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span>
</span><span class='line'>    <span class="n">baseEntropy</span> <span class="o">=</span> <span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
</span><span class='line'>    <span class="n">bestInfoGain</span> <span class="o">=</span><span class="mf">0.0</span>
</span><span class='line'>    <span class="n">bestFeature</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numFeatures</span><span class="p">):</span>
</span><span class='line'>        <span class="n">featList</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">]</span>
</span><span class='line'>        <span class="n">uniqueVals</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">featList</span><span class="p">)</span>
</span><span class='line'>        <span class="n">newEntropy</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">uniqueVals</span><span class="p">:</span>
</span><span class='line'>            <span class="n">subDataSet</span> <span class="o">=</span> <span class="n">splitDataSet</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">value</span><span class="p">)</span>
</span><span class='line'>            <span class="n">prob</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">subDataSet</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">))</span>
</span><span class='line'>            <span class="n">newEntropy</span> <span class="o">+=</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">calcShannonEnt</span><span class="p">(</span><span class="n">subDataSet</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">infoGain</span> <span class="o">=</span> <span class="n">baseEntropy</span> <span class="o">-</span> <span class="n">newEntropy</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">if</span><span class="p">(</span><span class="n">infoGain</span> <span class="o">&gt;</span> <span class="n">bestInfoGain</span><span class="p">):</span>
</span><span class='line'>            <span class="n">bestInfoGain</span> <span class="o">=</span> <span class="n">infoGain</span>
</span><span class='line'>            <span class="n">bestFeature</span> <span class="o">=</span> <span class="n">i</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">bestFeature</span>
</span></code></pre></td></tr></table></div></figure>




<p>这里的choseBestFeatureToSplit()函数的使用是需要满足一定条件的： <br>
1.  数据必须是一种有列表元素组成的列表，而且所有的列表元素都要具有相同的数据长度。 <br>
2. 数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签 </p>




<p>接下来，我们来运行choseBestFeatureToSplit()函数来计算出最佳分类特征。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">chooseBestFeatureToSplit</span><span class="p">(</span><span class="n">myDat</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>[Out] 0</p>
</blockquote>




<p>从这里我们可以得到第0个特征是最好用于划分数据集的特征。确实，这个分类特征的选择就我们目测而言也是最好的选择。</p>




<p>知道如何选取特征之后，下一步我们就要如何将上面的函数有机结合在一起构建出决策树。</p>




<h4 id="处理特殊情况">处理特殊情况</h4>




<p>工作原理： <br>
1.  得到原始数据集 <br>
2. 基于最好的属性值划分数据集 <br>
3.  由于特征值不止一个，将划分后的数据传递到树分支的下一个节点，再重复2操作 <br>
4. 程序遍历完所有划分数据集属性或每个分支下所有实例都具有相同分类后结束</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">majorityCnt</span><span class="p">(</span><span class="n">classList</span><span class="p">):</span> <span class="c"># 传入的参数是已经划分完所有特征之后剩余的数据集，</span>
</span><span class='line'>    <span class="c">#例如[[&#39;yes&#39;],[&#39;yes&#39;],[&#39;maybe&#39;]]</span>
</span><span class='line'>    <span class="n">classCount</span><span class="o">=</span><span class="p">{}</span> <span class="c">#创建一个字典</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">vote</span> <span class="ow">in</span> <span class="n">classList</span><span class="p">:</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">vote</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">classCount</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>            <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="n">classCount</span><span class="p">[</span><span class="n">vote</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>        <span class="c"># 根据上述的语句，以及我们的例子，我们最终可以得到的结果如下： {&#39;yes&#39;:2,&#39;maybe&#39;:1}</span>
</span><span class='line'>        <span class="n">sortedClassCount</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">classCount</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="n">operator</span><span class="o">.</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="c">#这个语句比较复杂，我们在下面详细讲解一下。</span>
</span><span class='line'><span class="c"># 使用字典iteritems</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">sortedClassCount</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>




<p>这里的majorityCnt()函数是为了处理<strong>特殊分类</strong>而存在的。我们知道如果根据特征来划分属性，每划分一次就会消耗一个特征，如果我们使用完了所有的特征但是类别还没有划分完那我们就可以采用多数表决的方法来确定叶子节点了。</p>




<p>在上面的代码中，我们发现最后我们用排序函数对剩余的类作了降序处理，并只返回了分类个数最多的元素的那个类。这是一种折中的方法，因为对于一些已经使用完特征的数据集，我们不可能清楚地将一些类分离出来，我们就只能统计其中数量最多的那个分类，以次划分。</p>




<h4 id="递归构建决策树">递归构建决策树</h4>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">createTree</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">labels</span><span class="p">):</span>
</span><span class='line'>    <span class="n">classList</span> <span class="o">=</span> <span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="n">classList</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="nb">len</span> <span class="p">(</span><span class="n">classList</span><span class="p">):</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">classList</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">majorityCnt</span><span class="p">(</span><span class="n">classList</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">bestFeat</span> <span class="o">=</span> <span class="n">chooseBestFeatureToSplit</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
</span><span class='line'>    <span class="n">bestFeatLabel</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">bestFeat</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">myTree</span> <span class="o">=</span> <span class="p">{</span><span class="n">bestFeatLabel</span><span class="p">:{}}</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">del</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">bestFeatL</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">featValues</span> <span class="o">=</span> <span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="n">bestFeat</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">uniqueVals</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">featValues</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">uniqueVals</span><span class="p">:</span>
</span><span class='line'>        <span class="n">subLabels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:]</span>
</span><span class='line'>        <span class="n">myTree</span><span class="p">[</span><span class="n">bestFeatLabel</span><span class="p">][</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">createTree</span><span class="p">(</span><span class="n">splitDataSet</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span><span class="n">bestFeat</span><span class="p">,</span><span class="n">value</span><span class="p">),</span><span class="n">subLabels</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">myTree</span>
</span></code></pre></td></tr></table></div></figure>




<p>最后，我们来运行我们的代码来构建出一棵决策树看看。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">createTree</span><span class="p">(</span><span class="n">myDat</span><span class="p">,</span><span class="n">labels</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<blockquote>
  <p>输出结果 <br>
  [‘no surfacing’, ‘flippers’] <br>
  0 <br>
  no surfacing <br>
  [‘flippers’] <br>
  0 <br>
  flippers <br>
  {‘no surfacing’: {0: ‘no’, 1: {‘flippers’: {0: ‘no’, 1: ‘yes’}}}}</p>
</blockquote>




<p>根据返回的结果，我们可以画出以下的决策树。 <br>
<img src="https://i.loli.net/2017/09/09/59b397d98b6e3.png" alt="dt.png" title=""></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Laplace变换]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/09/05/laplacebian-huan/"/>
    <updated>2017-09-05T21:20:57+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/09/05/laplacebian-huan</id>
    <content type="html"><![CDATA[<h1 id="拉普拉斯变换">拉普拉斯变换</h1>




<p>对于复值函数<script type="math/tex" id="MathJax-Element-1978">f(t)</script>,若<script type="math/tex" id="MathJax-Element-1979">\int_0^{\infty } f(t) \epsilon ^{-s t} \, dt</script>在复平面上的某一个区域<script type="math/tex" id="MathJax-Element-1980">D(s\in D)</script> 内收敛于<script type="math/tex" id="MathJax-Element-1981">F(s)</script>,则称：</p>




<p><script type="math/tex" id="MathJax-Element-1982">F(s)=\int_0^{\infty } f(t) \epsilon ^{-s t} \, dt</script></p>




<p>为函数的拉普拉斯变换（Laplace）变换（简称拉氏变换），记为</p>




<p><script type="math/tex" id="MathJax-Element-1983">F(s)=L[f(t)]</script></p>




<p>在科技领域，一般是对时间为自变量的函数进行拉普拉斯变换，即在t &lt; 0时，函数无意义或不需要考虑。</p>




<h3 id="线性性质">线性性质</h3>




<p>设<script type="math/tex" id="MathJax-Element-893">\alpha _1,\alpha _2</script>为常数， <br>
<script type="math/tex" id="MathJax-Element-894">F_1(s) = L[f_1(t)] , F_2(s) = L[f_2(t)] </script> 则  <br>
<script type="math/tex" id="MathJax-Element-895"> L[\alpha _1f_1(t) + \alpha _2f_2(t)] = \alpha_1F_1(s) + \alpha_2F_2(s)</script></p>




<h3 id="时移性质">时移性质</h3>




<p>若 <script type="math/tex" id="MathJax-Element-905">L[f(t)] = F(s)</script>，对于<script type="math/tex" id="MathJax-Element-906">t_0 > 0</script>，有<script type="math/tex" id="MathJax-Element-907">L[f( t-t_0 )] = e^{-st_0} F(s)</script></p>




<h3 id="频移性质">频移性质</h3>




<p>若 <script type="math/tex" id="MathJax-Element-947">L[f(t)] = F(s)</script>，则对任意常数a，有 <br>
<script type="math/tex" id="MathJax-Element-948">L[e^{at}f(t)] = F(s-a)</script></p>




<h3 id="微分性质">微分性质</h3>




<p>若 <script type="math/tex" id="MathJax-Element-1369">L[f(t)] = F(s)</script>，且<script type="math/tex" id="MathJax-Element-1370">f'(t)也是象原函数，则</script> <br>
<script type="math/tex" id="MathJax-Element-1371">L[f'(t)] = sF(s) - f(0^+)</script> <br>
这里，<script type="math/tex" id="MathJax-Element-1372"> \lim_{t\to 0^+}f( t)</script></p>




<p>若 <script type="math/tex" id="MathJax-Element-1373">L[f(t)] = F(s)</script>，则 <br>
<script type="math/tex" id="MathJax-Element-1374">L[ (-t)^n f(t)] = F^{(n)}(s) , n=0,1,2,...</script></p>




<h3 id="积分性质">积分性质</h3>




<p>若 <script type="math/tex" id="MathJax-Element-1631">L[f(t)] = F(s)</script>，则 <br>
<script type="math/tex" id="MathJax-Element-1632">L[\int_0^t f(\tau ) \, d\tau] = \frac{1}{s}F(s)</script></p>




<p>若 <script type="math/tex" id="MathJax-Element-1633">L[f(t)] = F(s)</script>，积分<script type="math/tex" id="MathJax-Element-1634">\int_s^\infty F(u ) \, du</script>收敛，则<script type="math/tex" id="MathJax-Element-1635">\frac{f(t)}{t}</script>的拉普拉斯变换存在，且</p>




<p><script type="math/tex" id="MathJax-Element-1636">L[\frac{f(t)}{t}] = \int_s^\infty F(u ) \, du</script></p>




<h3 id="极限性质">极限性质</h3>




<p>1.初值关系 <br>
若<script type="math/tex" id="MathJax-Element-1973">L[f(t)] = F(s)</script>，则<script type="math/tex" id="MathJax-Element-1974">f(0^+) =  \lim_{s\to \infty} sF( s)</script></p>




<p>2.终值关系 <br>
若<script type="math/tex" id="MathJax-Element-1975">L[f(t)] = F(s),且f(+\infty)存在,sF(s)</script>的所有奇点在半平面<script type="math/tex" id="MathJax-Element-1976">Re(s) < \sigma _0内，其中\sigma是f(t)的增长指数</script>，则</p>




<p><script type="math/tex" id="MathJax-Element-1977">f(+\infty) = lim_{s\to0}sF(s)</script></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何构建一个朴素贝叶斯分类器]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/09/03/ru-he-gou-jian-%5B%3F%5D-ge-po-su-bei-xie-si-fen-lei-qi/"/>
    <updated>2017-09-03T13:22:23+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/09/03/ru-he-gou-jian-[?]-ge-po-su-bei-xie-si-fen-lei-qi</id>
    <content type="html"><![CDATA[<h1 id="如何构建一个朴素贝叶斯分类器">如何构建一个朴素贝叶斯分类器</h1>




<h3 id="概念">概念</h3>




<p><strong>朴素贝叶斯分类</strong>是一些使用概率论来进行分类的方法中的一种代表。之所以成为为<strong>朴素</strong>，是因为整个形式化过程只做了最原始，最简单的假设。其具体表现为：在分类过程中，我们都假设为特征条件都是<strong>相互独立</strong>的，不互相构成影响。而贝叶斯即说明该方法是基于贝叶斯定理的。</p>




<p>朴素贝叶斯是贝叶斯决策理论的一部分，对比其他分类方法而言，其<strong>优点</strong>有：在数据较少的情况下仍然有效，并且可以处理多类别的问题，而不仅仅是二分类。<strong>但</strong>也存在对输入数据的准备方式较为敏感的缺点。</p>




<h3 id="目前在各方面的应用">目前在各方面的应用</h3>




<ol>
<li>垃圾邮件分类，即著名的贝叶斯过滤器</li>
<li>文本自动归类</li>
<li>文本情感的分析，话题分析。</li>
</ol>




<h3 id="核心思想">核心思想</h3>




<p><img src="https://i.loli.net/2017/09/02/59aa6f0d7afce.png" alt="beyas.png" title=""></p>




<p>现在假设我们有一张如上所示的两类数据的统计参数。 <br>
我们现在用p1(x,y)来表示数据点(x,y)属于类别X（图中的蓝点）的概率，用p2(x,y)表示数据点属于类别Y（图中的黄点）的概率。那么对于一个新的数据点(x,y)，我们可以用以下的规则来判断它的类别：</p>




<ul>
<li><script type="math/tex" id="MathJax-Element-24">If p1(x,y) > p2(x,y) then (x,y) -> X</script></li>
<li><script type="math/tex" id="MathJax-Element-25">If p2(x,y) > p1(x,y) then (x,y) -> Y</script></li>
</ul>




<p>也就是说，我们更倾向于选择高概率所对应的类别。这就是<strong>贝叶斯决策理论</strong>的核心思想。用一句话总结即：选择具有最高概率的决策。</p>




<h3 id="使用条件概率进行分类">使用条件概率进行分类</h3>




<p>从上面的推理我们得到两个分类准则：</p>




<ul>
<li><script type="math/tex" id="MathJax-Element-61">If p1(x,y) > p2(x,y) then (x,y) -> X</script></li>
<li><script type="math/tex" id="MathJax-Element-62">If p2(x,y) > p1(x,y) then (x,y) -> Y</script></li>
</ul>




<p>但是，这两个准则只是为了简化描述整个分类问题，而真正来说，在使用贝叶斯方法进行分类时，我们需要计算和比较的应该是 p(X|x,y) 和 p(Y|x,y) ，它们所代表的意义是：在给定某个由（x，y）表示的数据点之后，它来自X类别的概率和它来自Y类别的概率分别是多少？知道这点之后，我们来重新定义我们的分类准则：</p>




<ul>
<li><script type="math/tex" id="MathJax-Element-63">If P(X|x,y) > P(Y|x,y) then (x,y) -> X</script></li>
<li><script type="math/tex" id="MathJax-Element-64">If P(X|x,y) < P(Y|x,y) then (x,y) -> Y</script></li>
</ul>




<p>然后，我们可以再通过贝叶斯公式的转换把未知的概率用已知的概率计算出来。</p>




<p><strong>使用实例：垃圾邮件判别</strong> <br>
首先，我们假设有以下的统计数据：</p>




<ul>
<li>在74封电子邮件中，有30封为垃圾邮件。</li>
<li>在以上的74封电子邮件中，有51封邮件包含“sex”一词。</li>
<li>其中，20封包含了“sex”一词的邮件被认为是垃圾邮件。</li>
</ul>




<p>知道了以上这些简单的前提条件之后，我们可以尝试通过贝叶斯方法来求解我们下一封收到包含“sex”一词的邮件是垃圾邮件的概率是多少？</p>




<p><script type="math/tex" id="MathJax-Element-65">P (\text{spam}|\text{sex})=\frac{P(spam) * P  (\text{sex}|\text{spam})}{P (\text{sex})}=\frac {(20\div30)* (30\div74)} {51\div74} =\frac{20}{51}=0.39</script></p>




<p>其中，公式中的<strong>spam</strong>代表垃圾邮件的意思（1937年7月5日，美国罐头肉制造商Jay Hormel发布以其名字命名的「Hormel Spiced Ham（荷美尔香料火腿）」，后来通过命名比赛改名为 SPAM(Spiced Pork and Ham)，有添加香料（Spices）的猪肉火腿罐头。至于为何 SPAM演变成垃圾邮件呢？有一说法是源于一部英国喜剧团（Monty Python）曾在一出讽刺剧「spam-loving vikings（爱吃肉罐头的维京人），剧中有对夫妻去餐厅用餐，妻子不想吃SPAM罐头，可是在餐厅里有一大群人，高声地唱讼赞美「SPAM」称颂肉罐头的美味多达120次，让其他的用餐客人无可奈何。从此 SPAM就成为「重复、毫无益处、喧宾夺主、令人厌烦邮件」的代名词。就像当年经济萧条，人们买不起鲜肉，而吃的SPAM 肉罐头一样,没有营养成分。）</p>




<p>上面我们得出了一个词对整篇文章的分类判断情况，接下来我们可以进一步扩展这个问题，通过再增加以下为已知前提：</p>




<ul>
<li>25封邮件包含“money”一词，而其中24封被认为是垃圾邮件。</li>
</ul>




<p>那么现在当收到一封同时包含“sex”，“money”这两个词的邮件，它为垃圾邮件的可能性又有多大呢？</p>




<p><script type="math/tex" id="MathJax-Element-66">\frac{P(\text{spam}) P(\text{money}|\text{spam}) P(\text{sex}|\text{spam}\cap  
   \text{money})}{P(\text{money}) P(\text{sex}|\text{monry})}</script></p>




<p>写到这里我们发现，当我们不断增加相关词进行判定时，上述的贝叶斯推理公式也将越来越复杂。这时，就要开始应用朴素思想了，我们假设“sex”和“money”两者出现的事件都相互独立（虽然现实情况往往并不是这样的，当出现一些广告相关的词词语时，“金钱”一词往往就有很大的几率出现在后文，但这里采用朴素的思想来近似在分类上也足够准确了），这样我们就可以把上面的公式简化成：</p>




<p><script type="math/tex" id="MathJax-Element-67">P(\text{spam}|\text{money},\text{sex})=\frac{P(\text{spam})  
   P(\text{money}|\text{spam}) P(\text{sex}|\text{spam})}{p(\text{money})  
   P(\text{sex})}</script></p>




<p>这样，假如我们需要对一封收到的电子邮件进行分类的话，我们只要计算出在给出邮件内的词汇的情况下，它为一封垃圾邮件的条件概率即可。当然，这里存在的一个较大的缺陷就是，当一些词语极度相关时，而我们通过假设他们相互独立计算出来的概率可能并不是那么准确。</p>




<h3 id="分类实现">分类实现</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># -*- encoding : utf-8 -*-</span>
</span><span class='line'><span class="k">class</span> <span class="nc">BeyesClassifier</span><span class="o">::</span><span class="no">Base</span>
</span><span class='line'>  <span class="kp">extend</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">Storage</span><span class="o">::</span><span class="no">ActAsStorable</span>
</span><span class='line'>  <span class="kp">attr_reader</span> <span class="ss">:name</span>
</span><span class='line'>  <span class="kp">attr_reader</span> <span class="ss">:word_list</span>
</span><span class='line'>  <span class="kp">attr_reader</span> <span class="ss">:category_list</span>
</span><span class='line'>  <span class="kp">attr_reader</span> <span class="ss">:training_count</span>
</span><span class='line'>
</span><span class='line'>  <span class="kp">attr_accessor</span> <span class="ss">:tokenizer</span>
</span><span class='line'>  <span class="kp">attr_accessor</span> <span class="ss">:language</span>
</span><span class='line'>
</span><span class='line'>  <span class="kp">attr_accessor</span> <span class="ss">:thresholds</span>
</span><span class='line'>  <span class="kp">attr_accessor</span> <span class="ss">:min_prob</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>  <span class="n">storable</span> <span class="ss">:version</span><span class="p">,</span><span class="ss">:word_list</span><span class="p">,</span><span class="ss">:category_list</span><span class="p">,</span><span class="ss">:training_count</span><span class="p">,</span><span class="ss">:thresholds</span><span class="p">,</span><span class="ss">:min_prob</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># opts :</span>
</span><span class='line'>  <span class="c1"># language</span>
</span><span class='line'>  <span class="c1"># stemming : true | false</span>
</span><span class='line'>  <span class="c1"># weight</span>
</span><span class='line'>  <span class="c1"># assumed_prob</span>
</span><span class='line'>  <span class="c1"># storage</span>
</span><span class='line'>  <span class="c1"># purge_state ?</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="nb">name</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="p">{})</span>
</span><span class='line'>    <span class="vi">@version</span> <span class="o">=</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">VERSION</span>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@name</span> <span class="o">=</span> <span class="nb">name</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># This values are nil or are loaded from storage</span>
</span><span class='line'>    <span class="vi">@word_list</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@category_list</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@training_count</span><span class="o">=</span><span class="mi">0</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># storage</span>
</span><span class='line'>    <span class="n">purge_state</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:purge_state</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@storage</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:storage</span><span class="o">]</span> <span class="o">||</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">Base</span><span class="o">.</span><span class="n">storage</span>
</span><span class='line'>    <span class="k">unless</span> <span class="n">purge_state</span>
</span><span class='line'>      <span class="vi">@storage</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="nb">self</span><span class="p">)</span>
</span><span class='line'>    <span class="k">else</span>
</span><span class='line'>      <span class="vi">@storage</span><span class="o">.</span><span class="n">purge_state</span><span class="p">(</span><span class="nb">self</span><span class="p">)</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># This value can be set during initialization or overrided after load_state</span>
</span><span class='line'>    <span class="vi">@thresholds</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:thresholds</span><span class="o">]</span> <span class="o">||</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@min_prob</span> <span class="o">=</span> <span class="n">opts</span><span class="o">[</span><span class="ss">:min_prob</span><span class="o">]</span> <span class="o">||</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@ignore_words</span> <span class="o">=</span> <span class="kp">nil</span>
</span><span class='line'>    <span class="vi">@tokenizer</span> <span class="o">=</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">Tokenizer</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">incr_word</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">]</span> <span class="o">||=</span> <span class="p">{}</span>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">]</span> <span class="o">||=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">][</span><span class="n">category</span><span class="o">]</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">][</span><span class="n">category</span><span class="o">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># words count by categroy</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">]</span> <span class="o">||=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">incr_cat</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">]</span> <span class="o">||=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_count</span><span class="o">]</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_count</span><span class="o">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="vi">@training_count</span> <span class="o">||=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="vi">@training_count</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return number of times the word appears in a category</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">word_count</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span> <span class="k">unless</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">][</span><span class="n">category</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">][</span><span class="n">category</span><span class="o">].</span><span class="n">to_f</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of times the word appears in all categories</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">total_word_count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span> <span class="k">unless</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">].</span><span class="n">to_f</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of words in a categories</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">total_word_count_in_cat</span><span class="p">(</span><span class="n">cat</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span> <span class="k">unless</span> <span class="vi">@category_list</span><span class="o">[</span><span class="n">cat</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@category_list</span><span class="o">[</span><span class="n">cat</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">cat</span><span class="o">][</span><span class="ss">:_total_word</span><span class="o">].</span><span class="n">to_f</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of training item</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">total_cat_count</span>
</span><span class='line'>    <span class="vi">@training_count</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of training document for a category</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">cat_count</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_count</span><span class="o">]</span> <span class="p">?</span> <span class="vi">@category_list</span><span class="o">[</span><span class="n">category</span><span class="o">][</span><span class="ss">:_count</span><span class="o">].</span><span class="n">to_f</span> <span class="p">:</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of time categories in wich a word appear</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">categories_with_word_count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="mi">0</span> <span class="k">unless</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">]</span>
</span><span class='line'>    <span class="vi">@word_list</span><span class="o">[</span><span class="n">word</span><span class="o">][</span><span class="ss">:categories</span><span class="o">].</span><span class="n">length</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return the number of categories</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">total_categories</span>
</span><span class='line'>    <span class="n">categories</span><span class="o">.</span><span class="n">length</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># return categories list</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">categories</span>
</span><span class='line'>    <span class="vi">@category_list</span><span class="o">.</span><span class="n">keys</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># train the classifier</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</span><span class='line'>    <span class="vi">@tokenizer</span><span class="o">.</span><span class="n">each_word</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="p">{</span><span class="o">|</span><span class="n">w</span><span class="o">|</span> <span class="n">incr_word</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span> <span class="p">}</span>
</span><span class='line'>    <span class="n">incr_cat</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># classify a text</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kp">nil</span><span class="p">)</span>
</span><span class='line'>    <span class="c1"># Find the category with the highest probability</span>
</span><span class='line'>    <span class="n">max_prob</span> <span class="o">=</span> <span class="vi">@min_prob</span>
</span><span class='line'>    <span class="n">best</span> <span class="o">=</span> <span class="kp">nil</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">scores</span> <span class="o">=</span> <span class="n">cat_scores</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span><span class='line'>    <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
</span><span class='line'>      <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
</span><span class='line'>      <span class="k">if</span> <span class="n">prob</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
</span><span class='line'>        <span class="n">max_prob</span> <span class="o">=</span> <span class="n">prob</span>
</span><span class='line'>        <span class="n">best</span> <span class="o">=</span> <span class="n">cat</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># Return the default category in case the threshold condition was</span>
</span><span class='line'>    <span class="c1"># not met. For example, if the threshold for :spam is 1.2</span>
</span><span class='line'>    <span class="c1">#</span>
</span><span class='line'>    <span class="c1">#    :spam =&gt; 0.73, :ham =&gt; 0.40  (OK)</span>
</span><span class='line'>    <span class="c1">#    :spam =&gt; 0.80, :ham =&gt; 0.70  (Fail, :ham is too close)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">default</span> <span class="k">unless</span> <span class="n">best</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">threshold</span> <span class="o">=</span> <span class="vi">@thresholds</span><span class="o">[</span><span class="n">best</span><span class="o">]</span> <span class="o">||</span> <span class="mi">1</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
</span><span class='line'>      <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
</span><span class='line'>      <span class="k">next</span> <span class="k">if</span> <span class="n">cat</span> <span class="o">==</span> <span class="n">best</span>
</span><span class='line'>      <span class="k">return</span> <span class="n">default</span> <span class="k">if</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">threshold</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">best</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="nf">save_state</span>
</span><span class='line'>    <span class="vi">@storage</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="nb">self</span><span class="p">)</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">class</span> <span class="o">&lt;&lt;</span> <span class="nb">self</span>
</span><span class='line'>    <span class="kp">attr_writer</span> <span class="ss">:storage</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">storage</span>
</span><span class='line'>      <span class="vi">@storage</span> <span class="o">=</span> <span class="no">BeyesClassifier</span><span class="o">::</span><span class="no">InMemoryStorage</span><span class="o">.</span><span class="n">new</span> <span class="k">unless</span> <span class="n">defined?</span> <span class="vi">@storage</span>
</span><span class='line'>      <span class="vi">@storage</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">open</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
</span><span class='line'>      <span class="n">inst</span> <span class="o">=</span> <span class="nb">self</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
</span><span class='line'>      <span class="k">if</span> <span class="nb">block_given?</span>
</span><span class='line'>        <span class="k">yield</span> <span class="n">inst</span>
</span><span class='line'>        <span class="n">inst</span><span class="o">.</span><span class="n">save_state</span>
</span><span class='line'>      <span class="k">else</span>
</span><span class='line'>        <span class="n">inst</span>
</span><span class='line'>      <span class="k">end</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>完整代码实现可以参考<a href="https://github.com/alexandru/stuff-classifier"><strong>alexandru大神的github项目stuff-classifier</strong></a></p>




<h3 id="算法训练和使用">算法训练和使用</h3>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># 训练函数</span>
</span><span class='line'><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</span><span class='line'>  <span class="n">each_word</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="p">{</span><span class="o">|</span><span class="n">w</span><span class="o">|</span> <span class="n">increment_word</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span> <span class="p">}</span>
</span><span class='line'>  <span class="n">increment_cat</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
</span><span class='line'><span class="k">end</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># 使用</span>
</span><span class='line'><span class="n">classifier</span><span class="o">.</span><span class="n">train</span> <span class="ss">:spam</span><span class="p">,</span> <span class="s2">&quot;Grow your penis to 20 inches in just 1 week&quot;</span>
</span><span class='line'><span class="n">classifier</span><span class="o">.</span><span class="n">train</span> <span class="ss">:ham</span><span class="p">,</span>  <span class="s2">&quot;I&#39;m hungry, no I don&#39;t want your penis&quot;</span>
</span></code></pre></td></tr></table></div></figure>




<p>由于本文主要的目标是讲解贝叶斯算法，所以为了方便分词，主要使用英文语料训练，对于中文邮件分类而言，只要采用分词库分词即可，其他部分不变。</p>




<h3 id="提高准确度与算法优化">提高准确度与算法优化</h3>




<h4 id="计算优化">计算优化</h4>




<p>由于浮点数计算的一些先天性问题，如计算效率慢，精度不准确等。因此我们可以用自然对数来代替原本概率的形式。 <br>
<script type="math/tex" id="MathJax-Element-3265">claaify(word_1,word_2,…word_n)=\text{argmax}\sum _{i=1}^n \frac{\log  
   \left(P\left(\left.\text{word}_i\right|\text{spam}\right)\right)}{\log  
   (e)}+\frac{\log (P(\text{spam}))}{\log (e)}</script></p>




<h4 id="拉普拉斯平滑">拉普拉斯平滑</h4>




<p>由于贝叶斯公式依赖的都是用已知概率求未知概率，但是在分类中无法避免的一个情况就是当我们计算<script type="math/tex" id="MathJax-Element-4127">P(word_i|spam)</script>即：在已有的训练的垃圾邮件样本中出现<script type="math/tex" id="MathJax-Element-4128">word_i</script>的概率是多少时，我们遇到了一个从未在训练样本中出现过的词，那么此时就会导致<script type="math/tex" id="MathJax-Element-4129">P(word_i|spam)=0</script>。这样就会影响整体的判别。</p>




<p>这样由于训练样本不足导致分类器整体质量大大下降的问题很常见，为了解决这个问题，我们可以引入<strong>Laplace校准</strong>（即我们要讲的拉普拉斯平滑公式），它的原理非常简单，给未出现特征值，赋予一个“小”的值而不是0。</p>




<p>具体平滑方法如下： <br>
假设离散型随机变量z有{1,2,…,k}个值，我们用<script type="math/tex" id="MathJax-Element-4130">\phi _i=P(z=i)</script>来表示每个值的概率。假设有m个训练样本中，z的观察值是<script type="math/tex" id="MathJax-Element-4131">\left\{z^1,\text{...},z^m\right\}</script>其中每一个观察值对应k个值中的一个。那么根据原来的估计方法可以得到</p>




<p><script type="math/tex" id="MathJax-Element-4132">\phi _j=\frac{\sum _{i=1}^m 1 \left\{z^i=j\right\}}{m}</script></p>




<p>简单来说就是<script type="math/tex" id="MathJax-Element-4133">z=j</script>出现的比例。</p>




<p>拉普拉斯平滑法将每个k值出现次数事先都加1，即假设他们都出现过一次。 <br>
那么修改后的表达式为：</p>




<p><script type="math/tex" id="MathJax-Element-4134">\phi _j=\frac{\sum _{i=1}^m 1 \left\{z^i=j\right\}+1}{m+k}</script></p>




<p>每个z=j的分子都加1，分母加k。可见<script type="math/tex" id="MathJax-Element-4135">\sum _{j=1}^k \phi _j=1</script>。</p>




<p>这样在保持总体事件发现概率比例基本不变的同时，又避免了0概率的问题。</p>




<h4 id="去除停用词">去除停用词</h4>




<p><strong>停用词</strong>是指在信息检索中，为节省存储空间和提高搜索效率，在处理自然语言数据（或文本）之前或之后会自动过滤掉某些字或词，这些字或词即被称为<strong>Stop Words</strong>（停用词）。这些停用词都是人工输入、非自动化生成的，生成后的停用词会形成一个停用词表。但是，并没有一个明确的停用词表能够适用于所有的工具。</p>




<p>通常意义上，Stop Words大致为如下两类：</p>




<ol>
<li>第一类是那些应用十分广泛的词，在Internet上随处可见，比如“Web”一词几乎在每个网站上均会出现，对这样的词搜索引擎无 法保证能够给出真正相关的搜索结果，难以帮助缩小搜索范围，同时还会降低搜索的效率。</li>
<li>第二类就更多了，包括了语气助词、副词、介词、连接词等，通常自身并无明确的意义，只有将其放入一个完整的句子中才有一定作用，如常见的“的”、“在”之类。</li>
</ol>




<p>为了使得最后用于判别邮件类型的词向量能够更加贴近邮件本身真正想表达的含义，我们可以在读取扫描文本并生成词列表时，先<strong>剔除停用词</strong>，再进行下一步的概率计算。</p>




<p>常用中文停用词表： <br>
链接: <a href="https://pan.baidu.com/s/1o8hw5Cm">https://pan.baidu.com/s/1o8hw5Cm</a> 密码: crti</p>




<p>常用英文停用词表： <br>
链接: <a href="https://pan.baidu.com/s/1jIOOfgM">https://pan.baidu.com/s/1jIOOfgM</a> 密码: 7g95</p>




<h4 id="阈值选取">阈值选取</h4>




<p>假设我们计算出一封邮件的<script type="math/tex" id="MathJax-Element-4368">P(spam) = 0.6 </script>那么是否我们因为 <script type="math/tex" id="MathJax-Element-4369">P(spam) = 0.6 > P(not spam)=1-0.6=0.4</script> 就可以把它定义为垃圾邮件呢？显然这样做是不合理的，一个好的概率阈值应该是在训练及测试样本上使得发生误判情况最少时所取得的值。通常我们可以定义一个误差评判函数再通过不同阈值在样本上的评分来选取出最佳的阈值。简单实现就如下面的代码所示：</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kp">nil</span><span class="p">)</span>
</span><span class='line'>  <span class="c1"># Find the category with the highest probability</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">max_prob</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>  <span class="n">best</span> <span class="o">=</span> <span class="kp">nil</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">scores</span> <span class="o">=</span> <span class="n">cat_scores</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span><span class='line'>  <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
</span><span class='line'>    <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">prob</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
</span><span class='line'>      <span class="n">max_prob</span> <span class="o">=</span> <span class="n">prob</span>
</span><span class='line'>      <span class="n">best</span> <span class="o">=</span> <span class="n">cat</span>
</span><span class='line'>    <span class="k">end</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1"># Return the default category in case the threshold condition was</span>
</span><span class='line'>  <span class="c1"># not met. For example, if the threshold for :spam is 1.2</span>
</span><span class='line'>  <span class="c1">#</span>
</span><span class='line'>  <span class="c1">#    :spam =&gt; 0.73, :ham =&gt; 0.40  (OK)</span>
</span><span class='line'>  <span class="c1">#    :spam =&gt; 0.80, :ham =&gt; 0.70  (Fail, :ham is too close)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="n">default</span> <span class="k">unless</span> <span class="n">best</span>
</span><span class='line'>  <span class="n">threshold</span> <span class="o">=</span> <span class="vi">@thresholds</span><span class="o">[</span><span class="n">best</span><span class="o">]</span> <span class="o">||</span> <span class="mi">1</span><span class="o">.</span><span class="mi">0</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
</span><span class='line'>    <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
</span><span class='line'>    <span class="k">next</span> <span class="k">if</span> <span class="n">cat</span> <span class="o">==</span> <span class="n">best</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">default</span> <span class="k">if</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">threshold</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
</span><span class='line'>  <span class="k">end</span>
</span><span class='line'>  <span class="k">return</span> <span class="n">best</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>




<p>最后，写到这里，贝叶斯分类器构建的讲解基本就结束了。通观全篇，我们依旧有个问题并没有解决：朴素贝叶斯分类有一个限制条件，就是特征属性必须有条件独立或基本独立（实际上在现实应用中几乎不可能做到完全独立）。当这个条件成立时，朴素贝叶斯分类法的准确率是最高的，但不幸的是，现实中各个特征属性间往往并不条件独立，而是具有较强的相关性，这样就限制了朴素贝叶斯分类的能力。然而，这个问题也并不是无解的，贝叶斯分类中有一种更高级、应用范围更广的一种算法——<strong>贝叶斯网络（又称贝叶斯信念网络或信念网络）</strong>，信念网络在一定程度上使得模型更接近真实的实际情况，有兴趣的读者可以进一步深入了解。</p>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python实现Fisher判别分析]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/08/30/pythonshi-xian-fisherpan-bie-fen-xi/"/>
    <updated>2017-08-30T09:06:21+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/08/30/pythonshi-xian-fisherpan-bie-fen-xi</id>
    <content type="html"><![CDATA[<h1 id="python实现fisher-判别分析">Python实现Fisher 判别分析</h1>




<h2 id="fisher原理">Fisher原理</h2>




<p>费歇（Fisher）判别思想是投影，使多维问题化为一维问题来处理。选择一个适当的投影轴，使所有的样本点都投影在这个轴上得到一个投影值。对这个投影轴的方向的要求是：使每一类内的投影值所形成的类内距离差尽可能小，而不同类间的投影值所形成的类间距离差尽可能大。 <br>
<img src="https://i.loli.net/2017/09/01/59a90dda8790e.png" alt="" title=""></p>




<p><img src="https://i.loli.net/2017/09/01/59a9136f647d1.png" alt="enter image description here" title=""></p>




<p>这样如果我们想要同类样列的投影点尽可能接近，可以让同类样列投影点的协方差尽可能小，即<script type="math/tex" id="MathJax-Element-1">w^T \left(\sum _0 w\right)+w^T \left(\sum _1 w\right)</script>尽可能小;而欲使异类样列的投影点尽可能远离，可以让类中心之间的距离尽可能大，即<script type="math/tex" id="MathJax-Element-2">\left[\left[u_0 w^T-u_1 w^T\right]\right]</script>尽可能大。同时结合两者我们可以得到欲最大化的目标： <br>
<img src="https://i.loli.net/2017/09/01/59a9136f56af9.png" alt="enter image description here" title=""></p>




<p>(本文图片截取自<a href="https://book.douban.com/subject/26708119/">《机器学习》</a>周志华)</p>




<p><img src="https://i.loli.net/2017/09/01/59a9136f635c6.png" alt="enter image description here" title=""></p>




<p>有了上面的推理之后我们接下来就以DNA分类为例来实现一下Fisher线性判别。</p>




<h2 id="数据准备">数据准备</h2>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span><span class='line'><span class="n">dna_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;dna2&#39;</span><span class="p">,</span><span class="s">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span class='line'>    <span class="n">dna_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">strip</span><span class="p">,</span><span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()))</span>
</span><span class='line'>    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dna_list</span><span class="p">))</span>
</span><span class='line'><span class="k">def</span> <span class="nf">generate_feature</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">:</span>
</span><span class='line'>        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span class='line'>        <span class="k">yield</span> <span class="p">[</span>
</span><span class='line'>        <span class="n">chary</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s">&#39;a&#39;</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">,</span>
</span><span class='line'>        <span class="n">chary</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s">&#39;t&#39;</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">,</span>
</span><span class='line'>        <span class="n">chary</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s">&#39;c&#39;</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">,</span>
</span><span class='line'>        <span class="n">chary</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s">&#39;g&#39;</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">generate_feature</span><span class="p">(</span><span class="n">dna_list</span><span class="p">)),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span class='line'><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</span><span class='line'><span class="n">y</span><span class="p">[</span><span class="mi">10</span><span class="p">:]</span><span class="o">=</span><span class="mi">2</span>
</span><span class='line'><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="s">&#39;</span><span class="se">\n</span><span class="s">&#39;</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote>
  <p>输出结果： <br>
  40 <br>
  [[ 0.2972973   0.13513514  0.17117117  0.3963964 ] <br>
   [ 0.35454545  0.5         0.04545455  0.1       ] <br>
   [ 0.42342342  0.28828829  0.10810811  0.18018018] <br>
   [ 0.35135135  0.12612613  0.12612613  0.3963964 ] <br>
   [ 0.27927928  0.18918919  0.16216216  0.36936937] <br>
   [ 0.21818182  0.56363636  0.14545455  0.07272727] <br>
   [ 0.20720721  0.15315315  0.20720721  0.43243243] <br>
   [ 0.3         0.5         0.08181818  0.11818182] <br>
   [ 0.2         0.56363636  0.17272727  0.06363636] <br>
   [ 0.27027027  0.06306306  0.21621622  0.45045045] <br>
   [ 0.32727273  0.5         0.02727273  0.14545455] <br>
   [ 0.23423423  0.10810811  0.23423423  0.42342342] <br>
   [ 0.29090909  0.64545455  0.          0.06363636] <br>
   [ 0.18181818  0.13636364  0.27272727  0.40909091] <br>
   [ 0.29090909  0.5         0.11818182  0.09090909] <br>
   [ 0.25454545  0.51818182  0.1         0.12727273] <br>
   [ 0.27433628  0.36283186  0.19469027  0.16814159] <br>
   [ 0.27027027  0.15315315  0.16216216  0.41441441]]  <br>
   [ 1.  2.  1.  1.  1.  2.  1.  2.  2.  1.  2.  1.  2.  1.  2.  2.  2.  1.]</p>
</blockquote>




<h2 id="fisher算法实现">Fisher算法实现</h2>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">cal_cov_and_avg</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    给定一个类别的数据，计算协方差矩阵和平均向量</span>
</span><span class='line'><span class="sd">    :param samples: </span>
</span><span class='line'><span class="sd">    :return: </span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">u1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>    <span class="n">cov_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
</span><span class='line'>        <span class="n">t</span> <span class="o">=</span> <span class="n">s</span> <span class="o">-</span> <span class="n">u1</span>
</span><span class='line'>        <span class="n">cov_m</span> <span class="o">+=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">cov_m</span><span class="p">,</span> <span class="n">u1</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">fisher</span><span class="p">(</span><span class="n">c_1</span><span class="p">,</span> <span class="n">c_2</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    fisher算法实现(请参考上面推导出来的公式，那个才是精华部分)</span>
</span><span class='line'><span class="sd">    :param c_1: </span>
</span><span class='line'><span class="sd">    :param c_2: </span>
</span><span class='line'><span class="sd">    :return: </span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">cov_1</span><span class="p">,</span> <span class="n">u1</span> <span class="o">=</span> <span class="n">cal_cov_and_avg</span><span class="p">(</span><span class="n">c_1</span><span class="p">)</span>
</span><span class='line'>    <span class="n">cov_2</span><span class="p">,</span> <span class="n">u2</span> <span class="o">=</span> <span class="n">cal_cov_and_avg</span><span class="p">(</span><span class="n">c_2</span><span class="p">)</span>
</span><span class='line'>    <span class="n">s_w</span> <span class="o">=</span> <span class="n">cov_1</span> <span class="o">+</span> <span class="n">cov_2</span>
</span><span class='line'>    <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">s_w</span><span class="p">)</span>  <span class="c"># 奇异值分解</span>
</span><span class='line'>    <span class="n">s_w_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">))),</span> <span class="n">u</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">s_w_inv</span><span class="p">,</span> <span class="n">u1</span> <span class="o">-</span> <span class="n">u2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<h2 id="判别类型">判别类型</h2>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">judge</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c_1</span><span class="p">,</span> <span class="n">c_2</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    true 属于1</span>
</span><span class='line'><span class="sd">    false 属于2</span>
</span><span class='line'><span class="sd">    :param sample:</span>
</span><span class='line'><span class="sd">    :param w:</span>
</span><span class='line'><span class="sd">    :param center_1:</span>
</span><span class='line'><span class="sd">    :param center_2:</span>
</span><span class='line'><span class="sd">    :return:</span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">u1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">c_1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>    <span class="n">u2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">c_2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>    <span class="n">center_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">u1</span><span class="p">)</span>
</span><span class='line'>    <span class="n">center_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">u2</span><span class="p">)</span>
</span><span class='line'>    <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="nb">abs</span><span class="p">(</span><span class="n">pos</span> <span class="o">-</span> <span class="n">center_1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">abs</span><span class="p">(</span><span class="n">pos</span> <span class="o">-</span> <span class="n">center_2</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="n">w</span> <span class="o">=</span> <span class="n">fisher</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span>  <span class="c"># 调用函数，得到参数w</span>
</span><span class='line'><span class="n">pred</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
</span><span class='line'>    <span class="n">pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">judge</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>   <span class="c"># 判断所属的类别</span>
</span><span class='line'><span class="c"># evaluate accuracy</span>
</span><span class='line'><span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">pred</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
</span><span class='line'><span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">40</span><span class="p">):</span>
</span><span class='line'>    <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">judge</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>   <span class="c"># 判断所属的类别</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote>
  <p>输出结果： <br>
  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2. <br>
    2.  2.] [1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1] <br>
  0.95 <br>
  [1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1]</p>
</blockquote>




<p>在这我们可以看出我们的Fisher算法在测试集中的误差率还算理想，误判率仅有5%。但是，我们可以看出其预测分类并不如其他KNN，SVM，等算法的预测效果。</p>




<p>最后，有关Fisher算法的介绍也就到此结束了！</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K-近邻算法-Part2]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/08/23/k-jin-lin-suan-fa-part2/"/>
    <updated>2017-08-23T12:19:17+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/08/23/k-jin-lin-suan-fa-part2</id>
    <content type="html"><![CDATA[<h1>K-近邻算法-Part2</h1>

<h2>使用交叉验证来调整k值</h2>

<p>通常来说,一个最优的KNN模型其k参数所对应的预估错误率应该是最低的。因此，在选定模型k值的时候应该反复尝试不同的k值在预估上的效果，对比其错误率。初学者在这里为了降低模型的误差通常会将全部样本数据也作为训练集一起代入模型进行训练。虽然这种做法在训练时确实能够有效降低误差，对现有数据进行更好的拟合。但是，同时带来的后果是：我们会将数据的各种无法避免的真实误差，如测量误差，抽样误差等也训练进了我们的模型之中，使得训练出来的模型在新数据或未知数据上的预估效果特别差，这种现象也被称为<strong>过拟合（overfitting）</strong>。</p>

<p>为了降低预估的错误率以及避免过拟合现象的发生，我们可以在某种意义下将<strong>原始数据(dataset)</strong>进行分组,一部分做为<strong>训练集(train set)</strong>,另一部分做为<strong>验证集(validation set or test set)</strong>，首先用训练集对分类器进行训练,再利用验证集来测试训练得到的<strong>模型(model)</strong>,以此来做为评价分类器的性能指标。这种方法也就是所谓的<strong>交叉验证（Cross Validation）</strong>。</p>

<p>而在交叉验证中，<strong>K折交叉验证（k-fold cross validation）</strong>是比较常用的。其主要思想是：初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。</p>

<p><img src="https://kevinzakka.github.io/assets/k_fold_cv.jpg" alt="enter image description here" /></p>

<p>为了更好的理解k折交叉验证，我们继续沿用part1部分的训练数据，使用10折交叉验证的方法来调整我们的k值。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
</span><span class='line'><span class="c"># creating odd list of K for KNN</span>
</span><span class='line'><span class="n">myList</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">50</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="c"># subsetting just the odd ones</span>
</span><span class='line'><span class="n">neighbors</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">myList</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="c"># empty list that will hold cv scores</span>
</span><span class='line'><span class="n">cv_scores</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>
</span><span class='line'><span class="c"># perform 10-fold cross validation</span>
</span><span class='line'><span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">:</span>
</span><span class='line'>    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
</span><span class='line'>    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">&#39;accuracy&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">cv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</span><span class='line'>
</span><span class='line'><span class="c"># changing to misclassification error</span>
</span><span class='line'><span class="n">MSE</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">cv_scores</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="c"># determining best k</span>
</span><span class='line'><span class="n">optimal_k</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">[</span><span class="n">MSE</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">MSE</span><span class="p">))]</span>
</span><span class='line'><span class="k">print</span> <span class="p">(</span><span class="s">&quot;The optimal number of neighbors is </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">optimal_k</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># plot misclassification error vs k</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">MSE</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;Number of Neighbors K&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;Misclassification Error&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>在上面的程序中，我们在1-50的奇数中选取k值，并根据k值训练模型进行预估验证。最后根据不同k值训练出去的模型的<strong>均方误差（Mean Squared Error, MSE）</strong>作出折线图，并求出使得MSE最小的最优k值。</p>

<blockquote><p>输出结果:</p>

<p>The optimal number of neighbors is 7
<img src="https://kevinzakka.github.io/assets/cv_knn.png" alt="enter image description here" /></p></blockquote>

<p>由此我们可以得出：在这个模型中，10折交叉验证告诉我们最优的k值是7。</p>

<h2>尝试自己实现KNN算法</h2>

<p>到目前为止，我们都是调用sklearn库中的KNN来完成分类任务。那么，下面我们来尝试自己实现一个简单的KNN算法并用它来分类我们之前的数据。</p>

<p>经过上一篇文章的介绍，我们可以知道KNN算法的关键是计算出新的<strong>待分类数据</strong>与现有的样本数据的<strong>“距离”</strong>，而其中较为常用的还是<strong>欧式距离（euclidean distance ）</strong>。然后提取出k个最相邻的点，并根据他们大多数点的分类属性来给待分类点进行归类。</p>

<p>因此核心计算代码我们可以这样写：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span class='line'>  <span class="c"># create list for distances and targets</span>
</span><span class='line'>  <span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>  <span class="n">targets</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)):</span>
</span><span class='line'>      <span class="c"># first we compute the euclidean distance</span>
</span><span class='line'>      <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x_test</span> <span class="o">-</span> <span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])))</span>
</span><span class='line'>      <span class="c"># add it to list of distances</span>
</span><span class='line'>      <span class="n">distances</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">distance</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># sort the list</span>
</span><span class='line'>  <span class="n">distances</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># make a list of the k neighbors&#39; targets</span>
</span><span class='line'>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
</span><span class='line'>      <span class="n">index</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</span><span class='line'>      <span class="n">targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># return most common target</span>
</span><span class='line'>  <span class="k">return</span> <span class="n">Counter</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>在上面的代码中，我们首先创建一个保存距离的数组，并在存储完计算出的待测点与各样本点的距离后对数组进行升序排列，然后取出前k个最接近待测点的样本点，返回其出现最多的分类标签。</p>

<p>然后接下来让我继续完成整个KNN算法。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">kNearestNeighbor</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># loop over all observations</span>
</span><span class='line'>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)):</span>
</span><span class='line'>      <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">k</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>使用我们上面得出最优的 k = 7作为参数生成模型并进行预估。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># making our predictions </span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</span><span class='line'><span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>
</span><span class='line'><span class="n">kNearestNeighbor</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># transform the list into an array</span>
</span><span class='line'><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span><span class='line'><span class="c">#print(y_test,predictions)</span>
</span><span class='line'><span class="c"># evaluating accuracy</span>
</span><span class='line'><span class="c">#for i in range(predictions.size):</span>
</span><span class='line'><span class="c">#    print(predictions.tolist()[i],list(y_test)[i])</span>
</span><span class='line'><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\n</span><span class="s">The accuracy of our classifier is </span><span class="si">%d%%</span><span class="s">&#39;</span> <span class="o">%</span> <span class="nb">int</span><span class="p">(</span><span class="n">accuracy</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote><p>输出结果：
The accuracy of our classifier is 98%</p></blockquote>

<p>到此，我们基本已经完成了一个类似于sklearn库中的KNN算法了，并且还有不错的准确率。</p>

<h2>小结</h2>

<p>最后，KNN算法介绍性文章到这就结束了。我们来总结一下KNN算法的优点与不足。</p>

<h4>优点</h4>

<ul>
<li>易于理解</li>
<li>无需训练</li>
<li>容易迁移至多分类情况</li>
</ul>


<h4>不足</h4>

<ul>
<li>计算量大，时间复杂度随数据规模增大而增大</li>
<li>分类情况容易受高频分类影响</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K-近邻算法-Part1]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/08/14/k-jin-lin-suan-fa-part1/"/>
    <updated>2017-08-14T23:48:56+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/08/14/k-jin-lin-suan-fa-part1</id>
    <content type="html"><![CDATA[<h1 id="k-近邻算法-part1">K-近邻算法-Part1</h1>




<h2 id="概述">概述</h2>




<p>K-近邻算法，即K-近邻分类算法，简称KNN其通过采用测量不同的特征值之间的距离方法进行分类。</p>




<h3 id="有关k-近邻算法的问题">有关K-近邻算法的问题</h3>




<p>优点：精度高，对异常值不敏感，无数据输入假定</p>




<p>缺点：计算复杂度较高，空间复杂度较高</p>




<p>适用数据范围：数值型和标称型</p>




<h3 id="工作原理">工作原理</h3>




<p>存在一个样本数据集合，即训练样本集，并且训练样本中的每一个数据都存在标签，我们可以清楚地知道每一个数据条目其与对应分类的所属关系。</p>




<p>然后在接受没有标记的新数据输入时，将新数据的特征提取出来将其一一与训练样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似的（即所谓的最近邻）的分类标签来作为新数据的标签。</p>




<p>其中为了避免偶尔性和离群值造成的误差因此有了以样本数据集中前k个最相似的数据作为判别的参考的标准这种做法。<strong>通常k是不大于20的整数而且一般选取奇数作为k值</strong>（奇数可以在投票分类时避免出现等票的情况），最终的分类结果由k个样本的分类标签投票形成，出现最多的分类标签作为新数据的分类。</p>




<h3 id="一般算法流程">一般算法流程</h3>




<ol>
<li>收集数据</li>
<li>准备数据：对数据进行清洗和结构化处理，使得数据可以进行距离计算</li>
<li>分析数据：提取相关特征</li>
<li>训练分类：knn算法并不需要训练</li>
<li>测试算法：计算错误率</li>
<li>使用算法：将新数据输入进行对应结构化之后，运行算法进行判定分类情况，并对后续的分类结果进行进一步处理应用</li>
</ol>




<h2 id="用knn-制作简单的分类器">用KNN 制作简单的分类器</h2>




<p>使用数据：<a href="https://archive.ics.uci.edu/ml/datasets/Iris">UCI的鸢尾花数据集</a> <br>
点击进入目标链接后: </p>




<blockquote>
  <p>按照 Download Data Folder &gt; iris.data 路径来下载指定数据集</p>
</blockquote>




<h4 id="准备数据">准备数据</h4>




<p>在这里我们使用Python 的 Pandas 包以没有标题栏的csv文件的形式读入数据</p>




<p><strong>关键函数：read_csv</strong></p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># loading libraries</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'>
</span><span class='line'><span class="c"># define column names</span>
</span><span class='line'><span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s">&#39;sepal_width&#39;</span><span class="p">,</span> <span class="s">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s">&#39;petal_width&#39;</span><span class="p">,</span> <span class="s">&#39;class&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="c"># loading training data</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">&#39;iris.data.txt&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
</span><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>




<p><strong>输出</strong>：</p>




<table>
<thead>
<tr>
  <th>index</th>
  <th>sepal_length</th>
  <th>sepal_width</th>
  <th>petal_length</th>
  <th>petal_width</th>
  <th>class</th>
</tr>
</thead>
<tbody><tr>
  <td>0</td>
  <td>5.1</td>
  <td>3.5</td>
  <td>1.4</td>
  <td>0.2</td>
  <td>Iris-setosa</td>
</tr>
<tr>
  <td>1</td>
  <td>4.9</td>
  <td>3.0</td>
  <td>1.4</td>
  <td>0.2</td>
  <td>Iris-setosa</td>
</tr>
<tr>
  <td>2</td>
  <td>4.7</td>
  <td>3.2</td>
  <td>1.3</td>
  <td>0.2</td>
  <td>Iris-setosa</td>
</tr>
<tr>
  <td>3</td>
  <td>4.6</td>
  <td>3.1</td>
  <td>1.5</td>
  <td>0.2</td>
  <td>Iris-setosa</td>
</tr>
<tr>
  <td>4</td>
  <td>5.0</td>
  <td>3.6</td>
  <td>1.4</td>
  <td>0.2</td>
  <td>Iris-setosa</td>
</tr>
</tbody></table>




<h4 id="构建算法">构建算法</h4>




<p><strong>距离函数</strong></p>




<p>我a们在上面的例子中把一个很重要的概念隐藏了起来，在选择一个数量k还只是小问题，更重要的是距离的计算方法。毕竟，当我们说“最近的k个点”时，这个“近”是怎么衡量的？</p>




<p>在数学中，一个空间上距离的严格定义如下： <br>
设 M 为一个空间，M上的一个距离函数是一个函数<script type="math/tex" id="MathJax-Element-383">d:M\times M \rightarrow R</script>，满足：</p>




<ul>
<li><script type="math/tex" id="MathJax-Element-384">d(x,y)≥0  ∀x,y∈M</script></li>
<li><script type="math/tex" id="MathJax-Element-385">d(x,y)=0⟺x=y</script></li>
<li><script type="math/tex" id="MathJax-Element-386">d(x,y)=d(y,x) ∀x,y∈M</script></li>
<li><script type="math/tex" id="MathJax-Element-387">d(x,z)≤d(x,y)+d(y,z) ∀x,y,z∈M</script></li>
</ul>




<p>两个点 x,y 之间的距离就是<script type="math/tex" id="MathJax-Element-388">d(x,y)</script>。</p>




<p>我们一般最常用的距离函数是欧氏距离，也称作<script type="math/tex" id="MathJax-Element-389">L_2</script>距离。</p>




<p>如果 <br>
<script type="math/tex" id="MathJax-Element-390">x=(x1,x2,…,xn)</script> 和 <script type="math/tex" id="MathJax-Element-391">y=(y1,y2,…,yn)</script>是 n 维欧式空间 Rn 上的两个点，那它们之间的<script type="math/tex" id="MathJax-Element-392">L_2</script>距离是</p>




<p><script type="math/tex" id="MathJax-Element-393">d_2(X,Y)=\sqrt{\sum _{i=1}^n \left(X_i-Y_i\right){}^2}</script></p>




<p>由于Python 的scikit-learn包已经实现了KNN算法，因此我们在这里可以直接调用。</p>




<p>在<a href="http://scikit-learn.org/stable/index.html">scikit-learn</a>中，需要以matrix的形式和目标向量的形式来导入和训练数据。</p>




<p>因此在使用scikit-learn之前需要做额外的数据结构处理，同时还应该把原数据划分成训练数据和测试数据这样更加有利于我们下面的算法正确率评估。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># loading libraries</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span><span class='line'>
</span><span class='line'><span class="c"># create design matrix X and target vector y</span>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span>   <span class="c"># end index is exclusive</span>
</span><span class='line'><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;class&#39;</span><span class="p">])</span>   <span class="c"># another way of indexing a pandas df</span>
</span><span class='line'>
</span><span class='line'><span class="c"># split into train and test</span>
</span><span class='line'><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<p>最后，我们根据划分好的数据集来构建真正的分类器，并用构建出来的分类器来进行数据拟合以及评估他的正确率。</p>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># loading library</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
</span><span class='line'><span class="c"># instantiate learning model (k = 3)</span>
</span><span class='line'><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># fitting the model</span>
</span><span class='line'><span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># predict the response</span>
</span><span class='line'><span class="n">pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># evaluate accuracy</span>
</span><span class='line'><span class="c"># print(y_test,pred)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>




<p><strong>输出</strong></p>




<blockquote>
  <p>0.98</p>
</blockquote>




<p>由此可见，在适用的场合之下，KNN分类器的准确率也是可以达到一个较为理想的水平的。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[机器学习概述-科普向]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/08/06/ji-qi-xue-xi-gai-shu-ke-pu-xiang/"/>
    <updated>2017-08-06T23:02:41+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/08/06/ji-qi-xue-xi-gai-shu-ke-pu-xiang</id>
    <content type="html"><![CDATA[<h1>机器学习概论-科普篇</h1>

<h2>什么是机器学习？</h2>

<p>机器学习是一门多领域交叉学科。专门研究计算机或其他软硬件设备怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有知识结构使不断改善自身的性能。</p>

<h2>机器学习的应用领域</h2>

<p>机器学习是人工智能研究的核心内容。它的应用已遍及人工智能的各个分支。如：专家系统，自动推理，自然语言处理，模式识别，计算机视觉，智能机器人等领域。</p>

<h2>机器学习与数据挖掘的区别</h2>

<p>机器学习在数据挖掘中被大量使用，其技术内涵几乎通用，可以看作同一座山峰在不同角度下的侧影。</p>

<h2>机器学习与统计学的关系</h2>

<p>机器学习和统计学是非常接近的两个领域。根据 Michael I. Jordan在机器学习领域的理念，从方法论原则到理论工具，在统计学领域是有一段很长的史前史。他也建议数据科学这一术语作为全部领域的前置。 Leo Breiman区别两个统计学的模型：数据模型和算法模型，在算法模型中意味着或多或少包含着机器学习的算法，比如随机森林（Random forest）。 一些统计学家已经采纳了机器学习中的一些做法，引申出了一个联结领域&mdash;&ndash;统计学习。</p>

<h2>机器学习方法</h2>

<p><strong>决策树学习：</strong>决策树学习使用了一个决策树作为预测性模型，映射一个对象的观察结果给其目标价值一个推论。</p>

<p><strong>关联规则学习:</strong>是一种用来在大型数据库中发现变量之间的有趣联系的方法,例如频繁模式挖掘。</p>

<p><strong>人工神经网络：</strong>一个人工神经网络学习（ANN）算法，通常被称为神经网络（NN），是一个由生物的神经网络所激发出的一个算法。计算结构是由联结的人工神经元组所构成，通过联结式的方法来传递信息和计算。现代神经网络是非线性的统计学数据模型工具。它们通常被用来在输入和输出之间模拟复杂关系，找到数据中的关系，或者在观测变量中从不知道的节点捕获统计学结构。</p>

<p><strong>深度学习：</strong>个人不能承受硬件的价格和GPU的发展推动了这些年深度学习的进步，深度学习是由人工神经网络中的多个隐藏层组成的。这条道路试图去模拟人脑的过程，光、声进入视觉和听觉。一些成功的应用有计算机视觉和演讲识别。</p>

<p><strong>归纳逻辑编程：</strong>归纳逻辑编程（ILP）是一门用逻辑编程控制规则的学科，它使用统一的表示法来处理输入样例，背景知识和假说。给定已知的背景知识的编码和一组被表示为事实的逻辑数据库的示例，ILP系统将派生出一个假设的逻辑程序，该程序包含所有积极的和没有负面的示例。归纳编程是一个相关的领域，它考虑任何一种表示假设(而不仅仅是逻辑编程)的编程语言，例如函数式编程。</p>

<p><strong>支持向量机：</strong>支持向量机是一系列关于监督学习在分类和回归上的应用。给出训练样本的数据集，每一个标记属于两类中的一类，一个SVM训练算法构成了一个模型，可以用来预测一个新的样本是否进入一个类别或者是另一个。</p>

<p><strong>集群：</strong>集群分析是将一组观察结果分配到子集(称为集群)，这样，同一集群中的观察与一些预先确定的标准或标准相似，而来自不同集群的观察则不同。不同的聚类技术对数据的结构作出不同的假设，通常由一些相似性度量定义，并通过内部紧度(相同集群的成员之间的相似性)和不同的集群之间的分离来评估。其他方法基于估计的密度和图连通性。摘要聚类是一种非引导性学习的方法，是一种统计数据分析的常用技术。</p>

<p><strong>贝叶斯网络：</strong>一个贝叶斯网络，信任网络或者有向无环图模型是一个概率性图的模型，它通过有向无环图代表了一系列的随机变量和他们的条件独立性。举例，一个贝叶斯网络代表着疾病和症状可能的关系。给出症状，网络可以被用来计算疾病出现的可能性。有效的算法存在于执行推理和学习的过程中。</p>

<p><strong>增强学习：</strong>增强学习关心代理人如何在一个环境中采取行动，从而最大化一些长期受益的概念。增强学习算法尝试去寻找一些策略，映射当前世界的状态给代理在这些状态中应该采取的行动。</p>

<p><strong>相似度量学习：</strong>在这个问题中，学习机被给予了很多对相似或者不相似的例子。它需要去学习一个相似的函数，以用来预测一个新的对象是否相似。它有时被用到推荐系统中。</p>

<p><strong>遗传算法：</strong>遗传算法是一种启发式搜索，它模仿自然选择的过程，并且使用一些突变和变向来生成新的基因型，以找到好的情况解决问题。在机器学习中，遗传算法在20世纪80年代和90年代使用过。反之，机器学习技术被用来提高遗传和进化算法的表现。</p>

<p><strong>基于规则的机器学习：</strong>基于规则的机器学习是任何机器学习方法的通用术语，它可以识别、学习或发展规则来存储、操作或应用知识。基于规则的机器学习者的定义特征是一组关系规则的标识和利用，这些规则集合了系统所捕获的知识。这与其他机器学习者形成鲜明对比，他们通常会识别出一种特殊的模型，这种模型可以普遍应用于任何实例，以便做出预测。基于规则的机器学习方法包括学习分类器系统、关联规则学习和人工免疫系统。</p>

<h2>机器学习应用场景</h2>

<h3>活跃的领域：</h3>

<ul>
<li>数据分析</li>
<li>数据挖掘。</li>
<li>图像和语音识别</li>
<li>智能机器，机器人，人机对话，电脑博弈。</li>
</ul>


<h3>推荐系统：</h3>

<ul>
<li>基于物品的协同过滤</li>
<li>频繁模式挖掘</li>
</ul>


<h3>贝叶斯分类器：</h3>

<ul>
<li>垃圾邮件过滤</li>
<li>网页自动分类：自动化门户系统</li>
<li>评论自动分析</li>
</ul>


<h3>决策树</h3>

<ul>
<li>量化交易</li>
<li>智能博弈</li>
<li>局面标准化</li>
<li>局面评估函数</li>
<li>棋谱学习</li>
</ul>


<h3>神经网络和深度学习</h3>

<ul>
<li>语音识别,图像识别</li>
<li>图形识别：</li>
<li>车牌识别</li>
<li>指纹，虹膜纹识别</li>
<li>脸像识别</li>
<li>动态图像识别</li>
<li>小波分析</li>
</ul>


<h2>机器学习常用软件</h2>

<p>常用软件列表：</p>

<ul>
<li>R（及其扩展包）</li>
<li>Weka（Waikato Environment for Knowledge Analysis）</li>
<li>Matlab</li>
<li>Python,numpy,matplotlib,sklearn,tensorflow</li>
</ul>


<h2>代表性算法</h2>

<h3>回归预测及降维技术：</h3>

<ul>
<li>线性回归</li>
<li>Logistic回归</li>
<li>主成分分析</li>
<li>因子分析</li>
<li>岭回归</li>
<li>LASSO</li>
</ul>


<h3>分类器:</h3>

<ul>
<li>决策树</li>
<li>朴素贝叶斯</li>
<li>贝叶斯信念网络</li>
<li>支持向量机(SVM)</li>
<li>提升分类器准确率的Adaboost和随机森林算法</li>
</ul>


<h3>聚类和孤立点判别</h3>

<ul>
<li>Kmeans聚类</li>
</ul>


<h3>人工神经网路及深度学习</h3>

<ul>
<li>CNN</li>
<li>RNN</li>
</ul>


<p>&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scala概率编程语言库-Figaro介绍]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/07/24/scalagai-lu-bian-cheng-yu-yan-ku-figarojie-shao/"/>
    <updated>2017-07-24T16:15:49+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/07/24/scalagai-lu-bian-cheng-yu-yan-ku-figarojie-shao</id>
    <content type="html"><![CDATA[<h1>Scala 的概率编程语言库-Figaro</h1>

<h2>什么是概率编程？</h2>

<p><strong>概率编程</strong>是一种系统创建方法，它所创建的系统能够帮助我们在面对不确定性时作出决策。</p>

<h2>为什么使用概率编程？</h2>

<p>概率推理是机器学习的基础技术之一。Google,Amazon和Microsoft等公司使用它理解可用数据。概率推理已经应用于各种各样的应用程序，如预测股价，推荐电影，诊断计算机和检测网络入侵。</p>

<ul>
<li>概率推理可用于预测未来，推断过去，以及从过去的事实中学习更好地预测未来。</li>
<li>概率编程是使用图灵完备的编程语言作为表示语言的概率编程。</li>
</ul>


<p><strong>事实上：</strong>概率推理 + 图灵完备 = 概率编程</p>

<h2>Figaro的简介</h2>

<p>Figaro是一个内嵌于Scala编程语言的概率编程系统。除了继承了Scala的良好特性外，Figaro还提供了相当多的额外的优势，包括：</p>

<ul>
<li>Figaro能够表示及其广泛的概率模型。Figaro元素的值可以为任何类型，包括布尔型，整数，双精度数，数组，树，图等。</li>
<li>Figaro提供了使用其条件和约束规定证据的丰富框架</li>
<li>Figaro有多种多样的推理算法</li>
<li>Figaro能够表示和推理随时间变化的的动态模型</li>
<li>Figaro能够在其模型中包含明确决策，并支持最优决策的推断。</li>
</ul>


<h2>简单示例-量化“你好，世界”</h2>

<p>图片截取自<a href="http://www.epubit.com.cn/book/details/4366">《概率编程实战》</a> 表 1-1
<img src="https://edmondfrank.github.io/images/figaro.jpg"></p>

<p><strong>代码实现：</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">mport</span> <span class="n">com</span><span class="o">.</span><span class="n">cra</span><span class="o">.</span><span class="n">figaro</span><span class="o">.</span><span class="n">language</span><span class="o">.</span><span class="k">_</span>
</span><span class='line'><span class="k">import</span> <span class="nn">com.cra.figaro.library.compound.If</span>
</span><span class='line'><span class="k">import</span> <span class="nn">com.cra.figaro.algorithm.factored.VariableElimination</span>
</span><span class='line'>
</span><span class='line'><span class="k">object</span> <span class="nc">Main</span><span class="o">{</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">sunnyToday</span> <span class="k">=</span> <span class="nc">Flip</span><span class="o">(</span><span class="mf">0.2</span><span class="o">)</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">greetingToday</span> <span class="k">=</span> <span class="nc">If</span><span class="o">(</span><span class="n">sunnyToday</span><span class="o">,</span>
</span><span class='line'>    <span class="nc">Select</span><span class="o">(</span><span class="mf">0.6</span> <span class="o">-&gt;</span> <span class="s">&quot;Hello World&quot;</span><span class="o">,</span><span class="mf">0.4</span> <span class="o">-&gt;</span> <span class="s">&quot;Howdy universe&quot;</span><span class="o">),</span>
</span><span class='line'>    <span class="nc">Select</span><span class="o">(</span><span class="mf">0.2</span> <span class="o">-&gt;</span> <span class="s">&quot;Hello World&quot;</span><span class="o">,</span><span class="mf">0.8</span><span class="o">-&gt;</span> <span class="s">&quot;no not again!&quot;</span><span class="o">))</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">sunnyTomorrow</span> <span class="k">=</span> <span class="nc">If</span><span class="o">(</span><span class="n">sunnyToday</span><span class="o">,</span> <span class="nc">Flip</span> <span class="o">(</span><span class="mf">0.8</span><span class="o">)</span> <span class="o">,</span> <span class="nc">Flip</span> <span class="o">(</span><span class="mf">0.05</span><span class="o">))</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">greetingTomorrow</span> <span class="k">=</span> <span class="nc">If</span><span class="o">(</span><span class="n">sunnyTomorrow</span><span class="o">,</span>
</span><span class='line'>    <span class="nc">Select</span><span class="o">(</span><span class="mf">0.6</span> <span class="o">-&gt;</span> <span class="s">&quot;Hello World&quot;</span><span class="o">,</span><span class="mf">0.4</span> <span class="o">-&gt;</span> <span class="s">&quot;Howdy universe&quot;</span><span class="o">),</span>
</span><span class='line'>    <span class="nc">Select</span><span class="o">(</span><span class="mf">0.6</span> <span class="o">-&gt;</span> <span class="s">&quot;Hello World&quot;</span><span class="o">,</span><span class="mf">0.4</span> <span class="o">-&gt;</span> <span class="s">&quot;no not again&quot;</span><span class="o">))</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">predict</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">={</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="nc">VariableElimination</span><span class="o">.</span><span class="n">probability</span><span class="o">(</span><span class="n">greetingToday</span><span class="o">,</span><span class="s">&quot;Hello World&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="n">println</span><span class="o">(</span><span class="s">&quot;Today&#39;s greeting is \&quot;Hello World!\&quot; &quot;</span><span class="o">+</span><span class="s">&quot; with probability &quot;</span><span class="o">+</span> <span class="n">result</span> <span class="o">+</span><span class="s">&quot;.&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">infer</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">greeting</span> <span class="k">=</span> <span class="s">&quot;Hello World&quot;</span>
</span><span class='line'>    <span class="n">greetingToday</span><span class="o">.</span><span class="n">observe</span><span class="o">(</span><span class="n">greeting</span><span class="o">)</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="nc">VariableElimination</span><span class="o">.</span><span class="n">probability</span><span class="o">(</span><span class="n">sunnyToday</span><span class="o">,</span><span class="kc">true</span><span class="o">)</span>
</span><span class='line'>    <span class="n">println</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;If today&#39;s greeting is $greeting with probability $result.&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">learnAndPredict</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">={</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">greeting</span> <span class="k">=</span> <span class="s">&quot;Hello World&quot;</span>
</span><span class='line'>    <span class="n">greetingToday</span><span class="o">.</span><span class="n">observe</span><span class="o">(</span><span class="n">greeting</span><span class="o">)</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="nc">VariableElimination</span><span class="o">.</span><span class="n">probability</span><span class="o">(</span><span class="n">greetingTomorrow</span><span class="o">,</span><span class="n">greeting</span><span class="o">)</span>
</span><span class='line'>    <span class="n">println</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;If today&#39;s greeting is $greeting,tomorrow&#39;s greeting will be $greeting\n&quot;</span> <span class="o">+</span>
</span><span class='line'>      <span class="n">s</span><span class="s">&quot;with probability $result.&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">predict</span>
</span><span class='line'>    <span class="n">infer</span>
</span><span class='line'>    <span class="n">learnAndPredict</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python科学计算库NumPy的使用]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/07/19/pythonke-xue-ji-suan-ku-numpyde-shi-yong/"/>
    <updated>2017-07-19T19:10:49+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/07/19/pythonke-xue-ji-suan-ku-numpyde-shi-yong</id>
    <content type="html"><![CDATA[<h1>Python科学计算库NumPy的使用</h1>

<h2>NumPy的介绍</h2>

<p>NumPy(Numerical Python的缩写)是一个开源的Python科学计算库。使用NumPy,就可以很自然地使用数组和矩阵。NumPy包含很多实用的数学函数,涵盖线性代数运算、傅里叶变换和随机数生成等功能。如果你的系统中已经装有LAPACK,NumPy的线性代数模块会调用它,否则NumPy将使用自己实现的库函数。LAPACK是一个著名的数值计算库,最初是用Fortran写成的,Matlab同样也需要调用它。从某种意义上讲,NumPy可以取代Matlab和Mathematica的部分功能,并且允许用户进行快速的交互式原型设计。</p>

<h2>NumPy的数组对象</h2>

<p>ndarray是一个多维数组对象，该对象由实际数据+描述性元数据组成。
使用Numpy需要先安装和导入NumPy库，有关安装教程可以参考<a href="https://docs.scipy.org/doc/numpy/user/install.html">Installing NumPy</a></p>

<blockquote><p>导入语法：import numpy as np</p></blockquote>

<p>此处使用np为别名是为了避免命名空间被污染。</p>

<p><strong>特点</strong>：</p>

<ol>
<li>NumPy数组一般是同质（即数组内的元素为相同类型，特殊类型除外）</li>
<li>NumPy数组的下标也是从0开始</li>
<li>可以方便地创建高维数组</li>
</ol>


<p><em>eg：</em></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: <span class="nv">a</span> <span class="o">=</span> np.arange<span class="o">(</span>5<span class="o">)</span>
</span><span class='line'>In: a.dtype
</span><span class='line'>Out: dtype<span class="o">(</span><span class="s1">&#39;int64&#39;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>而在32位系统中，得到的结果类型可能是int32。</p>

<p><strong>多维数组的创建</strong>：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: <span class="nv">m</span> <span class="o">=</span> np.array<span class="o">([</span>np.arange<span class="o">(</span>2<span class="o">)</span>, np.arange<span class="o">(</span>2<span class="o">)])</span>
</span><span class='line'>In: m
</span><span class='line'>Out:
</span><span class='line'>array<span class="o">([[</span>0, 1<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>0, 1<span class="o">]])</span>
</span><span class='line'>In: m.shape <span class="c">#shape可以输出数组行列（维度）信息</span>
</span><span class='line'>Out: <span class="o">(</span>2, 2<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>选取数组元素</strong>：
我们继续沿用上面创建的数组m</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: m<span class="o">[</span>0,0<span class="o">]</span>
</span><span class='line'>Out: 0
</span><span class='line'>In: m<span class="o">[</span>0,1<span class="o">]</span>
</span><span class='line'>Out: 1
</span></code></pre></td></tr></table></div></figure>


<pre><code>是的,从数组中选取元素就是这么简单。对于数组 a ,只需要用 a[m,n] 选取各数组元素,其中 m 和 n 为元素下标。
</code></pre>

<p><strong>NumPy的数据类型</strong>:
    Python支持的数据类型有整型、浮点型以及复数型,但这些类型不足以满足科学计算的需求,因此NumPy添加了很多其他的数据类型。在NumPy中,许多函数的参数中可以指定数据类型,通常这个参数是可选的:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: np.arange<span class="o">(</span>7, <span class="nv">dtype</span><span class="o">=</span>uint16<span class="o">)</span>
</span><span class='line'>Out: array<span class="o">([</span>0, 1, 2, 3, 4, 5, 6<span class="o">]</span>, <span class="nv">dtype</span><span class="o">=</span>uint16<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>其中完整的数据类型可以通过np.sctypeDict.keys()查到：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dict_keys<span class="o">([</span>0, 1, 2, 3, <span class="s1">&#39;D&#39;</span>, 5, 6, <span class="s1">&#39;ushort&#39;</span>, 8, <span class="s1">&#39;P&#39;</span>, 10, 11, 12, <span class="s1">&#39;uintp&#39;</span>, 14, 15, 16, 17, 18, 19, <span class="s1">&#39;Float16&#39;</span>, 21, 22, 23, <span class="s1">&#39;cfloat&#39;</span>, 4, <span class="s1">&#39;Object0&#39;</span>, <span class="s1">&#39;int32&#39;</span>, <span class="s1">&#39;UInt64&#39;</span>, <span class="s1">&#39;Complex128&#39;</span>, <span class="s1">&#39;uint0&#39;</span>, <span class="s1">&#39;i2&#39;</span>, 7, <span class="s1">&#39;Int16&#39;</span>, <span class="s1">&#39;int&#39;</span>, <span class="s1">&#39;complex&#39;</span>, <span class="s1">&#39;ubyte&#39;</span>, <span class="s1">&#39;Int32&#39;</span>, <span class="s1">&#39;float&#39;</span>, <span class="s1">&#39;i&#39;</span>, <span class="s1">&#39;short&#39;</span>, <span class="s1">&#39;B&#39;</span>, <span class="s1">&#39;str0&#39;</span>, 9, <span class="s1">&#39;complex_&#39;</span>, <span class="s1">&#39;O&#39;</span>, <span class="s1">&#39;long&#39;</span>, <span class="s1">&#39;bytes&#39;</span>, <span class="s1">&#39;float_&#39;</span>, <span class="s1">&#39;Int64&#39;</span>, <span class="s1">&#39;int0&#39;</span>, <span class="s1">&#39;Void0&#39;</span>, <span class="s1">&#39;float128&#39;</span>, <span class="s1">&#39;Float64&#39;</span>, <span class="s1">&#39;Str0&#39;</span>, <span class="s1">&#39;int64&#39;</span>, <span class="s1">&#39;b&#39;</span>, <span class="s1">&#39;longdouble&#39;</span>, <span class="s1">&#39;void&#39;</span>, <span class="s1">&#39;f&#39;</span>, <span class="s1">&#39;longcomplex&#39;</span>, <span class="s1">&#39;ulonglong&#39;</span>, <span class="s1">&#39;intp&#39;</span>, <span class="s1">&#39;UInt32&#39;</span>, <span class="s1">&#39;V&#39;</span>, <span class="s1">&#39;object_&#39;</span>, <span class="s1">&#39;longlong&#39;</span>, <span class="s1">&#39;csingle&#39;</span>, <span class="s1">&#39;uint&#39;</span>, <span class="s1">&#39;c32&#39;</span>, <span class="s1">&#39;M&#39;</span>, <span class="s1">&#39;I&#39;</span>, <span class="s1">&#39;singlecomplex&#39;</span>, <span class="s1">&#39;double&#39;</span>, <span class="s1">&#39;timedelta64&#39;</span>, <span class="s1">&#39;object&#39;</span>, <span class="s1">&#39;unicode_&#39;</span>, <span class="s1">&#39;Float128&#39;</span>, <span class="s1">&#39;uint64&#39;</span>, <span class="s1">&#39;h&#39;</span>, <span class="s1">&#39;str&#39;</span>, <span class="s1">&#39;d&#39;</span>, <span class="s1">&#39;UInt8&#39;</span>, 20, <span class="s1">&#39;complex128&#39;</span>, <span class="s1">&#39;string_&#39;</span>, <span class="s1">&#39;clongfloat&#39;</span>, <span class="s1">&#39;H&#39;</span>, <span class="s1">&#39;m8&#39;</span>, <span class="s1">&#39;clongdouble&#39;</span>, <span class="s1">&#39;S&#39;</span>, <span class="s1">&#39;g&#39;</span>, <span class="s1">&#39;bool_&#39;</span>, <span class="s1">&#39;unicode&#39;</span>, <span class="s1">&#39;f16&#39;</span>, 13, <span class="s1">&#39;int8&#39;</span>, <span class="s1">&#39;void0&#39;</span>, <span class="s1">&#39;L&#39;</span>, <span class="s1">&#39;M8&#39;</span>, <span class="s1">&#39;uint32&#39;</span>, <span class="s1">&#39;p&#39;</span>, <span class="s1">&#39;bytes0&#39;</span>, <span class="s1">&#39;e&#39;</span>, <span class="s1">&#39;datetime64&#39;</span>, <span class="s1">&#39;U&#39;</span>, <span class="s1">&#39;float16&#39;</span>, <span class="s1">&#39;c16&#39;</span>, <span class="s1">&#39;?&#39;</span>, <span class="s1">&#39;Bool&#39;</span>, <span class="s1">&#39;byte&#39;</span>, <span class="s1">&#39;i4&#39;</span>, <span class="s1">&#39;c8&#39;</span>, <span class="s1">&#39;int16&#39;</span>, <span class="s1">&#39;half&#39;</span>, <span class="s1">&#39;uint16&#39;</span>, <span class="s1">&#39;str_&#39;</span>, <span class="s1">&#39;i8&#39;</span>, <span class="s1">&#39;Complex32&#39;</span>, <span class="s1">&#39;Int8&#39;</span>, <span class="s1">&#39;bool&#39;</span>, <span class="s1">&#39;Bytes0&#39;</span>, <span class="s1">&#39;G&#39;</span>, <span class="s1">&#39;l&#39;</span>, <span class="s1">&#39;uint8&#39;</span>, <span class="s1">&#39;f2&#39;</span>, <span class="s1">&#39;single&#39;</span>, <span class="s1">&#39;f8&#39;</span>, <span class="s1">&#39;q&#39;</span>, <span class="s1">&#39;Q&#39;</span>, <span class="s1">&#39;m&#39;</span>, <span class="s1">&#39;Complex64&#39;</span>, <span class="s1">&#39;f4&#39;</span>, <span class="s1">&#39;u2&#39;</span>, <span class="s1">&#39;Float32&#39;</span>, <span class="s1">&#39;i1&#39;</span>, <span class="s1">&#39;u4&#39;</span>, <span class="s1">&#39;Datetime64&#39;</span>, <span class="s1">&#39;intc&#39;</span>, <span class="s1">&#39;float64&#39;</span>, <span class="s1">&#39;a&#39;</span>, <span class="s1">&#39;complex64&#39;</span>, <span class="s1">&#39;u1&#39;</span>, <span class="s1">&#39;bytes_&#39;</span>, <span class="s1">&#39;cdouble&#39;</span>, <span class="s1">&#39;object0&#39;</span>, <span class="s1">&#39;UInt16&#39;</span>, <span class="s1">&#39;bool8&#39;</span>, <span class="s1">&#39;float32&#39;</span>, <span class="s1">&#39;uintc&#39;</span>, <span class="s1">&#39;Timedelta64&#39;</span>, <span class="s1">&#39;F&#39;</span>, <span class="s1">&#39;longfloat&#39;</span>, <span class="s1">&#39;b1&#39;</span>, <span class="s1">&#39;u8&#39;</span>, <span class="s1">&#39;int_&#39;</span>, <span class="s1">&#39;complex256&#39;</span><span class="o">])</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>创建自定义数据类型</strong>：</p>

<p>(1)创建数据类型</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: <span class="nv">t</span> <span class="o">=</span> np.dtype<span class="o">([(</span><span class="s1">&#39;name&#39;</span>,np.str_,128<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;count&#39;</span>,np.int32<span class="o">)</span>,<span class="o">(</span><span class="s1">&#39;price&#39;</span>,np.float64<span class="o">)])</span>
</span><span class='line'>In: t
</span><span class='line'>Out: dtype<span class="o">([(</span><span class="s1">&#39;name&#39;</span>, <span class="s1">&#39;&lt;U128&#39;</span><span class="o">)</span>, <span class="o">(</span><span class="s1">&#39;count&#39;</span>, <span class="s1">&#39;&lt;i4&#39;</span><span class="o">)</span>, <span class="o">(</span><span class="s1">&#39;price&#39;</span>, <span class="s1">&#39;&lt;f8&#39;</span><span class="o">)])</span>
</span></code></pre></td></tr></table></div></figure>


<p>(2)查看数据类型</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: t<span class="o">[</span><span class="s1">&#39;name&#39;</span><span class="o">]</span>
</span><span class='line'>Out: dtype<span class="o">(</span><span class="s1">&#39;&lt;U128&#39;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>(3)使用自定义数据</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: <span class="nv">itemz</span> <span class="o">=</span> np.array<span class="o">([(</span><span class="s1">&#39;Meaning of life DVD&#39;</span>, 42, 3.14<span class="o">)</span>, <span class="o">(</span><span class="s1">&#39;Butter&#39;</span>, 13, 2.72<span class="o">)]</span>, <span class="nv">dtype</span><span class="o">=</span>t<span class="o">)</span>
</span><span class='line'>In: itemz<span class="o">[</span>1<span class="o">]</span>
</span><span class='line'>Out: <span class="o">(</span><span class="s1">&#39;Butter&#39;</span>, 13, 2.72<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>一维数组的索引和切片</strong>：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: <span class="nv">a</span> <span class="o">=</span> np.arange<span class="o">(</span>9<span class="o">)</span>
</span><span class='line'>In: a<span class="o">[</span>3:7<span class="o">]</span>
</span><span class='line'>Out: array<span class="o">([</span>3, 4, 5, 6<span class="o">])</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>多维数组索引和切片</strong>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In： <span class="nv">b</span><span class="o">=</span>np.arange<span class="o">(</span>24<span class="o">)</span>.reshape<span class="o">(</span>2,3,4<span class="o">)</span>
</span><span class='line'>In: b
</span><span class='line'>Out: array<span class="o">([[[</span> 0,  1,  2,  3<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span> 4,  5,  6,  7<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span> 8,  9, 10, 11<span class="o">]]</span>,
</span><span class='line'>
</span><span class='line'>       <span class="o">[[</span>12, 13, 14, 15<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span>16, 17, 18, 19<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span>20, 21, 22, 23<span class="o">]]])</span>
</span><span class='line'>In: b<span class="o">[</span>0,2,1<span class="o">]</span>
</span><span class='line'>Out: 9-
</span><span class='line'><span class="c">#我们还可以这样写,选取第0组的所有元素:</span>
</span><span class='line'>In: b<span class="o">[</span>0,:,:<span class="o">]</span>
</span><span class='line'>Out: array<span class="o">([[</span>
</span><span class='line'>0, 1, 2, 3<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>4, 5, 6, 7<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>8, 9,10,11<span class="o">]])</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>同时，b[0,:,:] == b[0,&hellip;]。</em>
更多的多维数组的索引和切片操作可以参考<a href="https://docs.scipy.org/doc/numpy/reference/">NumPy使用手册</a></p>

<p><strong>数组展平</strong>:</p>

<p>(1)ravel</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: b-
</span><span class='line'>Out:
</span><span class='line'>array<span class="o">([[[</span> 0, 1, 2, 3<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 4, 5, 6, 7<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 8, 9,10,11<span class="o">]]</span>,
</span><span class='line'><span class="o">[[</span>12,13,14,15<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>16,17,18,19<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>20,21,22,23<span class="o">]]])</span>
</span><span class='line'>In: b.ravel<span class="o">()</span>
</span><span class='line'>Out:
</span><span class='line'>array<span class="o">([</span> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,
</span><span class='line'>17, 18, 19, 20, 21, 22, 23<span class="o">])</span>
</span></code></pre></td></tr></table></div></figure>


<p>(2)flatten</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: b.flatten<span class="o">()</span>
</span><span class='line'>Out:
</span><span class='line'>array<span class="o">([</span> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,
</span><span class='line'>17, 18, 19, 20, 21, 22, 23<span class="o">])</span>
</span></code></pre></td></tr></table></div></figure>


<p>flatten 和 ravel的区别在于：flatten函数会请求分配内存来保存结果，而reval函数只是返回数组的一个视图（view）</p>

<p>(3)改变数组的shape属性</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: b.shape <span class="o">=</span> <span class="o">(</span>6,4<span class="o">)</span>
</span><span class='line'>In: b
</span><span class='line'>Out:
</span><span class='line'>array<span class="o">([</span> 0, 1, 2, 3<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 4, 5, 6, 7<span class="o">]</span>,-
</span><span class='line'><span class="o">[</span> 8, 9,10,11<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>12,13,14,15<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>16,17,18,19<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>20,21,22,23<span class="o">]]</span>,
</span></code></pre></td></tr></table></div></figure>


<p>(4)transpose,相当与线性代数的转置</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: b.transpose<span class="o">()</span>
</span><span class='line'>Out:
</span><span class='line'>array<span class="o">([[</span> 0, 4, 8,12,16,20<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 1, 5, 9,13,17,21<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 2, 6,10,14,18,22<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 3, 7,11,15,19,23<span class="o">]])</span>
</span></code></pre></td></tr></table></div></figure>


<p>(5)resize，功能和reshape相同，但是resize会直接影响原操作数组</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: b.resize<span class="o">((</span>2,12<span class="o">))</span>
</span><span class='line'>In: b
</span><span class='line'>Out:
</span><span class='line'>array<span class="o">([[</span> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>12,13,14,15,16,17,18,19,20,21, 22, 23<span class="o">]])</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>数组组合</strong>：</p>

<p>(1)水平组合</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: <span class="nv">a</span> <span class="o">=</span> np.arange<span class="o">(</span>9<span class="o">)</span>.reshape<span class="o">(</span>3,3<span class="o">)</span>
</span><span class='line'>In: <span class="nv">b</span><span class="o">=</span>2*a
</span><span class='line'>In: np.hstack<span class="o">((</span>a,b<span class="o">))</span>
</span><span class='line'>Out: array<span class="o">([[</span> 0,  1,  2,  0,  2,  4<span class="o">]</span>,
</span><span class='line'>       <span class="o">[</span> 3,  4,  5,  6,  8, 10<span class="o">]</span>,
</span><span class='line'>       <span class="o">[</span> 6,  7,  8, 12, 14, 16<span class="o">]])</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>同样可以使用concatenate函数实现同样效果</em></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: concatenate<span class="o">((</span>a,b<span class="o">)</span>,axis<span class="o">=</span>1<span class="o">)</span>
</span><span class='line'>Out: array<span class="o">([[</span> 0, 1, 2, 0, 2, 4<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 3, 4, 5, 6, 8,10<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 6, 7, 8,12,14,16<span class="o">]])</span>
</span></code></pre></td></tr></table></div></figure>


<p>(2)垂直组合</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: np.vsta-ck<span class="o">((</span>a,b<span class="o">))</span>
</span><span class='line'>Out: array<span class="o">([[</span> 0,  1,  2<span class="o">]</span>,
</span><span class='line'>   <span class="o">[</span> 3,  4,  5<span class="o">]</span>,
</span><span class='line'>   <span class="o">[</span> 6,  7,  8<span class="o">]</span>,
</span><span class='line'>   <span class="o">[</span> 0,  2,  4<span class="o">]</span>,
</span><span class='line'>   <span class="o">[</span> 6,  8, 10<span class="o">]</span>,
</span><span class='line'>   <span class="o">[</span>12, 14, 16<span class="o">]])</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>同样可以使用concatenate函数实现同样效果</em></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: concatenate<span class="o">((</span>a,b<span class="o">)</span>,axis<span class="o">=</span>0<span class="o">)</span>
</span><span class='line'>Out: In: np.vstack<span class="o">((</span>a,b<span class="o">))</span>
</span><span class='line'>Out: array<span class="o">([[</span> 0,  1,  2<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 3,  4,  5<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 6,  7,  8<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 0,  2,  4<span class="o">]</span>,
</span><span class='line'><span class="o">[</span> 6,  8, 10<span class="o">]</span>,
</span><span class='line'><span class="o">[</span>12, 14, 16<span class="o">]])</span>
</span></code></pre></td></tr></table></div></figure>


<p>(3)深度组合</p>

<p>深度组合,就是将一系列数组沿着纵轴(深度)方向进行层叠组合。举个例子,有若干张二维平面内的图像点阵数据,我们可以将这些图像数据沿纵轴方向层叠在一起,这就形象地解释了什么是深度组合。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: np.dstack<span class="o">((</span>a,b<span class="o">))</span>
</span><span class='line'>Out: array<span class="o">([[[</span> 0,  0<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span> 1,  2<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span> 2,  4<span class="o">]]</span>,
</span><span class='line'>       <span class="o">[[</span> 3,  6<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span> 4,  8<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span> 5, 10<span class="o">]]</span>,
</span><span class='line'>
</span><span class='line'>       <span class="o">[[</span> 6, 12<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span> 7, 14<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span> 8, 16<span class="o">]]])</span>
</span></code></pre></td></tr></table></div></figure>


<p>(4)列组合,column_stack 函数对于一维数组将按列方向进行组合,而对于二维数组, column_stack 与 hstack 的效果是相同的</p>

<p>(5)行组合,当然,NumPy中也有按行方向进行组合的函数,它就是 row_stack 。对于两
个一维数组,将直接层叠起来组合成一个二维数组。同样，对于二维数组，row_stack 与 vstack 的效果是相同的。</p>

<p><strong>数组分割</strong>:</p>

<p>NumPy数组可以进行水平、垂直或深度分割,相关的函数有 hsplit 、 vsplit 、 dsplit 和split 。我们可以将数组分割成相同大小的子数组,也可以指定原数组中需要分割的位置。</p>

<p>(1)水平分割</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: a
</span><span class='line'>Out: array<span class="o">([[</span>0, 1, 2<span class="o">]</span>,
</span><span class='line'>       <span class="o">[</span>3, 4, 5<span class="o">]</span>,
</span><span class='line'>       <span class="o">[</span>6, 7, 8<span class="o">]])</span>
</span><span class='line'>In: np.hsplit<span class="o">(</span>a,3<span class="o">)</span> <span class="c">#沿水平方向分割成三个大小相同的子数组</span>
</span><span class='line'>Out: <span class="o">[</span>array<span class="o">([[</span>0<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span>3<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span>6<span class="o">]])</span>, array<span class="o">([[</span>1<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span>4<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span>7<span class="o">]])</span>, array<span class="o">([[</span>2<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span>5<span class="o">]</span>,
</span><span class='line'>        <span class="o">[</span>8<span class="o">]])]</span>
</span></code></pre></td></tr></table></div></figure>


<p>(2)垂直分割</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: np.vsplit<span class="o">(</span>a,3<span class="o">)</span> <span class="c">#在垂直方向上分割成三个大小相同的子数组</span>
</span><span class='line'>Out： <span class="o">[</span>array<span class="o">([[</span>0, 1, 2<span class="o">]])</span>, array<span class="o">([[</span>3, 4, 5<span class="o">]])</span>, array<span class="o">([[</span>6, 7, 8<span class="o">]])]</span>
</span></code></pre></td></tr></table></div></figure>


<p>(3)深度分割,dsplit函数将按深度方向分割数组。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>In: np.dsplit<span class="o">(</span>np.arange<span class="o">(</span>27<span class="o">)</span>.reshape<span class="o">(</span>3,3,3<span class="o">)</span>,3<span class="o">)</span>
</span><span class='line'>Out: <span class="o">[</span>array<span class="o">([[[</span> 0<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span> 3<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span> 6<span class="o">]]</span>,
</span><span class='line'>
</span><span class='line'>        <span class="o">[[</span> 9<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>12<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>15<span class="o">]]</span>,
</span><span class='line'>
</span><span class='line'>        <span class="o">[[</span>18<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>21<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>24<span class="o">]]])</span>, array<span class="o">([[[</span> 1<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span> 4<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span> 7<span class="o">]]</span>,
</span><span class='line'>
</span><span class='line'>        <span class="o">[[</span>10<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>13<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>16<span class="o">]]</span>,
</span><span class='line'>
</span><span class='line'>        <span class="o">[[</span>19<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>22<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>25<span class="o">]]])</span>, array<span class="o">([[[</span> 2<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span> 5<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span> 8<span class="o">]]</span>,
</span><span class='line'>
</span><span class='line'>        <span class="o">[[</span>11<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>14<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>17<span class="o">]]</span>,
</span><span class='line'>
</span><span class='line'>        <span class="o">[[</span>20<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>23<span class="o">]</span>,
</span><span class='line'>         <span class="o">[</span>26<span class="o">]]])]</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>同时，hsplit,vsplit同样也可以用函数split来实现，其使用就像上面的数组组合函数concatenate类似</em></p>

<p><strong>到此，NumPy的常规的数组操作基本就结束了！</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[有关统计学的一些笔记]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/07/14/you-guan-tong-ji-xue-de-yi-xie-bi-ji/"/>
    <updated>2017-07-14T13:22:09+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/07/14/you-guan-tong-ji-xue-de-yi-xie-bi-ji</id>
    <content type="html"><![CDATA[<h1>有关推断统计学</h1>

<h2>样本与总体</h2>

<p>在统计中，一个<strong>总体</strong>包括事件的全部，而一个<strong>样本</strong>是总体的一小部分（子集）
。</p>

<h2>推断统计学</h2>

<p><strong>推断统计学（Inferential statistics）</strong> 是使用样本归纳总体的一种统计方法。推断统计非常有用，因为他允许我们基于有限的信息（样本）对总体得出结论。</p>

<h2>假设检验</h2>

<p>当我们使用样本对总体进行推断时，这个过程为假设检验（Hypothesis testing）。在假设检验中，通常要陈述两个假设：<strong>原假设（null hypothesis）</strong> 和<strong>对立假设（alternative hypothesis）</strong>。原假设通常陈述处理没有效果，而对立假设陈述处理有效果。</p>

<h2>单边检验和双边检验</h2>

<p>在评估处理要看是否对任一方向有影响（了解得分是更高还是更低）时使用双边检验，而在母的仅仅是调查单一方向（仅仅是更高还是更低）时使用单边检验。</p>

<h2>第一类错误和第二类错误</h2>

<p>在假设检验中，使用样本对总体进行推断。因为样本是总体的不完整“图像”，所以在假设检验过程中，就可能有错误。有两类错误发生：第一类错误，第二类错误。如果在原假设是真实的情况下拒绝了原假设，就发生了第一类错误。如果在原假设是错误的情况下没有拒绝原假设，就发生了第二类错误。</p>

<h2>功效</h2>

<p><strong>功效（power）</strong>等于原假设错误的拒绝原假设的概率（如果原假设是错误的，他也是被拒绝的，就是做了一个正确的决策）。功效的取值范围在0~1之间，数值越大，功效越大。</p>

<h2>抽样误差</h2>

<p>一般来说，样本越小，样本与总体的差异就越大。样本与总体的差异就是<strong>抽样误差（sampling error）</strong></p>

<h2>p-值</h2>

<p>如果从总体中抽取的样本通常都是不相同的，那么我们应该如何确定样本之间存在有意义的差异，还是由于抽样误差所导致的结果。p-值表明在原假设为真时获得特定结果的的概率。在假设检验中，检验的p-值是和预先确定的数值进行比较的，且基于比较的结果，对原假设进行决策。在社会和行为科学中，常用0.05位水平，来评价p-值。</p>

<blockquote><p>评价p-值过程如下：
1. 如果p-值小于或等于0.05（α），拒绝原假设（假定策略之间存在差异）
2. 如果p-值大于0.05（α），不能拒绝原假设（没有假定策略之间有差异）</p></blockquote>

<h2>效应量</h2>

<p><strong>效应量（effect sizes）</strong>一般用来描述策略组之间的差异程度，表明我们研究结果的大小。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[贝叶斯算法在检测群聊垃圾广告中的应用]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/07/03/bei-xie-si-suan-fa-zai-jian-ce-qun-liao-la-ji-yan-gao-zhong-de-ying-yong/"/>
    <updated>2017-07-03T12:18:45+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/07/03/bei-xie-si-suan-fa-zai-jian-ce-qun-liao-la-ji-yan-gao-zhong-de-ying-yong</id>
    <content type="html"><![CDATA[<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. 背景：</a></li>
<li><a href="#sec-2">2. 基本原理：</a></li>
<li><a href="#sec-3">3. 联合概率计算</a></li>
<li><a href="#sec-4">4. 算法实现</a></li>
</ul>
</div>
</div>


<h1>贝叶斯算法在检测群聊垃圾广告中的应用</h1>

<h1>背景：<a id="sec-1" name="sec-1"></a></h1>

<p>贝叶斯过滤器是一种基于统计学的过滤器方法，是建立在已有的统计结果之上的，所以在实现算法
之前需要先建立历史资料库，即，先提供两组已经标注好的训练数据。
在此附上训练数据链接：<a href="https://pan.baidu.com/s/1nuGW2Ul">https://pan.baidu.com/s/1nuGW2Ul</a></p>

<h1>基本原理：<a id="sec-2" name="sec-2"></a></h1>

<p>当看到一段文本时，我们先假定它是广告文本的概率为50%，其实整个识别模式就像垃圾邮件过滤
一样，我们先用S来表示垃圾文本，用H来表示正常文本。因此，P(S)和 P(H)的先验概率都是
50%：</p>

<p><script type="math/tex" id="MathJax-Element-115"> P(S) = P(H) = 50% </script></p>


<p>然后我们再对其进行分词解析处理，我们用W来表示其中存在的某个关键词，然后问题就转变成了在
某个词语W存在的情况之下，目标文本为垃圾文本的可能性有多大？而解决这个问题的关键就是计算
P（S|W）的值。根据条件概率公式我们可以写出以下等式。</p>

<p><script type="math/tex" id="MathJax-Element-116"> P(S|W) = P(W|S)P(S)/(P(W|S)P(S)+P(W|H)P(H)) </script></p>


<p>公式之中，P(W|S)和P(W|H)分别代表在正常文本和垃圾文本之中，词语W出现的概率，而这个概率
我们可以根据已经标注的好训练数据中计算得出。这里，我们假设对于词语W来说，上面所提到的两个
概率分别为5%和0.05%，那么我们可以计算出P(S|W)＝ 99.0%</p>

<p>因此，根据我们得出的99%的后验概率，我们可以说词语W的推断能力很强，在垃圾文本和正常文本之
中有十分良好的推断效果。</p>

<h1>联合概率计算<a id="sec-3" name="sec-3"></a></h1>

<p>但是，一段文本中存在非常多的词汇，我们不能单凭一个单词就推断出这段文本的分类属性。因此，
常规的做法是我们需要选取出整段文本中，P(S|W)最高的15个词，然后计算它们的联合概率。
（其中可能存在的问题有：某些新词在历史数据中都不曾出现过，我们无法计算其P(S|W)的值，
对于这样的问题需要用到贝叶斯平滑的思想进行处理，本文为了从简，我们都先假设这类词的P(S|W)
值为0.4）</p>

<p>对于联合概率的补充解释：联合概率是指在多个事件发生的情况之下，另一个发生的概率有多大。
例如：已知，W<sub>1</sub> 和 W<sub>2</sub>为两个不同的词语，它们都出现在某段文本之中，那么这段文本为广告
文本的概率就是W<sub>1</sub>和W<sub>2</sub>的联合概率。</p>

<p>最后，根据提取的15个词，得出最终的概率计算公式</p>

<p><script type="math/tex" id="MathJax-Element-118"> P ＝ P_1P_2P_3…P_{15}/(P_1P_2…P_{15}+(1-P_1)(1-P_2)…(1-P_{15})) </script></p>


<p>在得出最后的概率后，再对阈值（门槛值）进行比较，如：0.9,若 > 0.9 则15个词联合
认定为90%为垃圾文本！</p>

<h1>算法实现<a id="sec-4" name="sec-4"></a></h1>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#encoding=utf-8</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">pickle</span>
</span><span class='line'><span class="c">#spam类对象</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">jieba</span><span class="p">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">os</span><span class="p">;</span>
</span><span class='line'><span class="k">class</span> <span class="nc">spamEmailBayes</span><span class="p">:</span>
</span><span class='line'>    <span class="c">#获得停用词表</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">getStopWords</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="n">stopList</span><span class="o">=</span><span class="p">[]</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;../data/stopwords&quot;</span><span class="p">):</span>
</span><span class='line'>            <span class="n">stopList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">stopList</span><span class="p">;</span>
</span><span class='line'>    <span class="c">#获得词典</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">get_word_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">content</span><span class="p">,</span><span class="n">wordsList</span><span class="p">,</span><span class="n">stopList</span><span class="p">):</span>
</span><span class='line'>        <span class="c">#分词结果放入res_list</span>
</span><span class='line'>        <span class="n">res_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">content</span><span class="p">))</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">res_list</span><span class="p">:</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopList</span> <span class="ow">and</span> <span class="n">i</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">!=</span><span class="s">&#39;&#39;</span> <span class="ow">and</span> <span class="n">i</span><span class="o">!=</span><span class="bp">None</span><span class="p">:</span>
</span><span class='line'>                <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">wordsList</span><span class="p">:</span>
</span><span class='line'>                    <span class="n">wordsList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#若列表中的词已在词典中，则加1，否则添加进去</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">addToDict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">wordsList</span><span class="p">,</span><span class="n">wordsDict</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">wordsList</span><span class="p">:</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">wordsDict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>                <span class="n">wordsDict</span><span class="p">[</span><span class="n">item</span><span class="p">]</span><span class="o">+=</span><span class="mi">1</span>
</span><span class='line'>            <span class="k">else</span><span class="p">:</span>
</span><span class='line'>                <span class="n">wordsDict</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">item</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">get_File_List</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">filePath</span><span class="p">):</span>
</span><span class='line'>        <span class="n">filenames</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">filePath</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">filenames</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#通过计算每个文件中p(s|w)来得到对分类影响最大的15个词</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">getTestWords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">testDict</span><span class="p">,</span><span class="n">spamDict</span><span class="p">,</span><span class="n">normDict</span><span class="p">,</span><span class="n">normFilelen</span><span class="p">,</span><span class="n">spamFilelen</span><span class="p">):</span>
</span><span class='line'>        <span class="n">wordProbList</span><span class="o">=</span><span class="p">{}</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">word</span><span class="p">,</span><span class="n">num</span>  <span class="ow">in</span> <span class="n">testDict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">spamDict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">normDict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>                <span class="c">#该文件中包含词个数</span>
</span><span class='line'>                <span class="n">pw_s</span><span class="o">=</span><span class="n">spamDict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">/</span><span class="n">spamFilelen</span>
</span><span class='line'>                <span class="n">pw_n</span><span class="o">=</span><span class="n">normDict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">/</span><span class="n">normFilelen</span>
</span><span class='line'>                <span class="n">ps_w</span><span class="o">=</span><span class="n">pw_s</span><span class="o">/</span><span class="p">(</span><span class="n">pw_s</span><span class="o">+</span><span class="n">pw_n</span><span class="p">)</span>
</span><span class='line'>                <span class="n">wordProbList</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="n">ps_w</span><span class="p">)</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">spamDict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">normDict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>                <span class="n">pw_s</span><span class="o">=</span><span class="n">spamDict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">/</span><span class="n">spamFilelen</span>
</span><span class='line'>                <span class="n">pw_n</span><span class="o">=</span><span class="mf">0.01</span>
</span><span class='line'>                <span class="n">ps_w</span><span class="o">=</span><span class="n">pw_s</span><span class="o">/</span><span class="p">(</span><span class="n">pw_s</span><span class="o">+</span><span class="n">pw_n</span><span class="p">)</span>
</span><span class='line'>                <span class="n">wordProbList</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="n">ps_w</span><span class="p">)</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spamDict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">normDict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>                <span class="n">pw_s</span><span class="o">=</span><span class="mf">0.01</span>
</span><span class='line'>                <span class="n">pw_n</span><span class="o">=</span><span class="n">normDict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">/</span><span class="n">normFilelen</span>
</span><span class='line'>                <span class="n">ps_w</span><span class="o">=</span><span class="n">pw_s</span><span class="o">/</span><span class="p">(</span><span class="n">pw_s</span><span class="o">+</span><span class="n">pw_n</span><span class="p">)</span>
</span><span class='line'>                <span class="n">wordProbList</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="n">ps_w</span><span class="p">)</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">spamDict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">normDict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>                <span class="c">#若该词不在脏词词典中，概率设为0.4</span>
</span><span class='line'>                <span class="n">wordProbList</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="mf">0.4</span><span class="p">)</span>
</span><span class='line'>        <span class="nb">sorted</span><span class="p">(</span><span class="n">wordProbList</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span><span class="n">d</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span>
</span><span class='line'>        <span class="k">return</span> <span class="p">(</span><span class="n">wordProbList</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#计算贝叶斯概率</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">calBayes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">wordList</span><span class="p">,</span><span class="n">spamdict</span><span class="p">,</span><span class="n">normdict</span><span class="p">):</span>
</span><span class='line'>        <span class="n">ps_w</span><span class="o">=</span><span class="mi">1</span>
</span><span class='line'>        <span class="n">ps_n</span><span class="o">=</span><span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">for</span> <span class="n">word</span><span class="p">,</span><span class="n">prob</span> <span class="ow">in</span> <span class="n">wordList</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="p">:</span>
</span><span class='line'>            <span class="k">print</span><span class="p">(</span><span class="n">word</span><span class="o">+</span><span class="s">&quot;/&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">prob</span><span class="p">))</span>
</span><span class='line'>            <span class="n">ps_w</span><span class="o">*=</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
</span><span class='line'>            <span class="n">ps_n</span><span class="o">*=</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">prob</span><span class="p">)</span>
</span><span class='line'>        <span class="n">p</span><span class="o">=</span><span class="n">ps_w</span><span class="o">/</span><span class="p">(</span><span class="n">ps_w</span><span class="o">+</span><span class="n">ps_n</span><span class="p">)</span>
</span><span class='line'><span class="c">#         print(str(ps_w)+&quot;////&quot;+str(ps_n))</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">p</span>
</span><span class='line'>
</span><span class='line'>    <span class="c">#计算预测结果正确率</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">calAccuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">testResult</span><span class="p">):</span>
</span><span class='line'>        <span class="n">rightCount</span><span class="o">=</span><span class="mi">0</span>
</span><span class='line'>        <span class="n">errorCount</span><span class="o">=</span><span class="mi">0</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">name</span> <span class="p">,</span><span class="n">catagory</span> <span class="ow">in</span> <span class="n">testResult</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span class='line'>            <span class="k">if</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">name</span><span class="p">)</span><span class="o">&lt;</span><span class="mi">1000</span> <span class="ow">and</span> <span class="n">catagory</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="ow">or</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">name</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">1000</span> <span class="ow">and</span> <span class="n">catagory</span><span class="o">==</span><span class="mi">1</span><span class="p">):</span>
</span><span class='line'>                <span class="n">rightCount</span><span class="o">+=</span><span class="mi">1</span>
</span><span class='line'>            <span class="k">else</span><span class="p">:</span>
</span><span class='line'>                <span class="n">errorCount</span><span class="o">+=</span><span class="mi">1</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">rightCount</span><span class="o">/</span><span class="p">(</span><span class="n">rightCount</span><span class="o">+</span><span class="n">errorCount</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">spam</span><span class="o">=</span><span class="n">spamEmailBayes</span><span class="p">()</span>
</span><span class='line'><span class="c">#保存词频的词典</span>
</span><span class='line'><span class="n">spamDict</span><span class="o">=</span><span class="p">{}</span>
</span><span class='line'><span class="n">normDict</span><span class="o">=</span><span class="p">{}</span>
</span><span class='line'><span class="n">testDict</span><span class="o">=</span><span class="p">{}</span>
</span><span class='line'><span class="c">#保存每封邮件中出现的词</span>
</span><span class='line'><span class="n">wordsList</span><span class="o">=</span><span class="p">[]</span>
</span><span class='line'><span class="n">wordsDict</span><span class="o">=</span><span class="p">{}</span>
</span><span class='line'><span class="c">#保存预测结果,key为文件名，值为预测类别</span>
</span><span class='line'><span class="n">testResult</span><span class="o">=</span><span class="p">{}</span>
</span><span class='line'><span class="c">#分别获得正常邮件、垃圾邮件及测试文件名称列表</span>
</span><span class='line'><span class="n">normFileList</span><span class="o">=</span><span class="n">spam</span><span class="o">.</span><span class="n">get_File_List</span><span class="p">(</span><span class="s">&quot;../data/normal&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">spamFileList</span><span class="o">=</span><span class="n">spam</span><span class="o">.</span><span class="n">get_File_List</span><span class="p">(</span><span class="s">&quot;../data/spam&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">testFileList</span><span class="o">=</span><span class="n">spam</span><span class="o">.</span><span class="n">get_File_List</span><span class="p">(</span><span class="s">&quot;../data/test2&quot;</span><span class="p">)</span>
</span><span class='line'><span class="c">#获取训练集中正常邮件与垃圾邮件的数量</span>
</span><span class='line'><span class="n">normFilelen</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">normFileList</span><span class="p">)</span>
</span><span class='line'><span class="n">spamFilelen</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">spamFileList</span><span class="p">)</span>
</span><span class='line'><span class="c">#获得停用词表，用于对停用词过滤</span>
</span><span class='line'><span class="n">stopList</span><span class="o">=</span><span class="n">spam</span><span class="o">.</span><span class="n">getStopWords</span><span class="p">()</span>
</span><span class='line'><span class="c">#获得正常邮件中的词频</span>
</span><span class='line'><span class="k">for</span> <span class="n">fileName</span> <span class="ow">in</span> <span class="n">normFileList</span><span class="p">:</span>
</span><span class='line'>    <span class="n">wordsList</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;../data/normal/&quot;</span><span class="o">+</span><span class="n">fileName</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">&#39;gbk&#39;</span><span class="p">):</span>
</span><span class='line'>        <span class="c">#过滤掉非中文字符</span>
</span><span class='line'>        <span class="n">rule</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&quot;[^\u4e00-\u9fa5]&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">line</span><span class="o">=</span><span class="n">rule</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="n">line</span><span class="p">)</span>
</span><span class='line'>        <span class="c">#将每封邮件出现的词保存在wordsList中</span>
</span><span class='line'>        <span class="n">spam</span><span class="o">.</span><span class="n">get_word_list</span><span class="p">(</span><span class="n">line</span><span class="p">,</span><span class="n">wordsList</span><span class="p">,</span><span class="n">stopList</span><span class="p">)</span>
</span><span class='line'>    <span class="c">#统计每个词在所有邮件中出现的次数</span>
</span><span class='line'>    <span class="n">spam</span><span class="o">.</span><span class="n">addToDict</span><span class="p">(</span><span class="n">wordsList</span><span class="p">,</span> <span class="n">wordsDict</span><span class="p">)</span>
</span><span class='line'><span class="n">normDict</span><span class="o">=</span><span class="n">wordsDict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="n">output</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;norm.pkl&#39;</span><span class="p">,</span><span class="s">&#39;wb&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">normDict</span><span class="p">,</span><span class="n">output</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="n">output</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="c">#获得垃圾邮件中的词频</span>
</span><span class='line'><span class="n">wordsDict</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</span><span class='line'><span class="k">for</span> <span class="n">fileName</span> <span class="ow">in</span> <span class="n">spamFileList</span><span class="p">:</span>
</span><span class='line'>    <span class="n">wordsList</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;../data/spam/&quot;</span><span class="o">+</span><span class="n">fileName</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">&#39;gbk&#39;</span><span class="p">):</span>
</span><span class='line'>        <span class="n">rule</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&quot;[^\u4e00-\u9fa5]&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">line</span><span class="o">=</span><span class="n">rule</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="n">line</span><span class="p">)</span>
</span><span class='line'>        <span class="n">spam</span><span class="o">.</span><span class="n">get_word_list</span><span class="p">(</span><span class="n">line</span><span class="p">,</span><span class="n">wordsList</span><span class="p">,</span><span class="n">stopList</span><span class="p">)</span>
</span><span class='line'>    <span class="n">spam</span><span class="o">.</span><span class="n">addToDict</span><span class="p">(</span><span class="n">wordsList</span><span class="p">,</span> <span class="n">wordsDict</span><span class="p">)</span>
</span><span class='line'><span class="n">spamDict</span><span class="o">=</span><span class="n">wordsDict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="n">output</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;spam.pkl&#39;</span><span class="p">,</span><span class="s">&#39;wb&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">spamDict</span><span class="p">,</span><span class="n">output</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="n">output</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="n">output</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;model.pkl&#39;</span><span class="p">,</span><span class="s">&#39;wb&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">spam</span><span class="p">,</span><span class="n">output</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="n">output</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="c"># 测试邮件</span>
</span><span class='line'><span class="k">for</span> <span class="n">fileName</span> <span class="ow">in</span> <span class="n">testFileList</span><span class="p">:</span>
</span><span class='line'>    <span class="n">testDict</span><span class="o">.</span><span class="n">clear</span><span class="p">(</span> <span class="p">)</span>
</span><span class='line'>    <span class="n">wordsDict</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</span><span class='line'>    <span class="n">wordsList</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;../data/test2/&quot;</span><span class="o">+</span><span class="n">fileName</span><span class="p">):</span>
</span><span class='line'>    <span class="c">#for line in open(&quot;../data/test/&quot;+fileName,encoding=&#39;gbk&#39;):</span>
</span><span class='line'>        <span class="n">rule</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&quot;[^\u4e00-\u9fa5]&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">line</span><span class="o">=</span><span class="n">rule</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="n">line</span><span class="p">)</span>
</span><span class='line'>        <span class="n">spam</span><span class="o">.</span><span class="n">get_word_list</span><span class="p">(</span><span class="n">line</span><span class="p">,</span><span class="n">wordsList</span><span class="p">,</span><span class="n">stopList</span><span class="p">)</span>
</span><span class='line'>    <span class="n">spam</span><span class="o">.</span><span class="n">addToDict</span><span class="p">(</span><span class="n">wordsList</span><span class="p">,</span> <span class="n">wordsDict</span><span class="p">)</span>
</span><span class='line'>    <span class="n">testDict</span><span class="o">=</span><span class="n">wordsDict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span class='line'>    <span class="c">#通过计算每个文件中p(s|w)来得到对分类影响最大的15个词</span>
</span><span class='line'>    <span class="n">wordProbList</span><span class="o">=</span><span class="n">spam</span><span class="o">.</span><span class="n">getTestWords</span><span class="p">(</span><span class="n">testDict</span><span class="p">,</span> <span class="n">spamDict</span><span class="p">,</span><span class="n">normDict</span><span class="p">,</span><span class="n">normFilelen</span><span class="p">,</span><span class="n">spamFilelen</span><span class="p">)</span>
</span><span class='line'>    <span class="c">#对每封邮件得到的15个词计算贝叶斯概率</span>
</span><span class='line'>    <span class="n">p</span><span class="o">=</span><span class="n">spam</span><span class="o">.</span><span class="n">calBayes</span><span class="p">(</span><span class="n">wordProbList</span><span class="p">,</span> <span class="n">spamDict</span><span class="p">,</span> <span class="n">normDict</span><span class="p">)</span>
</span><span class='line'>    <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="o">&gt;</span><span class="mf">0.9</span><span class="p">):</span>
</span><span class='line'>        <span class="n">testResult</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">fileName</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>    <span class="k">else</span><span class="p">:</span>
</span><span class='line'>        <span class="n">testResult</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">fileName</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'><span class="c">#计算分类准确率（测试集中文件名低于1000的为正常邮件）</span>
</span><span class='line'><span class="n">testAccuracy</span><span class="o">=</span><span class="n">spam</span><span class="o">.</span><span class="n">calAccuracy</span><span class="p">(</span><span class="n">testResult</span><span class="p">)</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ic</span> <span class="ow">in</span> <span class="n">testResult</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span class='line'>    <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="s">&quot;/&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">ic</span><span class="p">))</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">testAccuracy</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python大规模数据的处理技巧]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/06/07/pythonda-gui-mo-shu-ju-de-chu-li-ji-qiao/"/>
    <updated>2017-06-07T13:43:01+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/06/07/pythonda-gui-mo-shu-ju-de-chu-li-ji-qiao</id>
    <content type="html"><![CDATA[<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. 问题一：大数据量的csv读入到内存中</a>
<ul>
<li><a href="#sec-1-1">1.1. 问题分析：</a></li>
<li><a href="#sec-1-2">1.2. 应对思路：</a></li>
<li><a href="#sec-1-3">1.3. 简易示例：</a></li>
</ul>
</li>
<li><a href="#sec-2">2. 问题二：如何高效读取csv文件成python内部的list结构</a>
<ul>
<li><a href="#sec-2-1">2.1. 问题分析：</a></li>
<li><a href="#sec-2-2">2.2. 应对思路：</a></li>
<li><a href="#sec-2-3">2.3. 简易示例：</a></li>
</ul>
</li>
<li><a href="#sec-3">3. 问题三：数据结构之间合并</a>
<ul>
<li><a href="#sec-3-1">3.1. 问题分析：</a></li>
<li><a href="#sec-3-2">3.2. 应对思路：</a></li>
<li><a href="#sec-3-3">3.3. 简易示例：</a></li>
</ul>
</li>
</ul>
</div>
</div>


<p>目前在数据分析和挖掘领域内，最为热门的莫过于Python和R了，不过这两门语言一直因为不好处理大规模的数据而被人们调侃，
同时，hadoop和spark也因此应运而生。然而，其实Python在大规模的数据处理上也并非像传言所说的那么慢。甚者，其中也蕴含了
挺多的技巧让我们能够利用Python对大规模的数据进行分析计算。</p>

<p>下面就Python操作大规模数据时可能会遇到的问题，给出一些个人的见解。</p>

<h1>问题一：大数据量的csv读入到内存中<a id="sec-1" name="sec-1"></a></h1>

<h2>问题分析：<a id="sec-1-1" name="sec-1-1"></a></h2>

<p>当一个csv文件的数据量十分大时，例如，一个电商站点的一个月的流水帐单或交易记录，其中可能有高达几千万条至上亿条
记录文本。这样的文件对于一般性能的计算机来说，若是全部数据一次读入内存的存储就非常吃力了，甚至有崩溃的可能。</p>

<h2>应对思路：<a id="sec-1-2" name="sec-1-2"></a></h2>

<p>这时一个比较明智的方法就是将这些数据全部读入数据库之中，或者是根据我们的实际数据使用情况将大文件拆分成小块，然后
再按块读入。</p>

<h2>简易示例：<a id="sec-1-3" name="sec-1-3"></a></h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#使用pandas包的最简示例</span>
</span><span class='line'> <span class="n">chunker</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">PATH_LOAD</span><span class="p">,</span> <span class="n">chunksize</span> <span class="o">=</span> <span class="n">CHUNK_SIZE</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">#按列按需读取</span>
</span><span class='line'>  <span class="n">columns</span> <span class="o">=</span> <span class="p">(</span><span class="s">&quot;date_time&quot;</span><span class="p">,</span>  <span class="s">&quot;user_id&quot;</span><span class="p">)</span>
</span><span class='line'>  <span class="n">chunks_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">usecols</span> <span class="o">=</span> <span class="n">columns</span><span class="p">,</span> <span class="n">chunksize</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">#分块分行读取</span>
</span><span class='line'><span class="k">for</span> <span class="n">rawPiece</span> <span class="ow">in</span> <span class="n">chunker_rawData</span><span class="p">:</span>
</span><span class='line'>  <span class="n">current_chunk_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">rawPiece</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>   <span class="c">#rawPiece 是dataframe</span>
</span><span class='line'>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">current_chunk_size</span> <span class="p">):</span>
</span><span class='line'>    <span class="n">timeFlag</span> <span class="o">=</span> <span class="n">timeShape</span><span class="p">(</span><span class="n">rawPiece</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>   <span class="c">#获取第i行的数据</span>
</span></code></pre></td></tr></table></div></figure>


<h1>问题二：如何高效读取csv文件成python内部的list结构<a id="sec-2" name="sec-2"></a></h1>

<h2>问题分析：<a id="sec-2-1" name="sec-2-1"></a></h2>

<p>当仅仅需要对外部大规模的csv做一些的简单的求和，求平均值，等简单的统计描述性分析时，使用pandas包显然是不明智的，因为pd
的读取中包含了各种抽象的转换操作，一但数据规模较大，性能是十分低下的。</p>

<h2>应对思路：<a id="sec-2-2" name="sec-2-2"></a></h2>

<p>这时应该直接采用python原生的IO读写操作，节省那些多此一举的转换操作。</p>

<h2>简易示例：<a id="sec-2-3" name="sec-2-3"></a></h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#使用pandas包的方法，转换操作多，效率低下。</span>
</span><span class='line'>    <span class="n">userList</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="n">content</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">content</span><span class="p">)):</span>
</span><span class='line'>        <span class="n">line</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s">&#39;id&#39;</span><span class="p">]</span>
</span><span class='line'>        <span class="n">userList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">#直接使用原生操作读取外部数据，效率较高，但数据操作不及pandas方便</span>
</span><span class='line'>    <span class="n">userList</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</span><span class='line'>    <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">content</span><span class="p">:</span>
</span><span class='line'>        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\n</span><span class="s">&#39;</span><span class="p">,</span> <span class="s">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;,&#39;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">userList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h1>问题三：数据结构之间合并<a id="sec-3" name="sec-3"></a></h1>

<h2>问题分析：<a id="sec-3-1" name="sec-3-1"></a></h2>

<p>当你要对一组数据特征进行建模时，就要用到数据结构的合并功能了。
然而，对于大规模数据来说，任何的操作和合并如何采用的方法不当，其要浪费的时间都是十分致命的。</p>

<h2>应对思路：<a id="sec-3-2" name="sec-3-2"></a></h2>

<p>纵向的合并使用list并不好，因为需要去拆解list的每一个行元素，并用extend去拓展每一行的纵向元素
最好使用dataframe中的concat函数：c = pd.concat([a, b], axis = 1)，当axis=0时表示合并行（以行为轴）</p>

<h2>简易示例：<a id="sec-3-3" name="sec-3-3"></a></h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">inx1</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nSample_neg</span><span class="p">),</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;randVal&#39;</span><span class="p">])</span>
</span><span class='line'><span class="n">inx2</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nSample_neg</span><span class="p">),</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;inxVal&#39;</span><span class="p">])</span>
</span><span class='line'><span class="n">inx</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">inx1</span><span class="p">,</span> <span class="n">inx2</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于Redis的Bloomfilter]]></title>
    <link href="https://edmondfrank.github.io/blog/2017/05/21/ji-yu-redisde-bloomfilter/"/>
    <updated>2017-05-21T11:05:15+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2017/05/21/ji-yu-redisde-bloomfilter</id>
    <content type="html"><![CDATA[<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. 背景</a></li>
<li><a href="#sec-2">2. 前言及原理简介</a>
<ul>
<li><a href="#sec-2-1">2.1. 传统弊端</a></li>
<li><a href="#sec-2-2">2.2. bloomfilter</a>
<ul>
<li><a href="#sec-2-2-1">2.2.1. 优点：</a></li>
<li><a href="#sec-2-2-2">2.2.2. 缺点：</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#sec-3">3. 简单图示</a></li>
<li><a href="#sec-4">4. 算法实现</a></li>
</ul>
</div>
</div>


<h1>背景<a id="sec-1" name="sec-1"></a></h1>

<p>url去重一直是大型分布式爬虫的主题，在一般规模比较大的的情景，去重需要考虑到两个点：</p>

<ol>
<li>去重的数据量</li>
<li>去重的速度</li>
</ol>


<p>并且，在一般情况下为了尽量降低去重对爬虫效率的影响一般选择在内存中去重。</p>

<ul>
<li>小数据：直接使用语言的逻辑判断及数据结构去重，如python的set，ruby的Set</li>
<li>持续化去重： redis的set</li>
<li>中型数据量去重：加密算法压缩url及长字符串在混合使用其他方法去重</li>
<li>大型数据去重：使用bloomfilter（布隆过滤器）桉内存位去重</li>
</ul>


<h1>前言及原理简介<a id="sec-2" name="sec-2"></a></h1>

<h2>传统弊端<a id="sec-2-1" name="sec-2-1"></a></h2>

<p>按照以往惯例来说，我们一般判断一个元素是否在一个集合内的通常做法是：先将所有元素保存下来，
然后通过比较判断它是否在集合之中。但是，这样的常规判断方法有一个很大的弊端就是，随着集合内的
元素个数变大，我们需要的空间和时间都呈线性增长，检索速度也越来越慢。</p>

<h2>bloomfilter<a id="sec-2-2" name="sec-2-2"></a></h2>

<p>而Bloom filter 采用的是哈希函数的方法，将一个元素表示为一个点并将他映射到一个长度为m的
阵列上。在检索时如果在阵列上发现对应的映射点为1时，那么这个元素在集合内，反之则不在集合内。</p>

<h3>优点：<a id="sec-2-2-1" name="sec-2-2-1"></a></h3>

<p>Bloom filter 优点在于它的插入和查询时间都是常数，另外它查询的元素不保存元素本身，具有良好的
安全性。</p>

<h3>缺点：<a id="sec-2-2-2" name="sec-2-2-2"></a></h3>

<p>最明显的一点是，当插入元素越多，查询元素被错判成“在集合内”的概率就越大。针对这个问题常用的
解决方法有：使用k个哈希函数来对应映射k个点，如果所对应的所有点都是1的话。那么元素在集合内，
如果任何一个有0的话，则元素不在集合内。另外，Bloom filter也不能删除一个元素，因为多个元素的哈希
的结果可能在bloom filter的阵列中都是占用同一个位。如果删除了一个比特位，可能会影响多个元素的检测。</p>

<h1>简单图示<a id="sec-3" name="sec-3"></a></h1>

<p>实现我们设我们的哈希函数有两个。</p>

<p>开始时集合内没有元素：</p>

<p><img src="http://e.hiphotos.baidu.com/baike/s%3D250/sign=0fd8813a78f0f736dcfe4b043a54b382/7af40ad162d9f2d3f39093aaa9ec8a136227ccf6.jpg" alt="img" /></p>

<p>当来了一个元素a时，进行哈希计算再判断，当计算出对应的比特位上为0时，即a不在集合内，添加a的哈希值进去。</p>

<p><img src="http://g.hiphotos.baidu.com/baike/s%3D250/sign=7debb7818c1001e94a3c130a880e7b06/9d82d158ccbf6c815e2dd280bd3eb13533fa4044.jpg" alt="img" /></p>

<p>之后的元素，要判断是不是在集合内，也是同 a 一样的方法，只有对元素哈希后对应位置上都是 1 才认为这个元素在集合内</p>

<p><img src="http://c.hiphotos.baidu.com/baike/s%3D250/sign=71f00574a18b87d65442ac1a37092860/d6ca7bcb0a46f21f7ce5e916f6246b600d33aea6.jpg" alt="img" /></p>

<p>随着元素的插入，Bloom filter 中修改的值变多，出现误判的几率也随之变大，当新来一个元素时，
满足其在集合内的条件，即所有对应位都是1，这样就可能有两种情况，
一是这个元素就在集合内，没有发生误判；还有一种情况就是发生误判，出现了哈希碰撞，这个元素本不在集合内。</p>

<p><img src="http://a.hiphotos.baidu.com/baike/s%3D250/sign=7dd68ea2912397ddd2799f016983b216/2cf5e0fe9925bc31448eb6dd5edf8db1ca1370a7.jpg" alt="img" /></p>

<h1>算法实现<a id="sec-4" name="sec-4"></a></h1>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># encoding=utf-8</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">redis</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">hashlib</span> <span class="kn">import</span> <span class="n">md5</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">SimpleHash</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cap</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">cap</span> <span class="o">=</span> <span class="n">cap</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">hash</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
</span><span class='line'>        <span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)):</span>
</span><span class='line'>            <span class="n">ret</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">*</span> <span class="n">ret</span> <span class="o">+</span> <span class="nb">ord</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span class='line'>        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cap</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">ret</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">BloomFilter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><span class="s">&#39;localhost&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">6379</span><span class="p">,</span> <span class="n">db</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">blockNum</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s">&#39;bloomfilter&#39;</span><span class="p">):</span>
</span><span class='line'>        <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">        :param host: the host of Redis</span>
</span><span class='line'><span class="sd">        :param port: the port of Redis</span>
</span><span class='line'><span class="sd">        :param db: witch db in Redis</span>
</span><span class='line'><span class="sd">        :param blockNum: one blockNum for about 90,000,000; if you have more strings for filtering, increase it.</span>
</span><span class='line'><span class="sd">        :param key: the key&#39;s name in Redis</span>
</span><span class='line'><span class="sd">        &quot;&quot;&quot;</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">server</span> <span class="o">=</span> <span class="n">redis</span><span class="o">.</span><span class="n">Redis</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">port</span><span class="p">,</span> <span class="n">db</span><span class="o">=</span><span class="n">db</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">bit_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">31</span>  <span class="c"># Redis的String类型最大容量为512M，现使用256M</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">seeds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="mi">61</span><span class="p">]</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">key</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">blockNum</span> <span class="o">=</span> <span class="n">blockNum</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">hashfunc</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">seeds</span><span class="p">:</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">hashfunc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SimpleHash</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bit_size</span><span class="p">,</span> <span class="n">seed</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">isContains</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">str_input</span><span class="p">):</span>
</span><span class='line'>        <span class="k">if</span> <span class="ow">not</span> <span class="n">str_input</span><span class="p">:</span>
</span><span class='line'>            <span class="k">return</span> <span class="bp">False</span>
</span><span class='line'>        <span class="n">m5</span> <span class="o">=</span> <span class="n">md5</span><span class="p">()</span>
</span><span class='line'>        <span class="n">m5</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">str_input</span><span class="p">)</span>
</span><span class='line'>        <span class="n">str_input</span> <span class="o">=</span> <span class="n">m5</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
</span><span class='line'>        <span class="n">ret</span> <span class="o">=</span> <span class="bp">True</span>
</span><span class='line'>        <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">str_input</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="mi">16</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">blockNum</span><span class="p">)</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hashfunc</span><span class="p">:</span>
</span><span class='line'>            <span class="n">loc</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">str_input</span><span class="p">)</span>
</span><span class='line'>            <span class="n">ret</span> <span class="o">=</span> <span class="n">ret</span> <span class="o">&amp;</span> <span class="bp">self</span><span class="o">.</span><span class="n">server</span><span class="o">.</span><span class="n">getbit</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">loc</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">ret</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">insert</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">str_input</span><span class="p">):</span>
</span><span class='line'>        <span class="n">m5</span> <span class="o">=</span> <span class="n">md5</span><span class="p">()</span>
</span><span class='line'>        <span class="n">m5</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">str_input</span><span class="p">)</span>
</span><span class='line'>        <span class="n">str_input</span> <span class="o">=</span> <span class="n">m5</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
</span><span class='line'>        <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">str_input</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="mi">16</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">blockNum</span><span class="p">)</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hashfunc</span><span class="p">:</span>
</span><span class='line'>            <span class="n">loc</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">str_input</span><span class="p">)</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">server</span><span class="o">.</span><span class="n">setbit</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
</span><span class='line'><span class="sd">&quot;&quot;&quot; 第一次运行时会显示 not exists!，之后再运行会显示 exists! &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">bf</span> <span class="o">=</span> <span class="n">BloomFilter</span><span class="p">()</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">bf</span><span class="o">.</span><span class="n">isContains</span><span class="p">(</span><span class="s">&#39;http://www.baidu.com&#39;</span><span class="p">):</span>   <span class="c"># 判断字符串是否存在</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&#39;exists!&#39;</span>
</span><span class='line'>    <span class="k">else</span><span class="p">:</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&#39;not exists!&#39;</span>
</span><span class='line'>        <span class="n">bf</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="s">&#39;http://www.baidu.com&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
</feed>
