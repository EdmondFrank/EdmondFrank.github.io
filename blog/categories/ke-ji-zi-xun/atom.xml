<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 科技资讯 | EdmondFrank's 时光足迹]]></title>
  <link href="https://edmondfrank.github.io/blog/categories/ke-ji-zi-xun/atom.xml" rel="self"/>
  <link href="https://edmondfrank.github.io/"/>
  <updated>2020-04-09T15:52:44+08:00</updated>
  <id>https://edmondfrank.github.io/</id>
  <author>
    <name><![CDATA[EdmondFrank]]></name>
    <email><![CDATA[EdmomdFrank@yahoo.co.jp]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[SLAM的复兴-无人驾驶的未来?]]></title>
    <link href="https://edmondfrank.github.io/blog/2018/06/01/slamde-fu-xing-wu-ren-jia-shi-de-wei-lai/"/>
    <updated>2018-06-01T20:09:15+08:00</updated>
    <id>https://edmondfrank.github.io/blog/2018/06/01/slamde-fu-xing-wu-ren-jia-shi-de-wei-lai</id>
    <content type="html"><![CDATA[<h2 id="slam的前世今生">SLAM的前世今生</h2>




<p>SLAM，全称(simultaneous localization and mapping)，中文译做，即时定位与地图构建。是指运动物体根据传感器的信息，一边计算自身位置，一边构建环境地图的过程，解决机器人等在未知环境下运动时的定位与地图构建问题。目前，SLAM的主要应用于机器人、无人机、无人驾驶、AR、VR等领域。其用途包括传感器自身的定位，以及后续的路径规划、运动性能、场景理解。 </p>




<p>作为一种基础技术，最早可以追溯到当初的军事潜艇定位技术。而今年来随着扫地机器人的盛行，再次令他名声大噪。加上最近的无人驾驶与机器人的寻迹的崛起以及基于三维视觉的VSLAM的出现又让它越来越显主流。</p>




<p>目前用在SLAM上的Sensor主要分两大类，分别是激光雷达和摄像头。</p>




<h2 id="slam到底做了些什么">SLAM到底做了些什么?</h2>




<p>既然SLAM技术代表了即时定位与地图构建，那么可以说这就是一个机器人或设备尝试去根据他周围的环境创建地图的过程，并且还可以在该地图中实时定位自己。</p>




<p>这不是一件容易的事，这项技术现在还处在技术研究和设计的前沿。而为了成功实施SLAM有一大障碍是不可i避免的，那就是<strong>地图</strong>和<strong>定位</strong>问题，两个问题同时引入就变成了我们常说的典型的<strong>鸡与蛋</strong>问题。为了能够成功地顺利的根据环境创建地图，我们的设备就必须先知道它的方向和位置 ;然而，这些定位信息设备也只能从预先存在的环境地图中获得。</p>




<p>面对这一障碍，SLAM技术通常通过使用GPS数据构建预先存在的环境地图来克服这一复杂的鸡与蛋问题。随着机器人或设备在环境中移动，生成的地图会被迭代地改进。而这项技术的真正挑战是准确性。随着机器人或设备在空间中移动与寻迹，测量评估必须不断进行，并且该技术必须考虑设备移动和测量方法不准确而引起的“噪音”。</p>




<p><img src="https://i.loli.net/2018/06/01/5b11319dab704.gif" alt="enter image description here" title=""></p>




<p>这个gif是宾大的教授kumar做的特别有名的一个demo，是在无人机上利用二维激光雷达做的SLAM。</p>




<h2 id="vslam又是什么">VSLAM又是什么?</h2>




<p>VSLAM（基于视觉的定位与建图）：随着计算机视觉的迅速发展，视觉SLAM因为信息量大，适用范围广等优点受到广泛关注。</p>




<p>（1）基于深度摄像机的Vslam，跟激光SLAM类似，通过收集到的点云数据，能直接计算障碍物距离；</p>




<p>（2）基于单目、鱼眼相机的VSLAM方案，利用多帧图像来估计自身的位姿变化，再通过累计位姿变化来计算距离物体的距离，并进行定位与地图构建；</p>




<p><img src="https://i.loli.net/2018/06/01/5b1131954cc50.gif" alt="enter image description here" title=""></p>




<p>以上为百度 VSLAM demo展示。</p>




<h2 id="vslam能够为自动驾驶带来些什么">VSLAM能够为自动驾驶带来些什么?</h2>




<p>结合自动驾驶的场景，可以推出VSLAM的应用点主要是:</p>




<ul>
<li>gps缺失场景下的长时间定位，如室内，楼房中。</li>
<li>补偿行驶过程中gps信号不稳定造成的定位跳跃，如山洞，高楼群，野外山区等。</li>
</ul>




<p>VSLAM的精度及鲁棒性越高，适用的场景越宽广。如果VSLAM能在任何场景无限长定位保持高精度，那其他定位技术就可以下岗了，虽然按目前看来这个可能性很小，因此需要尝试结合IMU，编码器等设备融合。至于最终的技术形态，目前还没有定论。</p>




<p>在无人驾驶汽车上，目前比较显著的瓶颈还在计算方面，数据收发，障碍物感知，融合定位，路径规划，每个模块都需要占据相当的计算资源。而无论视觉还是激光SLAM本身就是对计算力消耗极大的一个模块，如果加上高频率的IMU进行融合优化，则计算力更加捉襟见肘。因此是否值得为视觉SLAM分配原本就那么有限的计算资源，如何识别场景对SLAM模块进行激活都是需要仔细衡量的。</p>

]]></content>
  </entry>
  
</feed>
